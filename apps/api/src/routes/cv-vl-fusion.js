/**
 * CV+VLæ··åˆè¯†åˆ«APIè·¯ç”±
 * ä¸ºSketchUpæ’ä»¶æä¾›CV+VLæ··åˆå»ºç­‘è¯†åˆ«æœåŠ¡
 */

const express = require('express');
const multer = require('multer');
const CVVLFusionService = require('../services/ai-modeling/CVVLFusionService');
const sharp = require('sharp');

const router = express.Router();

// é…ç½®æ–‡ä»¶ä¸Šä¼ 
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 }, // 10MB
  fileFilter: (req, file, cb) => {
    if (file.mimetype.startsWith('image/')) {
      cb(null, true);
    } else {
      cb(new Error('åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶'), false);
    }
  }
});

/**
 * POST /api/ai-modeling/cv-vl-fusion
 * CV+VLæ··åˆè¯†åˆ«ä¸»æ¥å£
 */
router.post('/cv-vl-fusion', async (req, res) => {
  console.log('ğŸ”„ æ¥æ”¶CV+VLæ··åˆè¯†åˆ«è¯·æ±‚...');
  
  try {
    let imageBuffer;
    let imageInfo;
    
    // å¤„ç†ä¸åŒçš„è¾“å…¥æ ¼å¼
    if (req.body.image_base64) {
      // Base64æ ¼å¼ (ä»SketchUp Rubyè„šæœ¬)
      console.log('ğŸ“¥ å¤„ç†Base64å›¾ç‰‡æ•°æ®...');
      imageBuffer = Buffer.from(req.body.image_base64, 'base64');
      imageInfo = req.body.image_info || {};
      
    } else {
      return res.status(400).json({
        success: false,
        error: 'MISSING_IMAGE_DATA',
        message: 'ç¼ºå°‘å›¾ç‰‡æ•°æ®ï¼Œè¯·æä¾›image_base64å­—æ®µ'
      });
    }
    
    // è·å–å›¾ç‰‡å…ƒæ•°æ®
    if (!imageInfo.width || !imageInfo.height) {
      console.log('ğŸ“ è·å–å›¾ç‰‡å°ºå¯¸...');
      const metadata = await sharp(imageBuffer).metadata();
      imageInfo = {
        width: metadata.width,
        height: metadata.height,
        format: metadata.format,
        size: imageBuffer.length
      };
    }
    
    console.log(`å›¾ç‰‡ä¿¡æ¯: ${imageInfo.width}Ã—${imageInfo.height}px, ${(imageBuffer.length/1024).toFixed(1)}KB`);
    
    // æå–é€‰é¡¹å‚æ•°
    const options = req.body.options || {};
    
    console.log('ğŸ”„ å¼€å§‹CV+VLæ··åˆåˆ†æ...');
    const startTime = Date.now();
    
    // è°ƒç”¨CV+VLæ··åˆæœåŠ¡
    const result = await CVVLFusionService.analyzeBuildingWithFusion(
      imageBuffer, 
      imageInfo, 
      options
    );
    
    const processingTime = Date.now() - startTime;
    console.log(`âœ… CV+VLåˆ†æå®Œæˆï¼Œè€—æ—¶: ${(processingTime/1000).toFixed(2)}ç§’`);
    
    // æ·»åŠ å¤„ç†æ—¶é—´å’Œè¯·æ±‚ä¿¡æ¯
    result.processing_info = {
      ...(result.processing_info || {}),
      processing_time_ms: processingTime,
      image_info: imageInfo,
      request_timestamp: new Date().toISOString(),
      api_version: '1.0'
    };
    
    // è¿”å›ç»“æœ
    res.json(result);
    
  } catch (error) {
    console.error('âŒ CV+VLæ··åˆè¯†åˆ«å¤±è´¥:', error.message);
    console.error(error.stack);
    
    res.status(500).json({
      success: false,
      error: 'CV_VL_FUSION_FAILED',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * POST /api/ai-modeling/cv-vl-fusion/file
 * æ–‡ä»¶ä¸Šä¼ ç‰ˆæœ¬çš„CV+VLæ··åˆè¯†åˆ«
 */
router.post('/cv-vl-fusion/file', upload.single('image'), async (req, res) => {
  console.log('ğŸ”„ æ¥æ”¶æ–‡ä»¶ä¸Šä¼ CV+VLæ··åˆè¯†åˆ«è¯·æ±‚...');
  
  try {
    if (!req.file) {
      return res.status(400).json({
        success: false,
        error: 'NO_FILE_UPLOADED',
        message: 'æœªä¸Šä¼ å›¾ç‰‡æ–‡ä»¶'
      });
    }
    
    const imageBuffer = req.file.buffer;
    console.log(`ä¸Šä¼ æ–‡ä»¶: ${req.file.originalname}, ${(imageBuffer.length/1024).toFixed(1)}KB`);
    
    // è·å–å›¾ç‰‡ä¿¡æ¯
    const metadata = await sharp(imageBuffer).metadata();
    const imageInfo = {
      width: metadata.width,
      height: metadata.height,
      format: metadata.format,
      size: imageBuffer.length,
      filename: req.file.originalname
    };
    
    // å¤„ç†é€‰é¡¹å‚æ•°
    const options = req.body.options ? JSON.parse(req.body.options) : {};
    
    console.log('ğŸ”„ å¼€å§‹CV+VLæ··åˆåˆ†æ...');
    const startTime = Date.now();
    
    // è°ƒç”¨CV+VLæ··åˆæœåŠ¡
    const result = await CVVLFusionService.analyzeBuildingWithFusion(
      imageBuffer, 
      imageInfo, 
      options
    );
    
    const processingTime = Date.now() - startTime;
    console.log(`âœ… CV+VLåˆ†æå®Œæˆï¼Œè€—æ—¶: ${(processingTime/1000).toFixed(2)}ç§’`);
    
    // æ·»åŠ å¤„ç†ä¿¡æ¯
    result.processing_info = {
      ...(result.processing_info || {}),
      processing_time_ms: processingTime,
      image_info: imageInfo,
      request_timestamp: new Date().toISOString(),
      api_version: '1.0'
    };
    
    res.json(result);
    
  } catch (error) {
    console.error('âŒ æ–‡ä»¶ä¸Šä¼ CV+VLè¯†åˆ«å¤±è´¥:', error.message);
    
    res.status(500).json({
      success: false,
      error: 'FILE_CV_VL_FUSION_FAILED',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * GET /api/ai-modeling/cv-vl-fusion/health
 * CV+VLæ··åˆæœåŠ¡å¥åº·æ£€æŸ¥
 */
router.get('/cv-vl-fusion/health', async (req, res) => {
  try {
    // æ£€æŸ¥CVæœåŠ¡
    const cvHealthy = await checkCVServiceHealth();
    
    // æ£€æŸ¥VLæœåŠ¡
    const vlHealthy = await checkVLServiceHealth();
    
    const overallHealthy = cvHealthy && vlHealthy;
    
    const healthStatus = {
      status: overallHealthy ? 'healthy' : 'degraded',
      timestamp: new Date().toISOString(),
      services: {
        cv_geometry_detection: {
          status: cvHealthy ? 'up' : 'down',
          endpoint: 'http://localhost:8088'
        },
        vl_semantic_analysis: {
          status: vlHealthy ? 'up' : 'down', 
          endpoint: process.env.QWENVL_ENDPOINT || 'http://10.10.18.2:8001'
        }
      },
      fusion_service: {
        status: 'up',
        version: '1.0'
      }
    };
    
    res.status(overallHealthy ? 200 : 503).json(healthStatus);
    
  } catch (error) {
    res.status(503).json({
      status: 'error',
      message: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * GET /api/ai-modeling/cv-vl-fusion/info
 * è·å–CV+VLæ··åˆæœåŠ¡ä¿¡æ¯
 */
router.get('/cv-vl-fusion/info', (req, res) => {
  res.json({
    service_name: 'CV+VLæ··åˆå»ºç­‘è¯†åˆ«æœåŠ¡',
    version: '1.0.0',
    description: 'ç»“åˆOpenCVå‡ ä½•æ£€æµ‹å’ŒVLè¯­ä¹‰è¯†åˆ«çš„æ··åˆå»ºç­‘åˆ†ææœåŠ¡',
    capabilities: {
      geometry_detection: {
        provider: 'OpenCV',
        features: ['çº¿æ®µæ£€æµ‹', 'ç­ç‚¹è®¡ç®—', 'è§’ç‚¹æ£€æµ‹', 'è½®å»“é‡å»º']
      },
      semantic_analysis: {
        provider: 'QwenVL-7B',
        features: ['å»ºç­‘åˆ†ç±»', 'åŠŸèƒ½è¯†åˆ«', 'ç©ºé—´å…³ç³»', 'è¯­ä¹‰æ ‡ç­¾']
      },
      fusion_algorithm: {
        strategy: 'geometry_cv_semantics_vl',
        quality_assessment: true,
        fallback_support: true
      }
    },
    input_formats: ['image/jpeg', 'image/png', 'image/webp'],
    max_file_size: '10MB',
    typical_processing_time: '5-15ç§’',
    endpoints: [
      'POST /api/ai-modeling/cv-vl-fusion',
      'POST /api/ai-modeling/cv-vl-fusion/file',
      'GET /api/ai-modeling/cv-vl-fusion/health',
      'GET /api/ai-modeling/cv-vl-fusion/info'
    ]
  });
});

// å¥åº·æ£€æŸ¥è¾…åŠ©å‡½æ•°
async function checkCVServiceHealth() {
  try {
    const axios = require('axios');
    const response = await axios.get('http://localhost:8088/health', { timeout: 3000 });
    return response.status === 200 && response.data.status === 'healthy';
  } catch (error) {
    return false;
  }
}

async function checkVLServiceHealth() {
  try {
    const axios = require('axios');
    const endpoint = process.env.QWENVL_ENDPOINT || 'http://10.10.18.2:8001';
    const response = await axios.get(`${endpoint}/v1/models`, { timeout: 5000 });
    return response.status === 200;
  } catch (error) {
    return false;
  }
}

module.exports = router;