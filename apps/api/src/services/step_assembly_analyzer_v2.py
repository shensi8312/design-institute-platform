#!/usr/bin/env python3
"""
STEPè£…é…æ–‡ä»¶æ™ºèƒ½åˆ†æå™¨ V2 - pythonOCCç‰ˆæœ¬
ç²¾ç¡®çš„å‡ ä½•ç‰¹å¾æå–å’Œè£…é…çº¦æŸåˆ†æ

å®‰è£…ä¾èµ–:
    conda create -n pythonocc python=3.10
    conda activate pythonocc
    conda install -c conda-forge pythonocc-core

å¦‚æœæ— æ³•å®‰è£…pythonOCCï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°æ­£åˆ™è§£ææ¨¡å¼
"""

import re
import json
import math
import sys
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Tuple, Optional, Any, TYPE_CHECKING

# å°è¯•å¯¼å…¥pythonOCC
try:
    from OCC.Core.STEPControl import STEPControl_Reader
    from OCC.Core.STEPCAFControl import STEPCAFControl_Reader
    from OCC.Core.TDocStd import TDocStd_Document
    from OCC.Core.TCollection import TCollection_ExtendedString
    from OCC.Core.BRepAdaptor import BRepAdaptor_Surface
    from OCC.Core.TopExp import TopExp_Explorer
    from OCC.Core.TopAbs import TopAbs_FACE, TopAbs_EDGE, TopAbs_VERTEX
    from OCC.Core.GeomAbs import (
        GeomAbs_Plane, GeomAbs_Cylinder, GeomAbs_Cone,
        GeomAbs_Sphere, GeomAbs_Torus, GeomAbs_BSplineSurface
    )
    from OCC.Core.gp import gp_Trsf, gp_Pnt, gp_Dir, gp_Ax1, gp_Vec
    from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape
    from OCC.Core.XCAFDoc import XCAFDoc_DocumentTool

    PYTHONOCC_AVAILABLE = True
    print("âœ… pythonOCCå·²åŠ è½½ï¼Œä½¿ç”¨ç²¾ç¡®å‡ ä½•åˆ†æ")
except ImportError:
    PYTHONOCC_AVAILABLE = False
    # å®šä¹‰å ä½ç±»å‹é¿å…ç±»å‹é”™è¯¯
    gp_Trsf = Any
    BRepAdaptor_Surface = Any
    print("âš ï¸  pythonOCCæœªå®‰è£…ï¼Œä½¿ç”¨æ­£åˆ™è§£ææ¨¡å¼ï¼ˆç²¾åº¦è¾ƒä½ï¼‰")


class StepAssemblyAnalyzerV2:
    """STEPè£…é…åˆ†æå™¨ - æ”¯æŒpythonOCCå’Œæ­£åˆ™ä¸¤ç§æ¨¡å¼"""

    def __init__(self, use_pythonocc=True):
        self.use_pythonocc = use_pythonocc and PYTHONOCC_AVAILABLE

        # å­˜å‚¨è§£æç»“æœ
        self.parts = []
        self.constraints = []
        self.file_type = 'unknown'

        # æ­£åˆ™æ¨¡å¼çš„æ•°æ®ç»“æ„ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
        self.entities = {}
        self.products = {}
        self.assemblies = []
        self.placements = {}
        self.positions = {}
        self.directions = {}
        self.cylinders = []

    def parse_step_file(self, filepath: str) -> Dict:
        """è§£æSTEPæ–‡ä»¶ - å…¥å£æ–¹æ³•"""
        filename = Path(filepath).name
        print(f"\n{'='*70}")
        print(f"ğŸ“‚ è§£æSTEPæ–‡ä»¶: {filename}")
        print(f"   æ¨¡å¼: {'pythonOCCç²¾ç¡®åˆ†æ' if self.use_pythonocc else 'æ­£åˆ™å¿«é€Ÿè§£æ'}")
        print(f"{'='*70}\n")

        if self.use_pythonocc:
            return self._parse_with_pythonocc(filepath)
        else:
            return self._parse_with_regex(filepath)

    # ==================== pythonOCCç²¾ç¡®è§£æ ====================

    def _parse_with_pythonocc(self, filepath: str) -> Dict:
        """ä½¿ç”¨pythonOCCè¿›è¡Œç²¾ç¡®å‡ ä½•åˆ†æ"""
        try:
            # Step 1: è¯»å–STEPæ–‡ä»¶
            reader = STEPCAFControl_Reader()
            status = reader.ReadFile(filepath)

            if status != 1:  # IFSelect_RetDone
                raise Exception(f"STEPæ–‡ä»¶è¯»å–å¤±è´¥: {filepath}")

            # Step 2: åˆ›å»ºXCAFæ–‡æ¡£ï¼ˆåŒ…å«è£…é…ç»“æ„ï¼‰
            doc = TDocStd_Document(TCollection_ExtendedString('MDTV-XCAF'))
            reader.Transfer(doc)

            # Step 3: è·å–å½¢çŠ¶å’Œé¢œè‰²å·¥å…·
            shape_tool = XCAFDoc_DocumentTool.ShapeTool(doc.Main())

            # Step 4: åˆ¤æ–­æ–‡ä»¶ç±»å‹
            self.file_type = self._identify_file_type_pythonocc(shape_tool)
            print(f"  ğŸ” æ–‡ä»¶ç±»å‹: {self.file_type}")

            # Step 5: éå†è£…é…æ ‘
            if self.file_type == 'assembly':
                self._traverse_assembly_tree(shape_tool, shape_tool.Label())
            else:
                # å•ä¸ªé›¶ä»¶
                shape = shape_tool.GetShape(shape_tool.Label())
                features = self._extract_features_from_shape(shape, gp_Trsf())
                self.parts.append({
                    'part_id': Path(filepath).stem,
                    'file_name': Path(filepath).name,
                    'features': features
                })

            # Step 6: åˆ†æçº¦æŸ
            self._analyze_constraints_pythonocc()

            print(f"\nâœ… pythonOCCè§£æå®Œæˆ:")
            print(f"   é›¶ä»¶æ•°: {len(self.parts)}")
            print(f"   çº¦æŸæ•°: {len(self.constraints)}")

            return self._export_results()

        except Exception as e:
            print(f"âŒ pythonOCCè§£æå¤±è´¥: {e}")
            print("   å›é€€åˆ°æ­£åˆ™è§£ææ¨¡å¼...")
            self.use_pythonocc = False
            return self._parse_with_regex(filepath)

    def _identify_file_type_pythonocc(self, shape_tool) -> str:
        """ä½¿ç”¨pythonOCCåˆ¤æ–­æ–‡ä»¶ç±»å‹"""
        label = shape_tool.Label()

        # æ£€æŸ¥æ˜¯å¦ä¸ºè£…é…ä½“
        if shape_tool.IsAssembly(label):
            return 'assembly'

        # æ£€æŸ¥å­èŠ‚ç‚¹æ•°é‡
        if label.NbChildren() > 1:
            return 'assembly'

        return 'part'

    def _traverse_assembly_tree(self, shape_tool, label, level=0, parent_trsf=None):
        """é€’å½’éå†è£…é…æ ‘ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰"""
        if parent_trsf is None:
            parent_trsf = gp_Trsf()

        # è·å–å½“å‰èŠ‚ç‚¹çš„åç§°
        try:
            from OCC.Core.TDataStd import TDataStd_Name
            name_attr = TDataStd_Name()
            if label.FindAttribute(TDataStd_Name.GetID(), name_attr):
                part_name = name_attr.Get().ToExtString()
            else:
                part_name = f"Part_{label.Tag()}"
        except:
            part_name = f"Part_{label.Tag()}"

        # æ£€æŸ¥æ˜¯å¦ä¸ºè£…é…ä½“
        if shape_tool.IsAssembly(label):
            print(f"  {'  '*level}ğŸ“¦ è£…é…ä½“: {part_name}")

            # éå†å­èŠ‚ç‚¹
            for i in range(1, label.NbChildren() + 1):
                child_label = label.FindChild(i)

                # è·å–å±€éƒ¨å˜æ¢çŸ©é˜µ
                loc = shape_tool.GetLocation(child_label)
                local_trsf = loc.Transformation() if loc else gp_Trsf()

                # è®¡ç®—å…¨å±€å˜æ¢ï¼ˆç´¯ç§¯ï¼‰
                global_trsf = gp_Trsf(parent_trsf)
                global_trsf.Multiply(local_trsf)

                # é€’å½’å¤„ç†å­èŠ‚ç‚¹
                self._traverse_assembly_tree(shape_tool, child_label, level+1, global_trsf)

        else:
            # å¶å­èŠ‚ç‚¹ = é›¶ä»¶
            print(f"  {'  '*level}ğŸ”© é›¶ä»¶: {part_name}")

            shape = shape_tool.GetShape(label)
            if not shape.IsNull():
                # æå–å‡ ä½•ç‰¹å¾ï¼ˆåº”ç”¨å…¨å±€å˜æ¢ï¼‰
                features = self._extract_features_from_shape(shape, parent_trsf)

                self.parts.append({
                    'part_id': part_name,
                    'file_name': part_name,
                    'features': features,
                    'transform': self._trsf_to_dict(parent_trsf)
                })

    def _extract_features_from_shape(self, shape, trsf) -> List[Dict]:
        """ä»å•ä¸ªé›¶ä»¶ä¸­æå–æ‰€æœ‰å‡ ä½•ç‰¹å¾ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰"""
        features = []

        # éå†æ‰€æœ‰é¢
        face_explorer = TopExp_Explorer(shape, TopAbs_FACE)
        face_count = 0

        while face_explorer.More():
            face = face_explorer.Current()
            surf_adaptor = BRepAdaptor_Surface(face)
            surf_type = surf_adaptor.GetType()

            # æ ¹æ®æ›²é¢ç±»å‹æå–ç‰¹å¾
            if surf_type == GeomAbs_Plane:
                feature = self._extract_plane(surf_adaptor, trsf)
                if feature:
                    features.append(feature)

            elif surf_type == GeomAbs_Cylinder:
                feature = self._extract_cylinder(surf_adaptor, trsf)
                if feature:
                    features.append(feature)

            elif surf_type == GeomAbs_Cone:
                feature = self._extract_cone(surf_adaptor, trsf)
                if feature:
                    features.append(feature)

            elif surf_type == GeomAbs_Sphere:
                feature = self._extract_sphere(surf_adaptor, trsf)
                if feature:
                    features.append(feature)

            elif surf_type == GeomAbs_Torus:
                feature = self._extract_torus(surf_adaptor, trsf)
                if feature:
                    features.append(feature)

            face_count += 1
            face_explorer.Next()

        print(f"      æå–ç‰¹å¾: {len(features)} ä¸ªï¼ˆæ¥è‡ª {face_count} ä¸ªé¢ï¼‰")
        return features

    def _extract_plane(self, surf, trsf) -> Optional[Dict]:
        """æå–å¹³é¢ç‰¹å¾"""
        plane = surf.Plane()

        # å±€éƒ¨åæ ‡
        local_pos = plane.Location()
        local_normal = plane.Axis().Direction()

        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡
        world_pos = local_pos.Transformed(trsf)
        world_normal_vec = gp_Vec(local_normal).Transformed(trsf)
        world_normal = gp_Dir(world_normal_vec)

        return {
            'type': 'plane',
            'normal': [world_normal.X(), world_normal.Y(), world_normal.Z()],
            'point': [world_pos.X(), world_pos.Y(), world_pos.Z()],
            'u_range': [surf.FirstUParameter(), surf.LastUParameter()],
            'v_range': [surf.FirstVParameter(), surf.LastVParameter()]
        }

    def _extract_cylinder(self, surf, trsf) -> Optional[Dict]:
        """æå–åœ†æŸ±é¢ç‰¹å¾"""
        cylinder = surf.Cylinder()

        # å±€éƒ¨åæ ‡
        local_axis = cylinder.Axis()
        local_center = local_axis.Location()
        local_direction = local_axis.Direction()
        radius = cylinder.Radius()

        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡
        world_center = local_center.Transformed(trsf)
        world_dir_vec = gp_Vec(local_direction).Transformed(trsf)
        world_direction = gp_Dir(world_dir_vec)

        # åˆ¤æ–­å­”/è½´ï¼ˆå¯å‘å¼ï¼‰
        feature_type = 'hole' if radius < 50.0 else 'shaft'

        return {
            'type': 'cylinder',
            'subtype': feature_type,
            'axis': [world_direction.X(), world_direction.Y(), world_direction.Z()],
            'center': [world_center.X(), world_center.Y(), world_center.Z()],
            'radius': radius,
            'u_range': [surf.FirstUParameter(), surf.LastUParameter()],
            'v_range': [surf.FirstVParameter(), surf.LastVParameter()]
        }

    def _extract_cone(self, surf, trsf) -> Optional[Dict]:
        """æå–åœ†é”¥é¢ç‰¹å¾ï¼ˆèºçº¹ã€å€’è§’å¸¸è§ï¼‰"""
        cone = surf.Cone()

        local_axis = cone.Axis()
        local_apex = cone.Apex()
        local_direction = local_axis.Direction()
        semi_angle = cone.SemiAngle()  # åŠé”¥è§’ï¼ˆå¼§åº¦ï¼‰

        world_apex = local_apex.Transformed(trsf)
        world_dir_vec = gp_Vec(local_direction).Transformed(trsf)
        world_direction = gp_Dir(world_dir_vec)

        return {
            'type': 'cone',
            'axis': [world_direction.X(), world_direction.Y(), world_direction.Z()],
            'apex': [world_apex.X(), world_apex.Y(), world_apex.Z()],
            'semi_angle_deg': math.degrees(semi_angle),
            'u_range': [surf.FirstUParameter(), surf.LastUParameter()],
            'v_range': [surf.FirstVParameter(), surf.LastVParameter()]
        }

    def _extract_sphere(self, surf, trsf) -> Optional[Dict]:
        """æå–çƒé¢ç‰¹å¾"""
        sphere = surf.Sphere()

        local_center = sphere.Location()
        radius = sphere.Radius()

        world_center = local_center.Transformed(trsf)

        return {
            'type': 'sphere',
            'center': [world_center.X(), world_center.Y(), world_center.Z()],
            'radius': radius
        }

    def _extract_torus(self, surf, trsf) -> Optional[Dict]:
        """æå–ç¯é¢ç‰¹å¾ï¼ˆåœ†è§’è¿‡æ¸¡ï¼‰"""
        torus = surf.Torus()

        local_axis = torus.Axis()
        local_center = local_axis.Location()
        local_direction = local_axis.Direction()
        major_radius = torus.MajorRadius()
        minor_radius = torus.MinorRadius()

        world_center = local_center.Transformed(trsf)
        world_dir_vec = gp_Vec(local_direction).Transformed(trsf)
        world_direction = gp_Dir(world_dir_vec)

        return {
            'type': 'torus',
            'axis': [world_direction.X(), world_direction.Y(), world_direction.Z()],
            'center': [world_center.X(), world_center.Y(), world_center.Z()],
            'major_radius': major_radius,
            'minor_radius': minor_radius
        }

    def _analyze_constraints_pythonocc(self):
        """ä½¿ç”¨pythonOCCç²¾ç¡®åˆ†æè£…é…çº¦æŸ"""
        print("\nğŸ” åˆ†æè£…é…çº¦æŸï¼ˆpythonOCCæ¨¡å¼ï¼‰...")

        # éå†æ‰€æœ‰é›¶ä»¶å¯¹
        for i, part_a in enumerate(self.parts):
            for part_b in self.parts[i+1:]:
                # éå†ç‰¹å¾å¯¹
                for feat_a in part_a['features']:
                    for feat_b in part_b['features']:
                        constraint = self._match_constraint_pythonocc(
                            feat_a, feat_b,
                            part_a['part_id'], part_b['part_id']
                        )
                        if constraint:
                            self.constraints.append(constraint)

        print(f"  âœ… è¯†åˆ«çº¦æŸ: {len(self.constraints)}")

    def _match_constraint_pythonocc(self, feat_a: Dict, feat_b: Dict,
                                    part_a_id: str, part_b_id: str) -> Optional[Dict]:
        """ç²¾ç¡®åŒ¹é…ä¸¤ä¸ªç‰¹å¾çš„çº¦æŸå…³ç³»"""

        # Cylinder - Cylinder é…åˆ
        if feat_a['type'] == 'cylinder' and feat_b['type'] == 'cylinder':
            return self._analyze_cylinder_pair(feat_a, feat_b, part_a_id, part_b_id)

        # Plane - Plane é…åˆ
        if feat_a['type'] == 'plane' and feat_b['type'] == 'plane':
            return self._analyze_plane_pair(feat_a, feat_b, part_a_id, part_b_id)

        # Cone - Cylinder é…åˆï¼ˆèºçº¹ï¼‰
        if (feat_a['type'] == 'cone' and feat_b['type'] == 'cylinder') or \
           (feat_a['type'] == 'cylinder' and feat_b['type'] == 'cone'):
            return self._analyze_thread_pair(feat_a, feat_b, part_a_id, part_b_id)

        return None

    def _analyze_cylinder_pair(self, cyl_a: Dict, cyl_b: Dict,
                               part_a: str, part_b: str) -> Optional[Dict]:
        """åˆ†æåœ†æŸ±-åœ†æŸ±é…åˆ"""
        axis_a = cyl_a['axis']
        axis_b = cyl_b['axis']
        center_a = cyl_a['center']
        center_b = cyl_b['center']

        # 1. è®¡ç®—è½´çº¿å¤¹è§’
        dot = sum(a*b for a, b in zip(axis_a, axis_b))
        angle = math.degrees(math.acos(max(-1.0, min(1.0, abs(dot)))))

        # 2. è®¡ç®—è½´å¿ƒè·
        axis_distance = self._point_to_line_distance(center_a, center_b, axis_b)

        # 3. è®¡ç®—ä¸­å¿ƒè·
        center_distance = math.sqrt(sum((a-b)**2 for a, b in zip(center_a, center_b)))

        # åˆ¤æ–­çº¦æŸç±»å‹

        # åŒè½´é…åˆï¼ˆç²¾ç¡®åˆ¤æ–­ï¼‰
        if angle < 2.0 and axis_distance < 0.5:
            return {
                'type': 'CONCENTRIC',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {
                    'axis_distance': round(axis_distance, 3),
                    'angle': round(angle, 2),
                    'radius_a': cyl_a['radius'],
                    'radius_b': cyl_b['radius']
                },
                'reasoning': f'åŒè½´é…åˆï¼šè½´å¿ƒè·{axis_distance:.2f}mmï¼Œè½´çº¿å¤¹è§’{angle:.1f}Â°',
                'confidence': 0.95,
                'source': 'pythonocc'
            }

        # å‚ç›´é…åˆ
        if 88.0 < angle < 92.0 and center_distance < 300:
            return {
                'type': 'PERPENDICULAR',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {
                    'angle': round(angle, 2),
                    'distance': round(center_distance, 2)
                },
                'reasoning': f'å‚ç›´é…åˆï¼šå¤¹è§’{angle:.1f}Â°ï¼Œè·ç¦»{center_distance:.1f}mm',
                'confidence': 0.90,
                'source': 'pythonocc'
            }

        # å¹³è¡Œé…åˆ
        if angle < 5.0 and 10 < axis_distance < 200:
            return {
                'type': 'PARALLEL',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {
                    'axis_distance': round(axis_distance, 2),
                    'angle': round(angle, 2)
                },
                'reasoning': f'å¹³è¡Œé…åˆï¼šè½´è·{axis_distance:.1f}mm',
                'confidence': 0.85,
                'source': 'pythonocc'
            }

        return None

    def _analyze_plane_pair(self, plane_a: Dict, plane_b: Dict,
                           part_a: str, part_b: str) -> Optional[Dict]:
        """åˆ†æå¹³é¢-å¹³é¢é…åˆ"""
        normal_a = plane_a['normal']
        normal_b = plane_b['normal']
        point_a = plane_a['point']
        point_b = plane_b['point']

        # 1. æ³•å‘å¤¹è§’
        dot = sum(a*b for a, b in zip(normal_a, normal_b))
        angle = math.degrees(math.acos(max(-1.0, min(1.0, abs(dot)))))

        # 2. ç‚¹åˆ°å¹³é¢è·ç¦»
        point_dist = abs(sum((point_a[i] - point_b[i]) * normal_b[i] for i in range(3)))

        # é‡åˆ/æ¥è§¦
        if angle < 2.0 and point_dist < 0.1:
            return {
                'type': 'COINCIDENT',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {
                    'angle': round(angle, 2),
                    'distance': round(point_dist, 3)
                },
                'reasoning': f'é¢æ¥è§¦ï¼šæ³•å‘å¤¹è§’{angle:.1f}Â°ï¼Œé—´è·{point_dist:.2f}mm',
                'confidence': 0.95,
                'source': 'pythonocc'
            }

        # å‚ç›´
        if 88.0 < angle < 92.0:
            return {
                'type': 'PERPENDICULAR',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {'angle': round(angle, 2)},
                'reasoning': f'å‚ç›´ï¼šå¤¹è§’{angle:.1f}Â°',
                'confidence': 0.90,
                'source': 'pythonocc'
            }

        return None

    def _analyze_thread_pair(self, feat_a: Dict, feat_b: Dict,
                            part_a: str, part_b: str) -> Optional[Dict]:
        """åˆ†æèºçº¹é…åˆï¼ˆåœ†é”¥+åœ†æŸ±ï¼‰"""
        cone = feat_a if feat_a['type'] == 'cone' else feat_b
        cylinder = feat_b if feat_a['type'] == 'cone' else feat_a

        # æ£€æŸ¥é”¥è§’æ˜¯å¦ç¬¦åˆèºçº¹ç‰¹å¾ï¼ˆ30Â°-60Â°ï¼‰
        semi_angle = cone.get('semi_angle_deg', 0)
        if not (30 < semi_angle < 60):
            return None

        # æ£€æŸ¥è½´çº¿æ˜¯å¦å¯¹é½
        axis_a = cone['axis']
        axis_b = cylinder['axis']
        dot = sum(a*b for a, b in zip(axis_a, axis_b))
        angle = math.degrees(math.acos(max(-1.0, min(1.0, abs(dot)))))

        if angle < 5.0:
            return {
                'type': 'SCREW',
                'part_a': part_a,
                'part_b': part_b,
                'parameters': {
                    'thread_angle': round(semi_angle * 2, 1),
                    'axis_angle': round(angle, 2)
                },
                'reasoning': f'èºçº¹é…åˆï¼šèºçº¹è§’{semi_angle*2:.1f}Â°',
                'confidence': 0.80,
                'source': 'pythonocc'
            }

        return None

    # ==================== æ­£åˆ™è§£æï¼ˆå…¼å®¹æ¨¡å¼ï¼‰ ====================

    def _parse_with_regex(self, filepath: str) -> Dict:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¿«é€Ÿè§£æï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰"""
        filename = Path(filepath).name

        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        # æå–æ‰€æœ‰å®ä½“
        entity_pattern = r'#(\d+)\s*=\s*([A-Z_0-9]+)\s*\((.*?)\);'
        for match in re.finditer(entity_pattern, content, re.DOTALL):
            entity_id = match.group(1)
            entity_type = match.group(2)
            entity_data = match.group(3)
            self.entities[entity_id] = {
                'type': entity_type,
                'data': entity_data
            }

        print(f"  âœ… æå– {len(self.entities)} ä¸ªå®ä½“")

        # è§£æäº§å“
        self._parse_products_regex()

        # è§£æè£…é…å…³ç³»
        self._parse_assemblies_regex()

        # åˆ¤æ–­æ–‡ä»¶ç±»å‹
        self.file_type = self._identify_file_type_regex(filename)
        print(f"  ğŸ” æ–‡ä»¶ç±»å‹: {self.file_type}")

        # è§£æå‡ ä½•
        self._parse_geometry_regex()

        # è§£æåœ†æŸ±é¢
        self._parse_cylinders_regex()

        # è§£æåœ†é”¥é¢ï¼ˆæ–°å¢ï¼‰
        self._parse_cones_regex()

        # åˆ†æçº¦æŸ
        self._analyze_constraints_regex()

        return self._export_results()

    def _identify_file_type_regex(self, filename: str) -> str:
        """æ­£åˆ™æ¨¡å¼ï¼šè¯†åˆ«æ–‡ä»¶ç±»å‹"""
        if filename.startswith('A') and filename[1:].split('.')[0].isdigit():
            return 'assembly'
        elif len(self.assemblies) > 0 or len(self.products) > 1:
            return 'assembly'
        return 'part'

    def _parse_products_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šæå–äº§å“"""
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'PRODUCT':
                name_match = re.search(r"'([^']*)'", entity['data'])
                if name_match:
                    self.products[entity_id] = {
                        'id': entity_id,
                        'name': name_match.group(1)
                    }
        print(f"  ğŸ”¹ äº§å“æ•°é‡: {len(self.products)}")

    def _parse_assemblies_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šæå–è£…é…å…³ç³»"""
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'NEXT_ASSEMBLY_USAGE_OCCURRENCE':
                refs = re.findall(r'#(\d+)', entity['data'])
                if len(refs) >= 2:
                    self.assemblies.append({
                        'id': entity_id,
                        'parent': refs[0],
                        'child': refs[1]
                    })
        print(f"  ğŸ”— è£…é…å…³ç³»: {len(self.assemblies)}")

    def _parse_geometry_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šè§£æå‡ ä½•"""
        # è§£æåæ ‡ç‚¹
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'CARTESIAN_POINT':
                coords = re.findall(r'([-+]?\d*\.?\d+(?:[Ee][-+]?\d+)?)', entity['data'])
                coords = [c for c in coords if c]
                if len(coords) >= 3:
                    try:
                        self.positions[entity_id] = [float(coords[0]), float(coords[1]), float(coords[2])]
                    except ValueError:
                        pass

        # è§£ææ–¹å‘å‘é‡
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'DIRECTION':
                coords = re.findall(r'([-+]?\d*\.?\d+(?:[Ee][-+]?\d+)?)', entity['data'])
                coords = [c for c in coords if c]
                if len(coords) >= 3:
                    try:
                        self.directions[entity_id] = [float(coords[0]), float(coords[1]), float(coords[2])]
                    except ValueError:
                        pass

        # è§£æAXIS2_PLACEMENT_3D
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'AXIS2_PLACEMENT_3D':
                refs = re.findall(r'#(\d+)', entity['data'])
                if len(refs) >= 1:
                    placement = {'id': entity_id}
                    if refs[0] in self.positions:
                        placement['position'] = self.positions[refs[0]]
                    if len(refs) >= 2 and refs[1] in self.directions:
                        placement['z_axis'] = self.directions[refs[1]]
                    if len(refs) >= 3 and refs[2] in self.directions:
                        placement['x_axis'] = self.directions[refs[2]]
                    if 'position' in placement:
                        self.placements[entity_id] = placement

        print(f"  ğŸ“ ä½ç½®æ•°æ®: {len(self.positions)}")
        print(f"  ğŸ¯ ç©ºé—´å˜æ¢: {len(self.placements)}")

    def _parse_cylinders_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šæå–åœ†æŸ±é¢"""
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'CYLINDRICAL_SURFACE':
                refs = re.findall(r'#(\d+)', entity['data'])
                if refs:
                    placement_id = refs[0]
                    radius_match = re.search(r',\s*([\d.E+-]+)\s*\)', entity['data'])
                    radius = float(radius_match.group(1)) if radius_match else None

                    if placement_id in self.placements and radius:
                        self.cylinders.append({
                            'id': entity_id,
                            'placement': self.placements[placement_id],
                            'radius': radius,
                            'type': 'hole' if radius < 50 else 'shaft'
                        })
        print(f"  ğŸ•³ï¸  åœ†æŸ±ç‰¹å¾: {len(self.cylinders)}")

    def _parse_cones_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šæå–åœ†é”¥é¢ï¼ˆæ–°å¢ï¼‰"""
        cone_count = 0
        for entity_id, entity in self.entities.items():
            if entity['type'] == 'CONICAL_SURFACE':
                refs = re.findall(r'#(\d+)', entity['data'])
                radius_angle_match = re.findall(r'([\d.E+-]+)', entity['data'])

                if refs and len(radius_angle_match) >= 2:
                    placement_id = refs[0]
                    try:
                        radius = float(radius_angle_match[-2])
                        semi_angle = float(radius_angle_match[-1])

                        if placement_id in self.placements:
                            # æ·»åŠ åˆ°åœ†æŸ±åˆ—è¡¨ï¼ˆä¸´æ—¶ï¼‰
                            self.cylinders.append({
                                'id': entity_id,
                                'placement': self.placements[placement_id],
                                'radius': radius,
                                'semi_angle': semi_angle,
                                'type': 'cone'
                            })
                            cone_count += 1
                    except (ValueError, IndexError):
                        pass
        print(f"  ğŸ”º åœ†é”¥ç‰¹å¾: {cone_count}")

    def _analyze_constraints_regex(self):
        """æ­£åˆ™æ¨¡å¼ï¼šåˆ†æçº¦æŸ"""
        print("\nğŸ” åˆ†æè£…é…çº¦æŸï¼ˆæ­£åˆ™æ¨¡å¼ï¼‰...")

        placements_list = list(self.placements.values())

        # 1. è½´å‘é…åˆ
        for i, p1 in enumerate(placements_list):
            for p2 in placements_list[i+1:]:
                constraint = self._analyze_mate_type_regex(p1, p2)
                if constraint:
                    self.constraints.append(constraint)

        # 2. å­”å¯¹å­”çº¦æŸ
        for i, c1 in enumerate(self.cylinders):
            for c2 in self.cylinders[i+1:]:
                constraint = self._analyze_hole_constraint_regex(c1, c2)
                if constraint:
                    self.constraints.append(constraint)

        print(f"  âœ… è¯†åˆ«çº¦æŸ: {len(self.constraints)}")

    def _analyze_mate_type_regex(self, p1: Dict, p2: Dict) -> Optional[Dict]:
        """æ­£åˆ™æ¨¡å¼ï¼šåˆ†æé…åˆç±»å‹"""
        if 'z_axis' not in p1 or 'z_axis' not in p2:
            return None
        if 'position' not in p1 or 'position' not in p2:
            return None

        z1 = p1['z_axis']
        z2 = p2['z_axis']
        pos1 = p1['position']
        pos2 = p2['position']

        dot = sum(a*b for a, b in zip(z1, z2))
        angle = math.degrees(math.acos(max(-1.0, min(1.0, dot))))
        distance = math.sqrt(sum((a-b)**2 for a, b in zip(pos1, pos2)))

        if distance > 300:
            return None

        mate_type = None
        if angle < 5 or angle > 175:
            mate_type = 'CONCENTRIC'
        elif 85 < angle < 95:
            mate_type = 'PERPENDICULAR'
        else:
            mate_type = f'ANGLE_{int(angle)}'

        return {
            'type': mate_type,
            'part_a': f'Placement#{p1["id"]}',
            'part_b': f'Placement#{p2["id"]}',
            'parameters': {
                'distance': round(distance, 2),
                'angle': round(angle, 2)
            },
            'reasoning': f'{mate_type}é…åˆï¼ˆè·ç¦»{distance:.1f}mmï¼‰',
            'confidence': 0.6,
            'source': 'regex'
        }

    def _analyze_hole_constraint_regex(self, c1: Dict, c2: Dict) -> Optional[Dict]:
        """æ­£åˆ™æ¨¡å¼ï¼šå­”-å­”çº¦æŸ"""
        p1 = c1['placement']
        p2 = c2['placement']

        if 'position' not in p1 or 'position' not in p2:
            return None

        pos1 = p1['position']
        pos2 = p2['position']
        distance = math.sqrt(sum((a-b)**2 for a, b in zip(pos1, pos2)))

        if distance < 200:
            return {
                'type': 'HOLE_SPACING',
                'part_a': f'Hole#{c1["id"]}',
                'part_b': f'Hole#{c2["id"]}',
                'parameters': {
                    'distance': round(distance, 2),
                    'radius1': c1['radius'],
                    'radius2': c2['radius']
                },
                'reasoning': f'å­”é—´è·çº¦æŸï¼ˆ{distance:.1f}mmï¼‰',
                'confidence': 0.8,
                'source': 'regex'
            }

        return None

    # ==================== å·¥å…·æ–¹æ³• ====================

    def _trsf_to_dict(self, trsf) -> Dict:
        """å˜æ¢çŸ©é˜µè½¬å­—å…¸"""
        return {
            'translation': [
                trsf.TranslationPart().X(),
                trsf.TranslationPart().Y(),
                trsf.TranslationPart().Z()
            ],
            'rotation': [
                [trsf.Value(i, j) for j in range(1, 4)]
                for i in range(1, 4)
            ]
        }

    def _point_to_line_distance(self, point: List[float], line_point: List[float],
                                line_dir: List[float]) -> float:
        """ç‚¹åˆ°ç›´çº¿çš„è·ç¦»"""
        # å‘é‡ point - line_point
        vec = [point[i] - line_point[i] for i in range(3)]

        # æŠ•å½±é•¿åº¦
        proj_length = sum(vec[i] * line_dir[i] for i in range(3))

        # æŠ•å½±ç‚¹
        proj_point = [line_point[i] + proj_length * line_dir[i] for i in range(3)]

        # è·ç¦»
        return math.sqrt(sum((point[i] - proj_point[i])**2 for i in range(3)))

    def _export_results(self) -> Dict:
        """å¯¼å‡ºåˆ†æç»“æœ"""
        if self.use_pythonocc:
            # pythonOCCæ¨¡å¼
            return {
                'file_type': self.file_type,
                'parser_mode': 'pythonocc',
                'metadata': {
                    'parts_count': len(self.parts),
                    'constraints_count': len(self.constraints),
                    'total_features': sum(len(p['features']) for p in self.parts)
                },
                'parts': self.parts,
                'constraints': self.constraints
            }
        else:
            # æ­£åˆ™æ¨¡å¼
            return {
                'file_type': self.file_type,
                'parser_mode': 'regex',
                'metadata': {
                    'products_count': len(self.products),
                    'assemblies_count': len(self.assemblies),
                    'placements_count': len(self.placements),
                    'cylinders_count': len(self.cylinders),
                    'constraints_count': len(self.constraints)
                },
                'products': list(self.products.values()),
                'assemblies': self.assemblies,
                'cylinders': [{
                    'id': c['id'],
                    'type': c['type'],
                    'radius': c['radius'],
                    'position': c['placement'].get('position'),
                    'axis': c['placement'].get('z_axis')
                } for c in self.cylinders],
                'constraints': self.constraints
            }


def main():
    if len(sys.argv) < 2:
        print("Usage: python step_assembly_analyzer_v2.py <step_file> [output_json] [--regex]")
        print("\né€‰é¡¹:")
        print("  --regex    å¼ºåˆ¶ä½¿ç”¨æ­£åˆ™è§£ææ¨¡å¼ï¼ˆå³ä½¿pythonOCCå¯ç”¨ï¼‰")
        sys.exit(1)

    step_file = sys.argv[1]
    output_file = None
    use_pythonocc = True

    # è§£æå‚æ•°
    for arg in sys.argv[2:]:
        if arg == '--regex':
            use_pythonocc = False
        elif not output_file:
            output_file = arg

    if not output_file:
        output_file = Path(step_file).stem + '_analysis.json'

    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘          STEPè£…é…æ™ºèƒ½åˆ†æå™¨ V2.0                               â•‘")
    print("â•‘          pythonOCCç²¾ç¡®åˆ†æ + æ­£åˆ™å¿«é€Ÿè§£æ                      â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

    analyzer = StepAssemblyAnalyzerV2(use_pythonocc=use_pythonocc)
    results = analyzer.parse_step_file(step_file)

    # è¾“å‡ºç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ç»“æœå·²å¯¼å‡º: {output_file}")
    print(f"   æ–‡ä»¶å¤§å°: {Path(output_file).stat().st_size / 1024:.1f} KB")

    print("\nğŸ“Š åˆ†ææ‘˜è¦:")
    print(f"  è§£ææ¨¡å¼: {results['parser_mode']}")
    print(f"  æ–‡ä»¶ç±»å‹: {results['file_type']}")
    if results['parser_mode'] == 'pythonocc':
        print(f"  é›¶ä»¶æ•°: {results['metadata']['parts_count']}")
        print(f"  æ€»ç‰¹å¾æ•°: {results['metadata']['total_features']}")
    else:
        print(f"  äº§å“æ•°: {results['metadata']['products_count']}")
        print(f"  è£…é…å…³ç³»: {results['metadata']['assemblies_count']}")
    print(f"  çº¦æŸæ•°: {results['metadata']['constraints_count']}")


if __name__ == '__main__':
    main()
