#!/usr/bin/env python3
"""
æ‰¹é‡STEPæ–‡ä»¶åˆ†æè„šæœ¬
éå†ç›®å½•ä¸­çš„æ‰€æœ‰STEPæ–‡ä»¶ï¼Œæå–å‡ ä½•ç‰¹å¾å’Œè£…é…çº¦æŸï¼Œå¹¶å­¦ä¹ è§„åˆ™
"""

import os
import json
import sys
from pathlib import Path
from datetime import datetime
from step_assembly_analyzer_v2 import StepAssemblyAnalyzerV2
sys.path.append(str(Path(__file__).parent / 'assembly'))
from ConstraintRuleLearner import ConstraintRuleLearner


class BatchStepAnalyzer:
    """æ‰¹é‡STEPæ–‡ä»¶åˆ†æå™¨"""

    def __init__(self, use_pythonocc=True):
        self.use_pythonocc = use_pythonocc
        self.results = []
        self.all_constraints = []
        self.statistics = {
            'total_files': 0,
            'assembly_files': 0,
            'part_files': 0,
            'total_parts': 0,
            'total_constraints': 0,
            'failed_files': []
        }

    def process_directory(self, directory_path: str, output_dir: str = None):
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„STEPæ–‡ä»¶"""
        directory = Path(directory_path)

        if not directory.exists():
            print(f"\nâŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
            return

        # æŸ¥æ‰¾æ‰€æœ‰STEPæ–‡ä»¶
        step_extensions = {'.step', '.stp', '.STEP', '.STP'}
        step_files = [
            f for f in directory.iterdir()
            if f.is_file() and f.suffix in step_extensions
        ]

        if not step_files:
            print(f"\nâš ï¸  ç›®å½•ä¸­æ²¡æœ‰STEPæ–‡ä»¶: {directory}")
            return

        print(f"\n{'='*70}")
        print(f"ğŸ” æ‰«æç›®å½•: {directory}")
        print(f"ğŸ“¦ æ‰¾åˆ° {len(step_files)} ä¸ªSTEPæ–‡ä»¶")
        print(f"{'='*70}\n")

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = directory / 'analysis_results'
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        # æ‰¹é‡å¤„ç†
        for i, step_file in enumerate(step_files, 1):
            print(f"\n[{i}/{len(step_files)}] å¤„ç†: {step_file.name}")
            print(f"   å¤§å°: {step_file.stat().st_size / 1024:.1f} KB")

            try:
                # åˆ›å»ºåˆ†æå™¨
                analyzer = StepAssemblyAnalyzerV2(use_pythonocc=self.use_pythonocc)

                # è§£ææ–‡ä»¶
                result = analyzer.parse_step_file(str(step_file))

                # ä¿å­˜å•ä¸ªæ–‡ä»¶ç»“æœ
                output_file = output_dir / f"{step_file.stem}_analysis.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)

                # ç»Ÿè®¡
                self.statistics['total_files'] += 1
                if result['file_type'] == 'assembly':
                    self.statistics['assembly_files'] += 1
                else:
                    self.statistics['part_files'] += 1

                if result['parser_mode'] == 'pythonocc':
                    self.statistics['total_parts'] += result['metadata']['parts_count']
                    self.statistics['total_constraints'] += result['metadata']['constraints_count']
                    # æ”¶é›†çº¦æŸç”¨äºå­¦ä¹ 
                    self.all_constraints.extend(result.get('constraints', []))
                else:
                    self.statistics['total_parts'] += result['metadata']['products_count']
                    self.statistics['total_constraints'] += result['metadata']['constraints_count']
                    self.all_constraints.extend(result.get('constraints', []))

                self.results.append({
                    'file_name': step_file.name,
                    'file_type': result['file_type'],
                    'parser_mode': result['parser_mode'],
                    'metadata': result['metadata'],
                    'output_file': str(output_file)
                })

                print(f"   âœ… å®Œæˆ")

            except Exception as e:
                print(f"   âŒ å¤±è´¥: {e}")
                self.statistics['failed_files'].append({
                    'file_name': step_file.name,
                    'error': str(e)
                })

        print(f"\n{'='*70}")
        print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"{'='*70}\n")

        # æ‰“å°ç»Ÿè®¡
        self.print_summary()

        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_file = output_dir / 'batch_summary.json'
        self.save_summary(summary_file)

        return output_dir

    def learn_rules(self, output_dir: Path):
        """ä»æ‰€æœ‰çº¦æŸä¸­å­¦ä¹ è§„åˆ™"""
        if not self.all_constraints:
            print("\nâš ï¸  æ²¡æœ‰çº¦æŸæ•°æ®ï¼Œè·³è¿‡è§„åˆ™å­¦ä¹ ")
            return None

        print(f"\n{'='*70}")
        print(f"ğŸ§  å¼€å§‹è§„åˆ™å­¦ä¹ ...")
        print(f"   çº¦æŸæ€»æ•°: {len(self.all_constraints)}")
        print(f"{'='*70}\n")

        # æ„å»ºfeatures_jsonæ ¼å¼
        features_json = {
            'parts': []
        }

        # ä»çº¦æŸä¸­æå–é›¶ä»¶ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        parts_map = {}
        for constraint in self.all_constraints:
            part_a = constraint.get('part_a', '')
            part_b = constraint.get('part_b', '')

            if part_a and part_a not in parts_map:
                parts_map[part_a] = {'part_id': part_a, 'features': []}
            if part_b and part_b not in parts_map:
                parts_map[part_b] = {'part_id': part_b, 'features': []}

        features_json['parts'] = list(parts_map.values())

        # åˆ›å»ºè§„åˆ™å­¦ä¹ å™¨
        learner = ConstraintRuleLearner()

        # ç›´æ¥ä½¿ç”¨çº¦æŸå­¦ä¹ ï¼ˆè·³è¿‡ç‰¹å¾åŒ¹é…ï¼‰
        learner._learn_rules_from_constraints(self.all_constraints)

        # å¯¼å‡ºè§„åˆ™
        rules_file = output_dir / 'learned_rules.json'
        learner.export_rules(str(rules_file))

        print(f"âœ… è§„åˆ™å­¦ä¹ å®Œæˆ: {len(learner.rules_db)} æ¡è§„åˆ™")

        return rules_file

    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        stats = self.statistics

        print("ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"  è£…é…æ–‡ä»¶: {stats['assembly_files']}")
        print(f"  é›¶ä»¶æ–‡ä»¶: {stats['part_files']}")
        print(f"  å¤±è´¥æ–‡ä»¶: {len(stats['failed_files'])}")
        print(f"\n  æ€»é›¶ä»¶æ•°: {stats['total_parts']}")
        print(f"  æ€»çº¦æŸæ•°: {stats['total_constraints']}")

        if stats['failed_files']:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶:")
            for failed in stats['failed_files']:
                print(f"  - {failed['file_name']}: {failed['error']}")

    def save_summary(self, output_file: Path):
        """ä¿å­˜æ±‡æ€»ç»“æœ"""
        summary = {
            'generated_at': datetime.now().isoformat(),
            'statistics': self.statistics,
            'files': self.results
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: {output_file}")
        print(f"   æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB")


def main():
    if len(sys.argv) < 2:
        print("Usage: python batch_analyze_step_files.py <directory> [output_dir] [--regex] [--learn]")
        print("\né€‰é¡¹:")
        print("  --regex    å¼ºåˆ¶ä½¿ç”¨æ­£åˆ™è§£ææ¨¡å¼")
        print("  --learn    å­¦ä¹ è£…é…è§„åˆ™")
        print("\nç¤ºä¾‹:")
        print("  python batch_analyze_step_files.py docs/solidworks/")
        print("  python batch_analyze_step_files.py docs/solidworks/ /tmp/results --learn")
        sys.exit(1)

    directory = sys.argv[1]
    output_dir = None
    use_pythonocc = True
    learn_rules = False

    # è§£æå‚æ•°
    for arg in sys.argv[2:]:
        if arg == '--regex':
            use_pythonocc = False
        elif arg == '--learn':
            learn_rules = True
        elif not output_dir and not arg.startswith('--'):
            output_dir = arg

    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘          æ‰¹é‡STEPæ–‡ä»¶åˆ†æå™¨ v2.0                               â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    # åˆ›å»ºæ‰¹é‡åˆ†æå™¨
    batch_analyzer = BatchStepAnalyzer(use_pythonocc=use_pythonocc)

    # å¤„ç†ç›®å½•
    result_dir = batch_analyzer.process_directory(directory, output_dir)

    # å­¦ä¹ è§„åˆ™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if learn_rules and result_dir:
        batch_analyzer.learn_rules(result_dir)

    print(f"\nğŸ‰ å®Œæˆ!")


if __name__ == '__main__':
    main()
