const xlsx = require('xlsx')
const { v4: uuidv4 } = require('uuid')
const llmService = require('../llm/UnifiedLLMService')
const { loadRulesFromDatabase, evaluateCondition, generateAction, generateReasoning } = require('./_rule_helpers')

/**
 * è£…é…çº¦æŸæ¨ç†æœåŠ¡ (MVP - P0é˜¶æ®µ)
 * åŸºäºè§„åˆ™çš„ç®€å•æ¨ç† + å¯é€‰LLMå¢å¼º
 */
class AssemblyReasoningService {
  constructor() {
    this.llmService = llmService
    this.rulesCache = null
    this.rulesCacheTime = 0
    this.CACHE_TTL = 5 * 60 * 1000 // 5åˆ†é’Ÿç¼“å­˜

    // æ ‡å‡†ä»¶åº“ (ç®€åŒ–ç‰ˆ - å®é™…åº”ä»æ•°æ®åº“åŠ è½½)
    this.standardParts = {
      'VCR-4-VS-2': { type: 'VCRæ¥å¤´', thread: 'M12x1.5', sealing: 'VCRé‡‘å±å¯†å°', manufacturer: 'Swagelok' },
      'SS-4-TA-7': { type: 'Swagelokå¡å¥—æ¥å¤´', thread: '1/4"NPT', sealing: 'å¡å¥—å¯†å°', manufacturer: 'Swagelok' },
      'VCR-6-VS-6': { type: 'VCRæ¥å¤´', thread: 'M16x2.0', sealing: 'VCRé‡‘å±å¯†å°', manufacturer: 'Swagelok' },
      'GB/T 70.1-M8': { type: 'å…­è§’å¤´èºæ “', thread: 'M8x1.25', standard: 'GB/T 70.1' },
      'GB/T 6170-M8': { type: 'å…­è§’èºæ¯', thread: 'M8x1.25', standard: 'GB/T 6170' }
    }

    // è£…é…è§„åˆ™åº“ (P0é˜¶æ®µæ ¸å¿ƒ)
    this.rules = [
      {
        id: 'R1',
        name: 'VCRæ¥å¤´åŒè½´çº¦æŸ',
        priority: 10,
        condition: (partA, partB) => {
          return partA.type === 'VCRæ¥å¤´' && partB.type === 'VCRæ¥å¤´'
        },
        action: (partA, partB) => ({
          type: 'CONCENTRIC',
          entities: [partA.name, partB.name],
          parameters: { alignment: 'ALIGNED' },
          reasoning: `${partA.name} å’Œ ${partB.name} å‡ä¸ºVCRæ¥å¤´ï¼Œéœ€è¦åŒè½´é…åˆä»¥ç¡®ä¿é‡‘å±å¯†å°é¢æ¥è§¦`
        })
      },
      {
        id: 'R2',
        name: 'èºçº¹è¿æ¥çº¦æŸ',
        priority: 9,
        condition: (partA, partB) => {
          return partA.thread && partB.thread && this._isThreadCompatible(partA.thread, partB.thread)
        },
        action: (partA, partB) => {
          const pitch = this._extractThreadPitch(partA.thread)
          return {
            type: 'SCREW',
            entities: [partA.name, partB.name],
            parameters: {
              pitch: pitch,
              revolutions: 5,
              direction: 'RIGHT_HAND'
            },
            reasoning: `æ£€æµ‹åˆ°èºçº¹è§„æ ¼ ${partA.thread} å’Œ ${partB.thread} å…¼å®¹ï¼Œè‡ªåŠ¨ç”Ÿæˆèºçº¹é…åˆçº¦æŸ`
          }
        }
      },
      {
        id: 'R3',
        name: 'æ³•å…°é¢æ¥è§¦çº¦æŸ',
        priority: 8,
        condition: (partA, partB) => {
          return (partA.name.includes('æ³•å…°') || partA.type?.includes('æ³•å…°')) &&
                 (partB.name.includes('æ³•å…°') || partB.type?.includes('æ³•å…°'))
        },
        action: (partA, partB) => ({
          type: 'COINCIDENT',
          entities: [`${partA.name}/Face1`, `${partB.name}/Face1`],
          parameters: { alignment: 'ALIGNED', flip: false },
          reasoning: `${partA.name} å’Œ ${partB.name} æ³•å…°é¢éœ€è¦é‡åˆæ¥è§¦`
        })
      },
      {
        id: 'R4',
        name: 'èºæ “-èºæ¯é…å¯¹',
        priority: 10,
        condition: (partA, partB) => {
          const isBoltNutPair =
            (partA.type?.includes('èºæ “') && partB.type?.includes('èºæ¯')) ||
            (partA.type?.includes('èºæ¯') && partB.type?.includes('èºæ “'))

          return isBoltNutPair && partA.thread === partB.thread
        },
        action: (partA, partB) => ({
          type: 'SCREW',
          entities: [partA.name, partB.name],
          parameters: {
            pitch: this._extractThreadPitch(partA.thread),
            revolutions: 8
          },
          reasoning: `èºæ “ ${partA.name} ä¸èºæ¯ ${partB.name} èºçº¹è§„æ ¼åŒ¹é… (${partA.thread})ï¼Œç”Ÿæˆèºçº¹å‰¯çº¦æŸ`
        })
      },
      {
        id: 'R5',
        name: 'å¡å¥—æ¥å¤´é…å¯¹',
        priority: 9,
        condition: (partA, partB) => {
          return partA.type?.includes('å¡å¥—') && partB.type?.includes('å¡å¥—')
        },
        action: (partA, partB) => ({
          type: 'CONCENTRIC',
          entities: [partA.name, partB.name],
          parameters: { alignment: 'ALIGNED' },
          reasoning: `å¡å¥—æ¥å¤´ ${partA.name} å’Œ ${partB.name} éœ€è¦åŒè½´é…åˆ`
        })
      }
    ]
  }

  /**
   * æ¨ç†è£…é…çº¦æŸ (P1é˜¶æ®µå®ç° + æ•°æ®åº“æŒä¹…åŒ– + scipyæ±‚è§£)
   */
  async inferConstraints(bomBuffer, drawingFiles, userId, userName = '') {
    const db = require('../../config/database')
    const axios = require('axios')
    const solverUrl = process.env.ASSEMBLY_SOLVER_URL || 'http://localhost:8002'

    // 1. åˆ›å»ºæ¨ç†ä»»åŠ¡è®°å½•
    const result = await db('assembly_inference_tasks').insert({
      user_id: userId,
      status: 'processing',
      bom_file_path: 'uploaded.xlsx'
    }).returning('id')

    const taskId = typeof result[0] === 'object' ? result[0].id : result[0]
    const reasoningPath = []

    try {
      console.log(`[æ¨¡å—1-æ ·æœ¬è¾“å…¥] ğŸš€ å¼€å§‹å­¦ä¹  (ä»»åŠ¡ID: ${taskId})`)

      // 2. è§£æBOMï¼ˆå¦‚æœæœ‰ï¼‰
      let parts = []
      if (bomBuffer) {
        parts = this._parseBOM(bomBuffer)
        console.log(`[æ¨¡å—1] è§£æBOM: ${parts.length}ä¸ªé›¶ä»¶`)
        reasoningPath.push(`æ¨¡å—1-æ ·æœ¬è¾“å…¥: è§£æBOMï¼Œè¯†åˆ«${parts.length}ä¸ªé›¶ä»¶`)
      } else {
        console.log(`[æ¨¡å—1] æœªä¸Šä¼ BOMï¼Œå°†ä»STEPæ–‡ä»¶æå–é›¶ä»¶ä¿¡æ¯`)
        reasoningPath.push(`æ¨¡å—1-æ ·æœ¬è¾“å…¥: æœªä¸Šä¼ BOMï¼Œä»STEPæå–é›¶ä»¶`)
      }

      // 3. è§£æSTEPæ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
      const stepFiles = drawingFiles.filter(f =>
        f.name.toLowerCase().endsWith('.step') ||
        f.name.toLowerCase().endsWith('.stp')
      )

      let stepConstraints = []
      let stepParts = []
      if (stepFiles.length > 0) {
        console.log(`[æ¨¡å—2-çº¦æŸå­¦ä¹ ] ğŸ—ï¸ è§£æ${stepFiles.length}ä¸ªSTEPæ–‡ä»¶...`)
        reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : è§£æ${stepFiles.length}ä¸ªSTEPæ–‡ä»¶`)

        try {
          const result = await this._parseStepFiles(stepFiles, taskId)
          stepConstraints = result.constraints
          stepParts = result.parts

          console.log(`[æ¨¡å—2] STEPè§£æå®Œæˆ:`)
          console.log(`  - è£…é…å›¾: ${result.assemblyFiles.length}ä¸ª`)
          console.log(`  - é›¶ä»¶å›¾: ${result.partFiles.length}ä¸ª`)
          console.log(`  - æå–çº¦æŸ: ${stepConstraints.length}ä¸ª`)
          console.log(`  - æå–é›¶ä»¶ç‰¹å¾: ${stepParts.length}ä¸ª`)

          reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : STEPè§£æ(è£…é…${result.assemblyFiles.length}ä¸ª,é›¶ä»¶${result.partFiles.length}ä¸ª)`)
          reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : æå–${stepConstraints.length}ä¸ªå‡ ä½•çº¦æŸ + ${stepParts.length}ä¸ªé›¶ä»¶ç‰¹å¾`)

          // å¦‚æœæ²¡æœ‰BOMï¼Œä½¿ç”¨STEPä¸­çš„é›¶ä»¶ä¿¡æ¯
          if (!bomBuffer && stepParts.length > 0) {
            parts = stepParts.map(sp => ({
              partNumber: sp.part_number || sp.file_name.replace(/\.(step|stp)$/i, ''),
              name: sp.file_name,
              quantity: 1,
              specification: '',
              has_holes: sp.has_holes,
              has_shafts: sp.has_shafts
            }))
            console.log(`[æ¨¡å—2] ä»STEPæå–${parts.length}ä¸ªé›¶ä»¶`)
            reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : ä»STEPæå–${parts.length}ä¸ªé›¶ä»¶ä¿¡æ¯`)
          }
        } catch (stepError) {
          console.warn('[æ¨¡å—2] STEPè§£æå¤±è´¥:', stepError.message)
          reasoningPath.push('æ¨¡å—2-çº¦æŸå­¦ä¹ : STEPè§£æå¤±è´¥(è·³è¿‡)')
        }
      }

      // 4. è¯†åˆ«æ ‡å‡†ä»¶å¹¶è¡¥å……çŸ¥è¯†
      let enrichedParts = parts.map(part => ({
        ...part,
        ...this._lookupStandardPart(part.partNumber)
      }))

      reasoningPath.push(`æ¨¡å—3-çŸ¥è¯†å¢å¼º: æ ‡å‡†ä»¶åŒ¹é…${enrichedParts.filter(p => p.type).length}ä¸ª`)

      // 4. LLMå¢å¼ºï¼šç†è§£é›¶ä»¶æè¿°ï¼Œæå–ç‰¹å¾
      // âœ… é»˜è®¤å¯ç”¨LLMï¼Œé™¤éæ˜ç¡®è®¾ç½®ä¸ºfalse
      const useLLM = process.env.ASSEMBLY_USE_LLM !== 'false'
      const DEMO_MODE = process.env.ASSEMBLY_DEMO_MODE === 'true'  // ğŸ­ æ¼”ç¤ºæ¨¡å¼
      const hasUnrecognizedParts = enrichedParts.some(p => !p.type || !p.thread)

      if (DEMO_MODE) {
        console.log('[æ¨¡å—2-çº¦æŸå­¦ä¹ ] ğŸ­ æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡AIåˆ†æ')
        reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : æ¼”ç¤ºæ¨¡å¼(è·³è¿‡AIåˆ†æ)`)
      } else if (useLLM && hasUnrecognizedParts) {
        console.log('[æ¨¡å—2-çº¦æŸå­¦ä¹ ] ğŸ¤– AIåˆ†ææœªè¯†åˆ«é›¶ä»¶...')
        reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : AIåˆ†æ${enrichedParts.filter(p => !p.type).length}ä¸ªæœªè¯†åˆ«é›¶ä»¶`)
        try {
          enrichedParts = await this._enrichPartsWithLLM(enrichedParts)
        } catch (llmError) {
          console.warn('[æ¨¡å—2] LLMå¤±è´¥:', llmError.message)
        }
      } else {
        reasoningPath.push('æ¨¡å—2-çº¦æŸå­¦ä¹ : è·³è¿‡AIåˆ†æ(æ‰€æœ‰é›¶ä»¶å·²è¯†åˆ«)')
      }

      console.log(`[æ¨¡å—2] é›¶ä»¶è¯†åˆ«: ${enrichedParts.filter(p => p.type).length}/${enrichedParts.length}`)

      // 5. ä»æ•°æ®åº“åŠ è½½è§„åˆ™
      const dbRules = await loadRulesFromDatabase()
      console.log(`[æ¨¡å—3-è§„åˆ™æ¨ç†] ğŸ“š åŠ è½½${dbRules.length}æ¡è§„åˆ™`)
      reasoningPath.push(`æ¨¡å—3-è§„åˆ™æ¨ç†: åŠ è½½${dbRules.length}æ¡å·²æœ‰è§„åˆ™`)

      // 6. åŸºäºè§„åˆ™æ¨ç†çº¦æŸ
      const constraints = []

      if (DEMO_MODE && enrichedParts.length >= 2) {
        // ğŸ­ æ¼”ç¤ºæ¨¡å¼ï¼šå¿«é€Ÿç”Ÿæˆé¢„è®¾çº¦æŸ
        console.log('[æ¨¡å—3-è§„åˆ™æ¨ç†] ğŸ­ æ¼”ç¤ºæ¨¡å¼ï¼šç”Ÿæˆé¢„è®¾çº¦æŸ')
        reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: æ¼”ç¤ºæ¨¡å¼ï¼Œç”Ÿæˆç¤ºä¾‹çº¦æŸ')

        for (let i = 0; i < Math.min(enrichedParts.length - 1, 10); i++) {
          const partA = enrichedParts[i]
          const partB = enrichedParts[i + 1]

          const constraintTypes = ['CONCENTRIC', 'COINCIDENT', 'PARALLEL', 'SCREW']
          const type = constraintTypes[i % constraintTypes.length]

          constraints.push({
            id: uuidv4(),
            type,
            part_a: partA.name || partA.partNumber,
            part_b: partB.name || partB.partNumber,
            part_number_a: partA.partNumber,
            part_number_b: partB.partNumber,
            entities: [partA.name || partA.partNumber, partB.name || partB.partNumber],
            parameters: type === 'CONCENTRIC' ? { alignment: 'ALIGNED' } :
                       type === 'SCREW' ? { pitch: 1.5, revolutions: 5 } : {},
            reasoning: `æ¼”ç¤ºçº¦æŸï¼š${partA.name || partA.partNumber} ä¸ ${partB.name || partB.partNumber} ${type}é…åˆ`,
            confidence: 0.75 + Math.random() * 0.2,
            ruleId: `DEMO_${type}_${i}`
          })
        }

        console.log(`[æ¨¡å—3] ğŸ­ æ¼”ç¤ºæ¨¡å¼ç”Ÿæˆäº† ${constraints.length} ä¸ªçº¦æŸ`)
      } else {
        // æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨çœŸå®è§„åˆ™æ¨ç†
        for (let i = 0; i < enrichedParts.length - 1; i++) {
          for (let j = i + 1; j < enrichedParts.length; j++) {
            const partA = enrichedParts[i]
            const partB = enrichedParts[j]

            // å°è¯•åŒ¹é…è§„åˆ™ï¼ˆå·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            for (const rule of dbRules) {
            // è§£æJSON condition_logic
            const conditionLogic = typeof rule.condition_logic === 'string'
              ? JSON.parse(rule.condition_logic)
              : rule.condition_logic

            if (evaluateCondition(conditionLogic, partA, partB)) {
              // è§£æJSON action_template
              const actionTemplate = typeof rule.action_template === 'string'
                ? JSON.parse(rule.action_template)
                : rule.action_template

              const action = generateAction(actionTemplate, partA, partB)
              const constraint = {
                id: uuidv4(),
                type: rule.constraint_type,
                part_a: partA.name || partA.partNumber,  // ä¼˜å…ˆä½¿ç”¨åç§°ï¼ˆåŒ…å«è§„æ ¼ä¿¡æ¯ï¼‰
                part_b: partB.name || partB.partNumber,
                part_number_a: partA.partNumber,  // ä¿ç•™ç¼–å·
                part_number_b: partB.partNumber,
                entities: [partA.name, partB.name],
                parameters: action.parameters,
                reasoning: generateReasoning(rule, partA, partB),
                confidence: this._calculateConfidence(rule, partA, partB),
                ruleId: rule.rule_id
              }
              constraints.push(constraint)
              console.log(`[AssemblyReasoning] ğŸ¯ è§¦å‘è§„åˆ™ ${rule.rule_id}: ${rule.name} (ç½®ä¿¡åº¦: ${(constraint.confidence * 100).toFixed(0)}%)`)

              // æ›´æ–°è§„åˆ™ä½¿ç”¨ç»Ÿè®¡
              await db('assembly_rules')
                .where({ rule_id: rule.rule_id })
                .increment('usage_count', 1)

              break // æ¯å¯¹é›¶ä»¶åªåº”ç”¨ä¼˜å…ˆçº§æœ€é«˜çš„ä¸€ä¸ªè§„åˆ™
            }
          }
        }
      }
      }

      reasoningPath.push(`æ¨¡å—2-çº¦æŸå­¦ä¹ : è§„åˆ™æ¨ç†${constraints.length}ä¸ªçº¦æŸ + STEPæå–${stepConstraints.length}ä¸ªçº¦æŸ`)

      // åˆå¹¶çº¦æŸï¼ˆSTEPçº¦æŸä¼˜å…ˆçº§æ›´é«˜ï¼‰
      const allConstraints = [...stepConstraints, ...constraints]

      // 7. è¿‡æ»¤ä½ç½®ä¿¡åº¦çº¦æŸ
      const threshold = 0.5
      const filteredConstraints = allConstraints.filter(c => c.confidence >= threshold)
      console.log(`[æ¨¡å—3] è¿‡æ»¤çº¦æŸ: ${allConstraints.length} â†’ ${filteredConstraints.length}`)
      reasoningPath.push(`æ¨¡å—3-è§„åˆ™æ¨ç†: ç½®ä¿¡åº¦è¿‡æ»¤ï¼Œä¿ç•™${filteredConstraints.length}ä¸ªé«˜è´¨é‡çº¦æŸ`)

      // 8. P1é˜¶æ®µï¼šçº¦æŸä¸€è‡´æ€§éªŒè¯ï¼ˆscipy æ±‚è§£å™¨ï¼‰
      let solverResult = { feasible: true, skipped: true }
      try {
        console.log('[æ¨¡å—3-è§„åˆ™æ¨ç†] ğŸ”¬ çº¦æŸæ±‚è§£å™¨éªŒè¯...')
        const response = await axios.post(`${solverUrl}/validate`, {
          constraints: filteredConstraints
        }, { timeout: 10000 })
        solverResult = response.data

        if (!solverResult.feasible) {
          console.error('[æ¨¡å—3] âŒ çº¦æŸå†²çª:', solverResult.conflicts)
          reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: çº¦æŸå†²çªæ£€æµ‹å¤±è´¥')
          await db('assembly_inference_tasks').where({ id: taskId }).update({
            status: 'failed',
            solver_result: solverResult
          })

          return {
            success: false,
            taskId,
            error: 'çº¦æŸå†²çª',
            conflicts: solverResult.conflicts
          }
        }
        console.log('[æ¨¡å—3] âœ… çº¦æŸéªŒè¯é€šè¿‡')
        reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: çº¦æŸæ±‚è§£å™¨éªŒè¯é€šè¿‡')
      } catch (error) {
        if (error.code === 'ECONNREFUSED') {
          console.warn('[æ¨¡å—3] âš ï¸ æ±‚è§£å™¨æœåŠ¡æœªå¯åŠ¨ï¼Œè·³è¿‡éªŒè¯')
          reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: æ±‚è§£å™¨è·³è¿‡(æœåŠ¡æœªå¯åŠ¨)')
        } else {
          console.error('[æ¨¡å—3] æ±‚è§£å™¨å¤±è´¥:', error.message)
          reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: æ±‚è§£å™¨éªŒè¯å¤±è´¥')
        }
      }

      // 9. P1é˜¶æ®µï¼šè£…é…é¡ºåºä¼˜åŒ–ï¼ˆæ‹“æ‰‘æ’åºï¼‰
      const assemblySequence = this._optimizeSequence(filteredConstraints, enrichedParts)
      console.log('[æ¨¡å—3] ğŸ“Š è£…é…é¡ºåº:', assemblySequence)
      reasoningPath.push('æ¨¡å—3-è§„åˆ™æ¨ç†: æ‹“æ‰‘æ’åºç”Ÿæˆè£…é…é¡ºåº')

      // 10. æ‰¹é‡ä¿å­˜çº¦æŸåˆ°æ•°æ®åº“ï¼ˆåˆ†æ‰¹é¿å…SQLå‚æ•°è¿‡å¤šï¼‰
      if (filteredConstraints.length > 0) {
        const DB_BATCH_SIZE = 100 // PostgreSQLå‚æ•°é™åˆ¶ï¼Œæ¯æ‰¹100ä¸ªçº¦æŸ
        const totalBatches = Math.ceil(filteredConstraints.length / DB_BATCH_SIZE)

        console.log(`[è§„åˆ™åº“] ğŸ’¾ ä¿å­˜${filteredConstraints.length}ä¸ªçº¦æŸï¼Œåˆ†${totalBatches}æ‰¹å†™å…¥`)

        for (let i = 0; i < totalBatches; i++) {
          const start = i * DB_BATCH_SIZE
          const end = Math.min(start + DB_BATCH_SIZE, filteredConstraints.length)
          const batch = filteredConstraints.slice(start, end)

          await db('assembly_constraints').insert(
            batch.map(c => ({
              task_id: taskId,
              constraint_type: c.type,
              entity_a: c.part_a,
              entity_b: c.part_b,
              parameters: JSON.stringify(c.parameters),
              confidence: c.confidence,
              reasoning: c.reasoning || '',
              rule_id: c.ruleId,
              review_status: 'pending'
            }))
          )

          console.log(`[è§„åˆ™åº“] ğŸ“¦ å·²ä¿å­˜ç¬¬${i + 1}/${totalBatches}æ‰¹ (${batch.length}ä¸ªçº¦æŸ)`)
        }

        console.log(`[è§„åˆ™åº“] âœ… å®Œæˆä¿å­˜${filteredConstraints.length}ä¸ªçº¦æŸåˆ°çŸ¥è¯†åº“`)
        reasoningPath.push(`ğŸ’¾ è§„åˆ™åº“: ä¿å­˜${filteredConstraints.length}ä¸ªçº¦æŸåˆ°çŸ¥è¯†åº“`)
      }

      // 11. æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await db('assembly_inference_tasks').where({ id: taskId }).update({
        status: 'completed',
        parts_count: parts.length,
        constraints_count: filteredConstraints.length,
        solver_result: {
          feasible: true,
          sequence: assemblySequence,
          ...solverResult
        }
      })

      // 12. ç”Ÿæˆå¯è§£é‡Šæ€§æŠ¥å‘Š
      const explainability = {
        reasoning_path: reasoningPath,
        rules_fired: [...new Set(filteredConstraints.map(c => c.ruleId))].map(
          ruleId => dbRules.find(r => r.rule_id === ruleId)?.name || ruleId
        )
      }

      console.log(`[å­¦ä¹ å®Œæˆ] âœ… è§„åˆ™åº“å·²æ›´æ–°: ${filteredConstraints.length}ä¸ªçº¦æŸ`)

      // 13. ä»çº¦æŸä¸­å­¦ä¹ æ–°è§„åˆ™
      const learnedRules = await this._extractRulesFromConstraints(filteredConstraints, taskId, parts)

      return {
        success: true,
        taskId,
        constraints: filteredConstraints,
        assemblySequence,
        solverResult,
        explainability,
        learnedRules,
        metadata: {
          partsCount: parts.length,
          constraintsCount: filteredConstraints.length,
          rulesApplied: explainability.rules_fired.length,
          llmEnhanced: useLLM && hasUnrecognizedParts,  // âœ… å®é™…ä½¿ç”¨LLMçš„çŠ¶æ€
          learnedRulesCount: learnedRules.length
        }
      }
    } catch (error) {
      console.error('[AssemblyReasoning] âŒ æ¨ç†å¤±è´¥:', error)

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
      await db('assembly_inference_tasks').where({ id: taskId }).update({
        status: 'failed',
        solver_result: { error: error.message }
      })

      throw error
    }
  }

  /**
   * P1é˜¶æ®µï¼šè£…é…é¡ºåºä¼˜åŒ–ï¼ˆæ‹“æ‰‘æ’åºï¼‰
   */
  _optimizeSequence(constraints, parts) {
    // æ„å»ºä¾èµ–å›¾
    const graph = new Map()
    const partNames = parts.map(p => p.partNumber || p.name)
    partNames.forEach(p => graph.set(p, []))

    // æ·»åŠ ä¾èµ–è¾¹
    constraints.forEach(c => {
      if (c.type === 'SCREW' || c.type === 'dependency') {
        const from = c.part_a
        const to = c.part_b
        if (graph.has(from)) {
          graph.get(from).push(to)
        }
      }
    })

    // Kahn ç®—æ³•æ‹“æ‰‘æ’åº
    const inDegree = new Map()
    partNames.forEach(p => inDegree.set(p, 0))

    graph.forEach((deps, part) => {
      deps.forEach(dep => {
        inDegree.set(dep, (inDegree.get(dep) || 0) + 1)
      })
    })

    const queue = partNames.filter(p => inDegree.get(p) === 0)
    const sequence = []

    while (queue.length > 0) {
      const current = queue.shift()
      sequence.push(current)

      const neighbors = graph.get(current) || []
      neighbors.forEach(neighbor => {
        inDegree.set(neighbor, inDegree.get(neighbor) - 1)
        if (inDegree.get(neighbor) === 0) {
          queue.push(neighbor)
        }
      })
    }

    return sequence
  }

  /**
   * æŸ¥è¯¢æ¨ç†ä»»åŠ¡å†å²
   */
  async getInferenceTasks(userId, limit = 10) {
    const db = require('../../config/database')
    return await db('assembly_inference_tasks')
      .where({ user_id: userId })
      .orderBy('created_at', 'desc')
      .limit(limit)
  }

  /**
   * è·å–ä»»åŠ¡çº¦æŸ
   */
  async getTaskConstraints(taskId) {
    const db = require('../../config/database')
    return await db('assembly_constraints')
      .where({ task_id: taskId })
      .select('*')
  }

  /**
   * è§£æBOM (æ”¯æŒExcel/CSV)
   */
  _parseBOM(buffer) {
    try {
      const workbook = xlsx.read(buffer, { type: 'buffer' })
      const sheetName = workbook.SheetNames[0]
      const sheet = workbook.Sheets[sheetName]
      const data = xlsx.utils.sheet_to_json(sheet)

      console.log(`[AssemblyReasoning] BOMåŸå§‹æ•°æ®åˆ—: ${Object.keys(data[0] || {}).join(', ')}`)

      return data.map((row, index) => {
        const name = row['é›¶ä»¶åç§°'] || row['Part Name'] || row['name'] || row['TITLE'] || `é›¶ä»¶${index + 1}`
        const description = row['æè¿°'] || row['Description'] || row['è¯´æ˜'] || row['TITLE'] || row['é›¶ä»¶ç±»å‹'] || ''

        // è‡ªåŠ¨è¯†åˆ«é›¶ä»¶ç±»å‹
        let type = null
        if (/èºæ “|bolt|screw(?!driver)/i.test(name + description)) {
          type = 'èºæ “'
        } else if (/èºæ¯|nut/i.test(name + description)) {
          type = 'èºæ¯'
        } else if (/æ³•å…°|flange/i.test(name + description)) {
          type = 'æ³•å…°'
        } else if (/æ¥å¤´|connector|fitting/i.test(name + description)) {
          type = 'æ¥å¤´'
        } else if (/å«ç‰‡|gasket|washer/i.test(name + description)) {
          type = 'å«ç‰‡'
        }

        // è‡ªåŠ¨æå–èºçº¹è§„æ ¼
        let thread = null
        const threadMatch = (name + description).match(/M(\d+)(?:x([\d.]+))?/i)
        if (threadMatch) {
          thread = threadMatch[2]
            ? `M${threadMatch[1]}x${threadMatch[2]}`
            : `M${threadMatch[1]}`
        }

        return {
          name,
          partNumber: row['é›¶ä»¶å·'] || row['Part Number'] || row['partNumber'] || row['å›¾å·'] || row['ç¼–å·'] || row['SAPæ–™å·'] || '',
          quantity: parseInt(row['æ•°é‡'] || row['Quantity'] || row['qty'] || row['æ€»æ•°'] || row['ä»¶æ•°'] || 1),
          spec: row['è§„æ ¼'] || row['Spec'] || row['specification'] || row['æè¿°'] || row['Description'] || '',
          description,
          type,     // è‡ªåŠ¨è¯†åˆ«çš„ç±»å‹
          thread    // è‡ªåŠ¨æå–çš„èºçº¹
        }
      })
    } catch (error) {
      console.error('[AssemblyReasoning] BOMè§£æå¤±è´¥:', error)
      throw new Error('BOMæ–‡ä»¶æ ¼å¼é”™è¯¯: ' + error.message)
    }
  }

  /**
   * æŸ¥è¯¢æ ‡å‡†ä»¶åº“
   */
  _lookupStandardPart(partNumber) {
    if (!partNumber) return {}

    // ç²¾ç¡®åŒ¹é…
    if (this.standardParts[partNumber]) {
      return this.standardParts[partNumber]
    }

    // æ¨¡ç³ŠåŒ¹é… (å‰ç¼€åŒ¹é…)
    for (const [key, value] of Object.entries(this.standardParts)) {
      if (partNumber.startsWith(key.split('-')[0])) {
        return value
      }
    }

    return {}
  }

  /**
   * LLMå¢å¼ºï¼šç†è§£é›¶ä»¶æè¿°ï¼Œæå–ç±»å‹å’Œç‰¹å¾
   */
  async _enrichPartsWithLLM(parts) {
    try {
      const unknownParts = parts.filter(p => !p.type && (p.description || p.spec))

      if (unknownParts.length === 0) {
        return parts
      }

      console.log(`[AssemblyReasoning] LLMåˆ†æ ${unknownParts.length} ä¸ªæœªè¯†åˆ«é›¶ä»¶...`)

      const prompt = `ä½ æ˜¯æœºæ¢°å·¥ç¨‹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹é›¶ä»¶ä¿¡æ¯ï¼Œæå–é›¶ä»¶ç±»å‹ã€èºçº¹è§„æ ¼ã€å¯†å°æ–¹å¼ç­‰ç‰¹å¾ã€‚

é›¶ä»¶åˆ—è¡¨:
${unknownParts.map((p, i) => `${i + 1}. åç§°: ${p.name}, è§„æ ¼: ${p.spec}, æè¿°: ${p.description}`).join('\n')}

è¯·è¿”å›JSONæ•°ç»„æ ¼å¼ (æ¯ä¸ªé›¶ä»¶ä¸€ä¸ªå¯¹è±¡):
[
  {
    "name": "é›¶ä»¶åç§°",
    "type": "é›¶ä»¶ç±»å‹ (å¦‚: èºæ “, èºæ¯, æ³•å…°, æ¥å¤´)",
    "thread": "èºçº¹è§„æ ¼ (å¦‚: M8x1.25, 1/4\\"NPT)",
    "sealing": "å¯†å°æ–¹å¼ (å¦‚: é‡‘å±å¯†å°, æ©¡èƒ¶å¯†å°)"
  }
]

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚`

      const response = await this.llmService.chat(prompt, {
        temperature: 0.1,
        max_tokens: 1000
      })

      // è§£æLLMè¿”å›çš„JSON
      const llmResults = JSON.parse(response.replace(/```json\n?|\n?```/g, ''))

      // åˆå¹¶LLMç»“æœ
      const enrichedMap = new Map(llmResults.map(r => [r.name, r]))

      return parts.map(p => {
        if (enrichedMap.has(p.name)) {
          const llmData = enrichedMap.get(p.name)
          return {
            ...p,
            type: p.type || llmData.type,
            thread: p.thread || llmData.thread,
            sealing: p.sealing || llmData.sealing,
            llmEnhanced: true
          }
        }
        return p
      })
    } catch (error) {
      console.error('[AssemblyReasoning] LLMå¢å¼ºå¤±è´¥:', error)
      return parts // å¤±è´¥æ—¶è¿”å›åŸå§‹æ•°æ®
    }
  }

  /**
   * è®¡ç®—ç½®ä¿¡åº¦
   */
  _calculateConfidence(rule, partA, partB) {
    let confidence = 0.6 // åŸºç¡€åˆ†

    // å¦‚æœåŒ¹é…åˆ°æ ‡å‡†ä»¶ï¼Œæé«˜ç½®ä¿¡åº¦
    if (partA.type || partB.type) {
      confidence += 0.15
    }

    // å¦‚æœæœ‰æ˜ç¡®çš„èºçº¹è§„æ ¼ï¼Œè¿›ä¸€æ­¥æé«˜
    if (partA.thread && partB.thread && partA.thread === partB.thread) {
      confidence += 0.2
    }

    // å¦‚æœæ˜¯LLMå¢å¼ºè¯†åˆ«çš„ï¼Œç•¥å¾®é™ä½ç½®ä¿¡åº¦
    if (partA.llmEnhanced || partB.llmEnhanced) {
      confidence -= 0.05
    }

    // æ ¹æ®è§„åˆ™ä¼˜å…ˆçº§è°ƒæ•´
    confidence += (rule.priority / 100)

    return Math.min(Math.max(confidence, 0.0), 1.0)
  }

  /**
   * åˆ¤æ–­èºçº¹æ˜¯å¦å…¼å®¹
   */
  _isThreadCompatible(threadA, threadB) {
    // ç®€åŒ–å®ç°ï¼šç²¾ç¡®åŒ¹é…
    return threadA === threadB
  }

  /**
   * æå–èºçº¹èºè·
   */
  _extractThreadPitch(threadSpec) {
    const match = threadSpec.match(/x([\d.]+)/)
    return match ? parseFloat(match[1]) : 1.5
  }

  /**
   * è§£æSTEPæ–‡ä»¶æå–è£…é…çº¦æŸå’Œé›¶ä»¶ç‰¹å¾
   */
  async _parseStepFiles(stepFiles, taskId) {
    const fs = require('fs').promises
    const path = require('path')
    const { spawn } = require('child_process')

    const allConstraints = []
    const allParts = []
    const assemblyFiles = []
    const partFiles = []

    const fileExists = async (targetPath) => {
      try {
        await fs.access(targetPath)
        return true
      } catch (err) {
        return false
      }
    }

    const defaultAnalyzerScript = path.join(__dirname, '../step_assembly_analyzer_v2.py')
    const legacyAnalyzerScript = path.join(__dirname, '../step_assembly_analyzer.py')
    const analyzerFromEnv = process.env.STEP_ANALYZER_SCRIPT
      ? (path.isAbsolute(process.env.STEP_ANALYZER_SCRIPT)
          ? process.env.STEP_ANALYZER_SCRIPT
          : path.join(process.cwd(), process.env.STEP_ANALYZER_SCRIPT))
      : defaultAnalyzerScript

    let analyzerScript = analyzerFromEnv
    if (!(await fileExists(analyzerScript))) {
      console.warn(`[STEPè§£æ] æŒ‡å®šçš„ STEP åˆ†æè„šæœ¬ä¸å­˜åœ¨: ${analyzerScript}ï¼Œå›é€€åˆ°é»˜è®¤è„šæœ¬`)
      analyzerScript = defaultAnalyzerScript
    }
    if (!(await fileExists(analyzerScript))) {
      console.warn(`[STEPè§£æ] é»˜è®¤ STEP åˆ†æè„šæœ¬ç¼ºå¤±ï¼Œå›é€€åˆ° legacy ç‰ˆæœ¬`)
      analyzerScript = legacyAnalyzerScript
    }

    const supportsRegexFlag = /step_assembly_analyzer_v2\.py$/.test(analyzerScript)
    const forceRegexMode = process.env.STEP_ANALYZER_MODE === 'regex'

    const CONSTRAINT_PRIORITY = {
      'concentric': 10,
      'perpendicular': 10,
      'hole_spacing': 9,
      'parallel': 8,
      'screw': 10,
      'coincident': 9,
      'distance': 8,
      'flow_direction': 6,
      'angle_0': 7,
      'angle_90': 10,
      'angle_120deg': 7,
      'angle_135deg': 7,
      'angle_146deg': 7,
      'angle_149deg': 7,
      'angle_150deg': 7,
      'angle_158deg': 7,
      'angle_180': 7,
      'axis_align': 8
    }

    const getConstraintPriority = (type) => {
      const normalized = (type || '').toLowerCase()
      return CONSTRAINT_PRIORITY[normalized] || 5
    }

    for (const stepFile of stepFiles) {
      try {
        const fileName = stepFile.originalname || stepFile.name
        const fileSize = stepFile.buffer.length / (1024 * 1024) // MB
        console.log(`[STEPè§£æ] å¼€å§‹å¤„ç†: ${fileName} (${fileSize.toFixed(2)}MB)`)

        // ä¿å­˜STEPæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        const tempDir = path.join(__dirname, '../../../uploads/temp')
        await fs.mkdir(tempDir, { recursive: true })

        const tempPath = path.join(tempDir, fileName)
        await fs.writeFile(tempPath, stepFile.buffer)
        console.log(`[STEPè§£æ] æ–‡ä»¶å·²ä¿å­˜åˆ°: ${tempPath}`)

        // è°ƒç”¨Pythonè§£æå™¨
        const outputFile = path.join(tempDir, `analysis_${taskId}_${Date.now()}.json`)
        const analyzerArgs = [analyzerScript, tempPath, outputFile]
        if (supportsRegexFlag && forceRegexMode) {
          analyzerArgs.push('--regex')
        }

        console.log(`[STEPè§£æ] è°ƒç”¨Python: python3 ${analyzerArgs.join(' ')}`)
        console.log(`[STEPè§£æ] è¾“å‡ºæ–‡ä»¶: ${outputFile}`)

        const result = await new Promise((resolve, reject) => {
          const python = spawn('python3', analyzerArgs)

          let stdout = ''
          let stderr = ''

          // è¶…æ—¶å¤„ç† (å¤§æ–‡ä»¶éœ€è¦æ›´é•¿æ—¶é—´)
          const timeout = fileSize > 20 ? 120000 : 60000 // 20MBä»¥ä¸Šç»™120ç§’
          const timer = setTimeout(() => {
            python.kill()
            reject(new Error(`Pythonè„šæœ¬è¶…æ—¶ (${timeout/1000}ç§’)`))
          }, timeout)

          python.stdout.on('data', (data) => {
            stdout += data.toString()
            console.log('[Python]:', data.toString().trim())
          })

          python.stderr.on('data', (data) => {
            stderr += data.toString()
            console.error('[Pythoné”™è¯¯]:', data.toString().trim())
          })

          python.on('close', async (code) => {
            clearTimeout(timer)

            console.log(`[STEPè§£æ] Pythonè¿›ç¨‹é€€å‡ºï¼Œä»£ç : ${code}`)

            if (code === 0) {
              try {
                // æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                const fileExists = await fs.access(outputFile).then(() => true).catch(() => false)
                if (!fileExists) {
                  reject(new Error(`è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: ${outputFile}`))
                  return
                }

                const content = await fs.readFile(outputFile, 'utf-8')
                console.log(`[STEPè§£æ] è¯»å–ç»“æœæ–‡ä»¶ï¼Œå¤§å°: ${content.length}å­—èŠ‚`)

                const analysis = JSON.parse(content)
                const partSummary = analysis.metadata?.products_count ?? analysis.metadata?.parts_count ?? 0
                console.log(`[STEPè§£æ] è§£ææˆåŠŸ: ${partSummary}ä¸ªé›¶ä»¶/äº§å“, ${analysis.metadata?.constraints_count || 0}ä¸ªçº¦æŸ (æ¨¡å¼: ${analysis.parser_mode || 'unknown'})`)

                // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                await fs.unlink(tempPath).catch(() => {})
                await fs.unlink(outputFile).catch(() => {})

                resolve(analysis)
              } catch (error) {
                reject(new Error(`è§£æç»“æœæ–‡ä»¶å¤±è´¥: ${error.message}\nStdout: ${stdout.slice(-500)}\nStderr: ${stderr.slice(-500)}`))
              }
            } else {
              reject(new Error(`Pythonè„šæœ¬é€€å‡ºç : ${code}\nStderr: ${stderr}\nStdout: ${stdout.slice(-500)}`))
            }
          })

          python.on('error', (error) => {
            clearTimeout(timer)
            reject(new Error(`Pythonè¿›ç¨‹é”™è¯¯: ${error.message}`))
          })
        })

        // æ ¹æ®æ–‡ä»¶ç±»å‹åˆ†ç±»å¤„ç†
        if (result.file_type === 'assembly') {
          assemblyFiles.push(fileName)

          const parserMode = result.parser_mode || (result.parts ? 'pythonocc' : 'regex')

          if (parserMode === 'pythonocc') {
            const parts = result.parts || []
            const partIdMap = new Map()

            parts.forEach((part, index) => {
              const partId = part.part_id || part.file_name || `Part_${index + 1}`
              partIdMap.set(part.part_id || part.file_name, partId)

              const features = part.features || []
              const hasHoles = features.some(f => f.type === 'cylinder' && f.subtype === 'hole')
              const hasShafts = features.some(f => f.type === 'cylinder' && f.subtype === 'shaft')

              allParts.push({
                file_name: part.file_name || partId,
                part_number: partId,
                product_id: part.part_id || part.file_name,
                has_holes: hasHoles,
                has_shafts: hasShafts,
                features_count: features.length,
                transform: part.transform || null
              })
            })
            console.log(`[STEPè§£æ] pythonOCC è£…é…ä½“åŒ…å« ${parts.length} ä¸ªé›¶ä»¶`)

            const rawConstraints = result.constraints || []
            const beforeCount = allConstraints.length
            rawConstraints.forEach((constraint) => {
              const partNumberA = partIdMap.get(constraint.part_a) || constraint.part_a || 'UNKNOWN_A'
              const partNumberB = partIdMap.get(constraint.part_b) || constraint.part_b || 'UNKNOWN_B'

              allConstraints.push({
                id: uuidv4(),
                type: (constraint.type || constraint.constraint_type || 'UNKNOWN').toUpperCase(),
                part_a: partNumberA,
                part_b: partNumberB,
                entities: [partNumberA, partNumberB],
                parameters: constraint.parameters || {},
                reasoning: constraint.reasoning || `STEP(occ)æ¨ç†ï¼š${(constraint.type || '').toUpperCase()}`,
                confidence: constraint.confidence ?? 0.9,
                source: constraint.source || 'pythonocc',
                step_file: fileName,
                priority: getConstraintPriority(constraint.type || constraint.constraint_type)
              })
            })

            console.log(`[STEPè§£æ] pythonOCC çº¦æŸé‡‡é›†: ${rawConstraints.length} æ¡ï¼Œæ–°å¢ ${allConstraints.length - beforeCount} æ¡ç³»ç»Ÿçº¦æŸ`)
          } else {
            // âœ… è½¬æ¢äº§å“ä¸ºé›¶ä»¶ + æ„å»ºIDæ˜ å°„
            const productIdToPartNumber = {}  // Product_ID â†’ çœŸå®é›¶ä»¶ç¼–å·
            const allPartNumbers = []         // æ‰€æœ‰é›¶ä»¶ç¼–å·åˆ—è¡¨
            if (result.products && result.products.length > 0) {
              result.products.forEach(product => {
                const partNumber = product.name
                productIdToPartNumber[product.id] = partNumber
                allPartNumbers.push(partNumber)
                allParts.push({
                  file_name: product.name,
                  part_number: partNumber,
                  product_id: product.id,
                  has_holes: false,
                  has_shafts: false
                })
              })
              console.log(`[STEPè§£æ] è£…é…ä½“åŒ…å« ${result.products.length} ä¸ªé›¶ä»¶`)
            }

            // ğŸ“Š ä¼˜åŒ–çº¦æŸè´¨é‡ï¼šæ’åº + è¿‡æ»¤ + å»é‡ + åˆ†æ‰¹å¤„ç†
            const rawConstraints = result.constraints || []
            const beforeCount = allConstraints.length
            console.log(`[STEPè§£æ] Pythonè¿”å› ${rawConstraints.length} ä¸ªçº¦æŸ`)

            // ğŸ†• æ„å»ºPlacementâ†’é›¶ä»¶ç¼–å·çš„æ˜ å°„ï¼ˆæŒ‰é¡ºåºå¾ªç¯åˆ†é…ï¼‰
            const placementToPartNumber = {}
            const placementIds = new Set()
            rawConstraints.forEach(c => {
              if (c.part1) placementIds.add(c.part1)
              if (c.part2) placementIds.add(c.part2)
              if (c.hole1) placementIds.add(c.hole1)
              if (c.hole2) placementIds.add(c.hole2)
            })

            const sortedPlacementIds = Array.from(placementIds).sort((a, b) => parseInt(a) - parseInt(b))
            sortedPlacementIds.forEach((pid, index) => {
              // ä½¿ç”¨å–æ¨¡å¾ªç¯åˆ†é…çœŸå®é›¶ä»¶ç¼–å·
              const partNumber = allPartNumbers.length
                ? allPartNumbers[index % allPartNumbers.length]
                : `é›¶ä»¶#${pid}`
              placementToPartNumber[pid] = partNumber
            })

            console.log(`[STEPè§£æ] Placementæ˜ å°„: ${sortedPlacementIds.length}ä¸ªplacement â†’ ${allPartNumbers.length}ä¸ªé›¶ä»¶`)

            // 1ï¸âƒ£ æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆä¿ç•™ä¸­é«˜è´¨é‡çº¦æŸï¼Œå±•ç¤ºå¤šæ ·æ€§ï¼‰
            const CONFIDENCE_THRESHOLD = 0.5  // é™ä½é˜ˆå€¼ï¼ŒåŒ…å«æ›´å¤šç±»å‹
            const highQualityConstraints = rawConstraints.filter(c =>
              (c.confidence || 0.5) >= CONFIDENCE_THRESHOLD
            )
            console.log(`[çº¦æŸä¼˜åŒ–] ç½®ä¿¡åº¦è¿‡æ»¤: ${rawConstraints.length} â†’ ${highQualityConstraints.length} (>=${CONFIDENCE_THRESHOLD})`)

            // æŒ‰ç±»å‹åˆ†ç»„
            const byType = {}
            highQualityConstraints.forEach(c => {
              const type = c.type
              if (!byType[type]) byType[type] = []
              byType[type].push(c)
            })

            // æ¯ç§ç±»å‹å–å‰Nä¸ªï¼ˆç¡®ä¿å¤šæ ·æ€§ï¼‰
            const balancedConstraints = []
            const samplesPerType = Object.keys(byType).length
              ? Math.ceil(5000 / Object.keys(byType).length)
              : 0

            Object.entries(byType).forEach(([type, constraints]) => {
              const sorted = constraints
                .sort((a, b) => (b.confidence || 0.5) - (a.confidence || 0.5))
                .slice(0, samplesPerType || constraints.length)
              balancedConstraints.push(...sorted)
            })

            console.log(`[çº¦æŸä¼˜åŒ–] ç±»å‹å¹³è¡¡é‡‡æ ·: ${Object.keys(byType).length}ç§ç±»å‹ï¼Œæ¯ç§çº¦${samplesPerType || 0}ä¸ª`)

            // å†æŒ‰ä¼˜å…ˆçº§æ’åº
            const sortedConstraints = balancedConstraints.sort((a, b) => {
              const priorityA = getConstraintPriority(a.type)
              const priorityB = getConstraintPriority(b.type)
              if (priorityA !== priorityB) return priorityB - priorityA
              return (b.confidence || 0.5) - (a.confidence || 0.5)
            })

            // 3ï¸âƒ£ å»é‡ç›¸ä¼¼çº¦æŸï¼ˆåŸºäºè·ç¦»å’Œç±»å‹ï¼‰
            const uniqueConstraints = []
            const constraintKeys = new Set()

            for (const c of sortedConstraints) {
              const key = `${c.type}_${c.part1 || c.hole1}_${c.part2 || c.hole2}_${Math.round(c.distance || 0)}`
              if (!constraintKeys.has(key)) {
                constraintKeys.add(key)
                uniqueConstraints.push(c)
              }
            }
            console.log(`[çº¦æŸä¼˜åŒ–] å»é‡: ${sortedConstraints.length} â†’ ${uniqueConstraints.length}`)

            // 4ï¸âƒ£ åˆ†æ‰¹å¤„ç†ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼Œä½†ä¸ä¸¢å¼ƒæ•°æ®ï¼‰
            const BATCH_SIZE = 1000
            const totalBatches = Math.ceil(uniqueConstraints.length / BATCH_SIZE) || 1
            console.log(`[çº¦æŸä¼˜åŒ–] ğŸ“¦ åˆ†æ‰¹å¤„ç†: ${uniqueConstraints.length}ä¸ªçº¦æŸ â†’ ${totalBatches}æ‰¹`)

            // 5ï¸âƒ£ è½¬æ¢ä¸ºç³»ç»Ÿæ ¼å¼ï¼ˆåˆ†æ‰¹æ·»åŠ åˆ°allConstraintsï¼‰
            for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
              const batchStart = batchIdx * BATCH_SIZE
              const batchEnd = Math.min(batchStart + BATCH_SIZE, uniqueConstraints.length)
              const batch = uniqueConstraints.slice(batchStart, batchEnd)

              console.log(`[çº¦æŸä¼˜åŒ–] å¤„ç†ç¬¬ ${batchIdx + 1}/${totalBatches} æ‰¹: ${batch.length}ä¸ªçº¦æŸ`)

              for (const c of batch) {
                // ğŸ”„ å°†Placement IDè½¬æ¢ä¸ºçœŸå®é›¶ä»¶ç¼–å·
                const placementIdA = c.part1 || c.hole1 || 'unknown'
                const placementIdB = c.part2 || c.hole2 || 'unknown'

                // ä¼˜å…ˆä½¿ç”¨placementæ˜ å°„ï¼Œå†å°è¯•productæ˜ å°„ï¼Œæœ€åä½¿ç”¨"é›¶ä»¶#ID"æ ¼å¼
                const partNumberA = placementToPartNumber[placementIdA] || productIdToPartNumber[placementIdA] || `é›¶ä»¶#${placementIdA}`
                const partNumberB = placementToPartNumber[placementIdB] || productIdToPartNumber[placementIdB] || `é›¶ä»¶#${placementIdB}`

                allConstraints.push({
                  id: uuidv4(),
                  type: (c.type || '').toUpperCase(),
                  part_a: partNumberA,  // âœ… ä½¿ç”¨çœŸå®é›¶ä»¶ç¼–å·
                  part_b: partNumberB,  // âœ… ä½¿ç”¨çœŸå®é›¶ä»¶ç¼–å·
                  entities: [partNumberA, partNumberB],
                  parameters: {
                    distance: c.distance,
                    angle: c.angle,
                    radius1: c.radius1,
                    radius2: c.radius2
                  },
                  reasoning: this._generateStepReasoning(c),
                  confidence: c.confidence || 0.9,
                  source: 'step_assembly',
                  step_file: fileName,
                  priority: getConstraintPriority(c.type)
                })
              }
            }

            console.log(`[STEPè§£æ] æˆåŠŸå¤„ç† ${allConstraints.length - beforeCount} ä¸ªè£…é…çº¦æŸ`)
          }

        } else if (result.file_type === 'part') {
          partFiles.push(fileName)

          const parserMode = result.parser_mode || (result.parts ? 'pythonocc' : 'regex')

          if (parserMode === 'pythonocc' && (result.parts?.length || 0) > 0) {
            const partInfo = result.parts[0]
            const features = partInfo.features || []
            const partFeatures = {
              file_name: partInfo.file_name || fileName,
              part_number: partInfo.part_id || fileName.split('.')[0],
              has_holes: features.some(f => f.type === 'cylinder' && f.subtype === 'hole'),
              has_shafts: features.some(f => f.type === 'cylinder' && f.subtype === 'shaft'),
              features_count: features.length,
              transform: partInfo.transform || null
            }
            allParts.push(partFeatures)
            console.log(`[STEPè§£æ] pythonOCCé›¶ä»¶: ç‰¹å¾=${partFeatures.features_count}, å­”=${partFeatures.has_holes}, è½´=${partFeatures.has_shafts}`)
          } else {
            // æå–é›¶ä»¶ç‰¹å¾ï¼ˆå­”ã€è½´ã€é¢ç­‰ï¼‰
            const partFeatures = {
              file_name: fileName,
              part_number: fileName.split('.')[0],  // ä»æ–‡ä»¶åæå–é›¶ä»¶å·
              cylinders: result.cylinders || [],
              placements: result.metadata.placements_count || 0,
              has_holes: (result.cylinders || []).some(c => c.type === 'hole'),
              has_shafts: (result.cylinders || []).some(c => c.type === 'shaft')
            }

            allParts.push(partFeatures)
            console.log(`[STEPè§£æ] é›¶ä»¶ç‰¹å¾: å­”=${partFeatures.has_holes}, è½´=${partFeatures.has_shafts}`)
          }
        }

      } catch (error) {
        console.error(`[STEPè§£æ] âŒ å¤±è´¥ ${stepFile.originalname || stepFile.name}:`, error.message)
        console.error(error.stack)
      }
    }

    console.log(`[STEPè§£æ] æ±‡æ€»: è£…é…ä½“${assemblyFiles.length}ä¸ª, é›¶ä»¶${partFiles.length}ä¸ª, æ€»é›¶ä»¶${allParts.length}ä¸ª, æ€»çº¦æŸ${allConstraints.length}ä¸ª`)

    return {
      constraints: allConstraints,
      parts: allParts,
      assemblyFiles,
      partFiles
    }
  }

  /**
   * ç”ŸæˆSTEPçº¦æŸæ¨ç†è¯´æ˜
   */
  _generateStepReasoning(stepConstraint) {
    if (stepConstraint.type === 'concentric') {
      return `STEPæ–‡ä»¶åˆ†æï¼šæ£€æµ‹åˆ°åŒè½´é…åˆï¼ˆè·ç¦»${stepConstraint.distance}mmï¼‰`
    } else if (stepConstraint.type === 'perpendicular') {
      return `STEPæ–‡ä»¶åˆ†æï¼šæ£€æµ‹åˆ°å‚ç›´é…åˆï¼ˆè§’åº¦${stepConstraint.angle}Â°ï¼‰`
    } else if (stepConstraint.type === 'hole_spacing') {
      return `STEPæ–‡ä»¶åˆ†æï¼šæ£€æµ‹åˆ°å­”é—´è·çº¦æŸï¼ˆ${stepConstraint.distance}mmï¼Œå­”å¾„${stepConstraint.radius1}/${stepConstraint.radius2}ï¼‰`
    } else {
      return `STEPæ–‡ä»¶åˆ†æï¼š${stepConstraint.type}é…åˆ`
    }
  }

  /**
   * ä»BOMç›´æ¥æ¨ç†çº¦æŸï¼ˆç”¨äºPIDè¯†åˆ«ç»“æœï¼‰
   */
  async inferConstraintsFromBOM(bomData, taskId, userId) {
    console.log(`[AssemblyReasoning] ğŸ” ä»BOMæ¨ç†çº¦æŸ: ${bomData.length}ä¸ªé›¶ä»¶`)

    const db = require('../../config/database')

    try {
      // 1. ä¸°å¯Œé›¶ä»¶ä¿¡æ¯
      const enrichedParts = bomData.map(part => ({
        ...part,
        name: part.part_number,
        type: part.part_type,
        partNumber: part.part_number
      }))

      // 2. åŠ è½½è£…é…è§„åˆ™ï¼ˆæ•°æ®åº“ + ç¡¬ç¼–ç ï¼‰
      const dbRules = await loadRulesFromDatabase()
      const allRules = [...this.rules, ...dbRules]

      console.log(`[AssemblyReasoning] ğŸ“š åŠ è½½${allRules.length}æ¡è§„åˆ™`)

      // 3. è§„åˆ™åŒ¹é…ï¼šéå†æ‰€æœ‰é›¶ä»¶å¯¹
      const constraints = []
      for (let i = 0; i < enrichedParts.length - 1; i++) {
        for (let j = i + 1; j < enrichedParts.length; j++) {
          const partA = enrichedParts[i]
          const partB = enrichedParts[j]

          // å°è¯•åŒ¹é…è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
          for (const rule of allRules) {
            let matched = false

            // æ£€æŸ¥æ˜¯æ•°æ®åº“è§„åˆ™è¿˜æ˜¯ç¡¬ç¼–ç è§„åˆ™
            if (rule.condition_logic) {
              // æ•°æ®åº“è§„åˆ™
              const conditionLogic = typeof rule.condition_logic === 'string'
                ? JSON.parse(rule.condition_logic)
                : rule.condition_logic

              if (evaluateCondition(conditionLogic, partA, partB)) {
                matched = true
                const actionTemplate = typeof rule.action_template === 'string'
                  ? JSON.parse(rule.action_template)
                  : rule.action_template

                const action = generateAction(actionTemplate, partA, partB)
                const constraint = {
                  id: require('uuid').v4(),
                  task_id: taskId,
                  constraint_type: rule.constraint_type,
                  entity_a: partA.part_number,
                  entity_b: partB.part_number,
                  parameters: JSON.stringify(action.parameters),
                  reasoning: generateReasoning(rule, partA, partB),
                  confidence: this._calculateConfidence(rule, partA, partB),
                  rule_id: rule.rule_id,
                  review_status: 'pending'
                }
                constraints.push(constraint)
                console.log(`[AssemblyReasoning] ğŸ¯ è§¦å‘è§„åˆ™ ${rule.rule_id}: ${rule.name}`)
              }
            } else {
              // ç¡¬ç¼–ç è§„åˆ™
              if (rule.condition(partA, partB)) {
                matched = true
                const action = rule.action(partA, partB)
                const constraint = {
                  id: require('uuid').v4(),
                  task_id: taskId,
                  constraint_type: action.type,
                  entity_a: partA.part_number,
                  entity_b: partB.part_number,
                  parameters: JSON.stringify(action.parameters),
                  reasoning: action.reasoning,
                  confidence: 0.85,
                  rule_id: rule.id,
                  review_status: 'pending'
                }
                constraints.push(constraint)
                console.log(`[AssemblyReasoning] ğŸ¯ è§¦å‘è§„åˆ™ ${rule.id}: ${rule.name}`)
              }
            }

            if (matched) break // åªåº”ç”¨ä¼˜å…ˆçº§æœ€é«˜çš„è§„åˆ™
          }
        }
      }

      console.log(`[AssemblyReasoning] âœ… æ¨ç†å®Œæˆ: ${constraints.length}ä¸ªçº¦æŸ`)

      // 4. ä¿å­˜çº¦æŸåˆ°æ•°æ®åº“
      if (constraints.length > 0) {
        await db('assembly_constraints').insert(constraints)
      }

      return {
        success: true,
        constraints,
        partsCount: bomData.length,
        rulesApplied: allRules.length
      }
    } catch (error) {
      console.error('[AssemblyReasoning] âŒ æ¨ç†å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * ä»çº¦æŸæ•°æ®ä¸­æå–è§„åˆ™ï¼ˆè§„åˆ™å­¦ä¹ ï¼‰
   */
  async _extractRulesFromConstraints(constraints, taskId, parts) {
    const db = require('../../config/database')

    console.log(`[è§„åˆ™å­¦ä¹ ] ğŸ§  å¼€å§‹åˆ†æ ${constraints.length} ä¸ªçº¦æŸ...`)

    // æŒ‰çº¦æŸç±»å‹åˆ†ç»„
    const grouped = {}
    constraints.forEach(c => {
      const type = c.type || c.constraint_type
      if (!grouped[type]) grouped[type] = []
      grouped[type].push(c)
    })

    const learnedRules = []
    const assemblyRuleRows = []

    const buildConditionLogicFromPattern = (pattern) => {
      if (pattern.featureType === 'thread') {
        return {
          type: 'thread_match',
          value: pattern.feature
        }
      }

      return {
        type: 'name_contains',
        field: 'name',
        value: pattern.feature
      }
    }

    const buildActionTemplateFromType = (constraintType) => ({
      constraint_type: (constraintType || 'GENERIC').toUpperCase(),
      parameters: {}
    })

    const toPriorityNumber = (priorityLabel) => priorityLabel === 'high' ? 9 : 5

    // å¯¹æ¯ç§çº¦æŸç±»å‹è¿›è¡Œæ¨¡å¼åˆ†æ
    for (const [type, items] of Object.entries(grouped)) {
      if (items.length < 2) {
        console.log(`[è§„åˆ™å­¦ä¹ ] â­ï¸  è·³è¿‡ ${type}: æ ·æœ¬æ•°ä¸è¶³ (${items.length} < 2)`)
        continue
      }

      console.log(`[è§„åˆ™å­¦ä¹ ] ğŸ” åˆ†æ ${type} çº¦æŸ: ${items.length} ä¸ªæ ·æœ¬`)

      // æå–é›¶ä»¶ç‰¹å¾æ¨¡å¼
      const patterns = {}
      items.forEach(item => {
        const partA = item.entity_a || item.part_a
        const partB = item.entity_b || item.part_b

        // æ¨¡å¼1: èºçº¹è§„æ ¼
        const threadMatch = (partA + ' ' + partB).match(/M(\d+)/g)
        if (threadMatch) {
          const threads = [...new Set(threadMatch)]
          threads.forEach(thread => {
            const key = `${type}_${thread}`
            if (!patterns[key]) {
              patterns[key] = {
                type,
                feature: thread,
                featureType: 'thread',
                count: 0,
                examples: []
              }
            }
            patterns[key].count++
            patterns[key].examples.push({ partA, partB })
          })
        }

        // æ¨¡å¼2: å­”å¾„é…åˆ
        const holeMatch = (partA + ' ' + partB).match(/[Î¦Ï†](\d+\.?\d*)/g)
        if (holeMatch) {
          const holes = [...new Set(holeMatch)]
          holes.forEach(hole => {
            const key = `${type}_${hole}`
            if (!patterns[key]) {
              patterns[key] = {
                type,
                feature: hole,
                featureType: 'hole',
                count: 0,
                examples: []
              }
            }
            patterns[key].count++
            patterns[key].examples.push({ partA, partB })
          })
        }

        // æ¨¡å¼3: é›¶ä»¶åç§°å…³é”®è¯
        const keywords = ['èºæ¯', 'èºé’‰', 'èºæ “', 'å«ç‰‡', 'æ³•å…°', 'æ¥å¤´', 'é˜€é—¨']
        keywords.forEach(keyword => {
          if (partA?.includes(keyword) || partB?.includes(keyword)) {
            const key = `${type}_${keyword}`
            if (!patterns[key]) {
              patterns[key] = {
                type,
                feature: keyword,
                featureType: 'keyword',
                count: 0,
                examples: []
              }
            }
            patterns[key].count++
            patterns[key].examples.push({ partA, partB })
          }
        })
      })

      // ç”Ÿæˆè§„åˆ™
      for (const [patternKey, patternData] of Object.entries(patterns)) {
        if (patternData.count >= 2) { // è‡³å°‘å‡ºç°2æ¬¡æ‰å­¦ä¹ 
          const confidence = Math.min(0.5 + (patternData.count * 0.1), 0.95)

          const rule = {
            rule_type: 'assembly',
            rule_code: `LEARNED_${type}_${patternData.feature}_${Date.now()}`,
            rule_name: `${patternData.feature} ${patternData.featureType === 'thread' ? 'èºçº¹' : patternData.featureType === 'hole' ? 'å­”å¾„' : 'é›¶ä»¶'}é…åˆè§„åˆ™`,
            rule_content: `å½“æ£€æµ‹åˆ°åŒ…å«"${patternData.feature}"ç‰¹å¾çš„é›¶ä»¶æ—¶ï¼Œè‡ªåŠ¨ç”Ÿæˆ${type}çº¦æŸ`,
            parameters: JSON.stringify({
              constraint_type: type,
              feature: patternData.feature,
              feature_type: patternData.featureType,
              learned_from: 'constraint_analysis',
              sample_count: patternData.count,
              examples: patternData.examples.slice(0, 3) // ä¿å­˜å‰3ä¸ªç¤ºä¾‹
            }),
            category_id: null,
            priority: patternData.count >= 5 ? 'high' : 'normal',
            confidence_score: confidence,
            source_document_id: taskId,
            learned_from: 'ai_learning',
            review_status: 'pending',
            is_active: true,
            usage_count: 0,
            success_count: 0
          }

          learnedRules.push(rule)
          console.log(`[è§„åˆ™å­¦ä¹ ] ğŸ“š å­¦åˆ°è§„åˆ™: ${rule.rule_name} (ç½®ä¿¡åº¦: ${(confidence * 100).toFixed(0)}%, æ ·æœ¬: ${patternData.count})`)

          const conditionLogic = buildConditionLogicFromPattern(patternData)
          const actionTemplate = buildActionTemplateFromType(type)

          assemblyRuleRows.push({
            rule_id: rule.rule_code,
            name: rule.rule_name,
            description: rule.rule_content,
            priority: toPriorityNumber(rule.priority),
            constraint_type: (type || 'GENERIC').toUpperCase(),
            condition_logic: JSON.stringify(conditionLogic),
            action_template: JSON.stringify(actionTemplate),
            is_active: true,
            learned_from: 'constraint_learning',
            created_by: 'system',
            confidence_boost: 0,
            usage_count: 0,
            success_count: 0,
            updated_at: new Date(),
            created_at: new Date()
          })
        }
      }
    }

    // ä¿å­˜åˆ°æ•°æ®åº“
    if (learnedRules.length > 0) {
      await db('design_rules').insert(learnedRules)
      await db('assembly_rules')
        .insert(assemblyRuleRows)
        .onConflict('rule_id')
        .merge({
          description: db.raw('excluded.description'),
          priority: db.raw('excluded.priority'),
          constraint_type: db.raw('excluded.constraint_type'),
          condition_logic: db.raw('excluded.condition_logic'),
          action_template: db.raw('excluded.action_template'),
          is_active: db.raw('excluded.is_active'),
          learned_from: db.raw('excluded.learned_from'),
          updated_at: db.raw('excluded.updated_at')
        })

      console.log(`[è§„åˆ™å­¦ä¹ ] âœ… æˆåŠŸä¿å­˜ ${learnedRules.length} æ¡æ–°è§„åˆ™åˆ°æ•°æ®åº“ï¼Œå¹¶åŒæ­¥åˆ° assembly_rules`)
    } else {
      console.log(`[è§„åˆ™å­¦ä¹ ] â„¹ï¸  æœªå‘ç°å¯å­¦ä¹ çš„è§„åˆ™æ¨¡å¼`)
    }

    return learnedRules
  }

  /**
   * å­¦ä¹ åé¦ˆ (P0é˜¶æ®µè®°å½•æ—¥å¿—)
   */
  async learnFromFeedback(feedback) {
    console.log('[AssemblyReasoning] ğŸ“ æ”¶åˆ°åé¦ˆ:', {
      constraintId: feedback.constraintId,
      isCorrect: feedback.isCorrect,
      userId: feedback.userId,
      timestamp: feedback.timestamp.toISOString()
    })

    // P0é˜¶æ®µ: ä»…è®°å½•åˆ°æ—¥å¿—
    // P1é˜¶æ®µ: å†™å…¥æ•°æ®åº“
    // P2é˜¶æ®µ: åœ¨çº¿å­¦ä¹ æ›´æ–°è§„åˆ™æƒé‡
  }
}

module.exports = AssemblyReasoningService
