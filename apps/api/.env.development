# 服务器配置
NODE_ENV=development
PORT=3000
API_URL=http://localhost:3000
# Document server inside Docker需要访问宿主机API时改成宿主机IP，比如 http://10.10.6.2:3000
ONLYOFFICE_API_URL=http://10.10.6.95:3000
API_PREFIX=/api

# 数据库配置
DB_HOST=localhost
DB_PORT=5433
DB_NAME=design_platform
DB_USER=postgres
DB_PASSWORD=postgres

# JWT配置
JWT_SECRET=your-super-secret-jwt-key-here-change-in-production
JWT_EXPIRES_IN=7d
REFRESH_TOKEN_SECRET=your-refresh-token-secret-here
REFRESH_TOKEN_EXPIRES_IN=30d

# CORS配置 - 添加OnlyOffice Document Server端口8880
CORS_ORIGIN=http://localhost:8000,http://localhost:8001,http://localhost:3000,http://localhost:5173,http://localhost:8080,http://localhost:8082,http://localhost:8880,http://localhost:80,http://localhost

# 文件上传配置
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=10485760

# Redis配置
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# RAGFlow配置
RAGFLOW_API_BASE=http://localhost:8081
RAGFLOW_API_KEY=ragflow-your-api-key

# GraphRAG配置
GRAPHRAG_PATH=/Users/shenguoli/Documents/projects/design-institute-platform/03-knowledge-graph/graphrag
GRAPHRAG_WORKSPACE=./graphrag-workspace
GRAPHRAG_API_KEY=sk-test

# Neo4j配置
NEO4J_URL=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j123

# vLLM配置 (使用本地Ollama)
OPENAI_API_BASE=http://localhost:11434/v1
OPENAI_API_KEY=ollama
OPENAI_MODEL=qwen2:1.5b

# Embedding配置 (使用服务器 vLLM)
EMBEDDING_API_BASE=http://10.10.18.3:11434/v1
EMBEDDING_API_KEY=sk-test
EMBEDDING_MODEL=/mnt/data/models/bge-large-zh-v1.5

# Automatic1111配置
SD_API_BASE=http://10.10.18.3:7860

# QwenVL和vLLM服务配置
QWENVL_ENDPOINT=http://10.10.18.2:8001/v1/chat/completions
VLLM_ENDPOINT=http://10.10.18.3:8000/v1/chat/completions

# QwenVL多模态配置（用于PID识别等视觉任务）
QWENVL_URL=http://10.10.18.2:8001
QWENVL_MODEL=qwen-vl-72b
QWENVL_API_KEY=

# 日志配置
LOG_LEVEL=info
LOG_FILE=./logs/app.log
# ==================== LLM配置（统一） ====================
# LLM提供商: ollama (开发/本地) | vllm (生产/公司服务器)
LLM_PROVIDER=vllm

# Ollama配置（开发环境）
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2:1.5b

# vLLM配置（生产环境 - 公司服务器 ✓ 已验证可用）
VLLM_URL=http://10.10.18.3:8000
VLLM_MODEL=qwen-next-80b
VLLM_API_KEY=

# Qwen-next GPU服务器（测试环境 - 80B模型 ✓ 已验证可用）
QWEN_NEXT_URL=http://58.209.247.194:8000
QWEN_NEXT_MODEL=deepseek-v3
QWEN_NEXT_API_KEY=

# MinIO对象存储配置
MINIO_ENDPOINT=localhost
MINIO_PORT=9003
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# Milvus向量数据库配置
MILVUS_ADDRESS=localhost:19530
MILVUS_USERNAME=
MILVUS_PASSWORD=

# DeepSeek-OCR文档识别服务配置
DOCUMENT_RECOGNITION_SERVICE=http://10.10.18.3:7000/ocr
USE_OCR_FOR_PDF=true

# Docling文档结构化解析服务配置
DOCLING_SERVICE_URL=http://localhost:7001
USE_DOCLING_PARSER=true

# 装配约束推理引擎配置
ASSEMBLY_USE_LLM=true
ASSEMBLY_SOLVER_LEVEL=P0

# ==================== 语义层V2.0配置 ====================
# 向量存储后端: milvus | chroma | pgvector
VECTOR_STORE_BACKEND=milvus
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=semantic_chunks

# 缓存配置
CACHE_TTL=3600
CACHE_PREFIX=semantic:
