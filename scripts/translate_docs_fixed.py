#!/usr/bin/env python3
"""
å®Œæ•´æ‰¹é‡å¤„ç†è„šæœ¬
æ­¥éª¤1ï¼šç”¨ LibreOffice è½¬æ¢ DOC â†’ DOCXï¼ˆä¿ç•™æ‰€æœ‰æ ·å¼ï¼‰
æ­¥éª¤2ï¼šç¿»è¯‘ DOCXï¼ˆä¿ç•™æ‰€æœ‰æ ¼å¼ï¼‰
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from typing import List, Dict
import requests

sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

# ============ é…ç½® ============
SOURCE_DIR = "docs/specs/Full Length"
OUTPUT_DIR = "docs/specs_zh/Full Length"
TRANSLATION_MAP = "docs/specs/æ–‡ä»¶åç¿»è¯‘å¯¹ç…§è¡¨_å®Œæ•´ç‰ˆ.json"
VLLM_URL = os.getenv("VLLM_URL", "http://10.10.18.3:8000")
VLLM_MODEL = os.getenv("VLLM_MODEL", "/mnt/data/models/Qwen3-32B")
BATCH_SIZE = 10
LIBREOFFICE = os.getenv("LIBREOFFICE", "soffice")  # Linux: soffice, macOS: /Applications/LibreOffice.app/Contents/MacOS/soffice

# ============ åŠ è½½ç¿»è¯‘å¯¹ç…§è¡¨ ============
def load_translation_map() -> Dict:
    try:
        with open(TRANSLATION_MAP, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {"folders": {}, "files": {}}

TRANS_MAP = load_translation_map()

def translate_folder_name(folder_name: str) -> str:
    return TRANS_MAP.get("folders", {}).get(folder_name, folder_name)

def is_translation_complete(text: str) -> bool:
    """æ£€æŸ¥ç¿»è¯‘æ˜¯å¦å®Œæ•´ï¼ˆä¸åŒ…å«å¸¸è§è‹±æ–‡å•è¯ï¼‰"""
    # å¸¸è§çš„éœ€è¦ç¿»è¯‘çš„è‹±æ–‡å•è¯
    common_words = [
        'for', 'and', 'of', 'the', 'in', 'to', 'with', 'on', 'at',
        'Preparation', 'Installation', 'System', 'Equipment', 'Materials',
        'Requirements', 'Specifications', 'Design', 'Construction', 'Details',
        'General', 'Special', 'Testing', 'Quality', 'Control', 'Management',
        'Building', 'Structure', 'Mechanical', 'Electrical', 'Plumbing'
    ]

    # æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡å•è¯ï¼ˆå¿½ç•¥æ•°å­—å’Œ"FL"ä¹‹ç±»çš„ç¼©å†™ï¼‰
    words = text.split()
    for word in words:
        # è·³è¿‡æ•°å­—å’ŒçŸ­ç¼©å†™
        if word.isdigit() or len(word) <= 2:
            continue
        # æ£€æŸ¥æ˜¯å¦æ˜¯è‹±æ–‡å•è¯
        for common in common_words:
            if common.lower() in word.lower():
                return False
    return True

def translate_file_name(file_name: str) -> str:
    """ç¿»è¯‘æ–‡ä»¶åï¼ˆä¼˜å…ˆä½¿ç”¨å¯¹ç…§è¡¨ï¼Œå¦åˆ™ç”¨VLLMç¿»è¯‘ï¼‰"""
    name_without_ext = file_name.replace('.DOC', '').replace('.docx', '')

    # å°è¯•ä»å¯¹ç…§è¡¨è·å–
    if file_name in TRANS_MAP.get("files", {}):
        translated = TRANS_MAP["files"][file_name]
        # æ£€æŸ¥ç¿»è¯‘æ˜¯å¦å®Œæ•´ï¼ˆä¸åŒ…å«å¸¸è§è‹±æ–‡å•è¯ï¼‰
        if translated != name_without_ext and is_translation_complete(translated):
            return f"{translated}.docx"

    # å¦‚æœå¯¹ç…§è¡¨ä¸­æ²¡æœ‰æˆ–ç¿»è¯‘ä¸å®Œæ•´ï¼Œç”¨VLLMç¿»è¯‘
    # åˆ†ç¦»ç¼–å·å’Œåç§°ï¼ˆå¦‚ "000107 FL - Seals Page" -> "000107 FL - " + "Seals Page"ï¼‰
    parts = name_without_ext.split(' - ', 1)
    if len(parts) == 2:
        prefix = parts[0]  # "000107 FL"
        name_part = parts[1]  # "Seals Page"

        # åªç¿»è¯‘åç§°éƒ¨åˆ†
        translated_name = translate_single(name_part)
        return f"{prefix} - {translated_name}.docx"

    # å¦‚æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œä¿æŒåŸæ ·
    return f"{name_without_ext}.docx"

# ============ ç« èŠ‚æ ‡é¢˜ç¿»è¯‘å­—å…¸ ============
SECTION_HEADINGS = {
    "ACTION SUBMITTALS": "æ“ä½œæäº¤ä»¶",
    "INFORMATIONAL SUBMITTALS": "ä¿¡æ¯æäº¤ä»¶",
    "CLOSEOUT SUBMITTALS": "ç«£å·¥æäº¤ä»¶",
    "QUALITY ASSURANCE": "è´¨é‡ä¿è¯",
    "DELIVERY, STORAGE, AND HANDLING": "äº¤ä»˜ã€å­˜å‚¨å’Œå¤„ç†",
    "FIELD CONDITIONS": "ç°åœºæ¡ä»¶",
    "WARRANTY": "ä¿ä¿®",
    "MAINTENANCE": "ç»´æŠ¤",
}

# ============ å†…å®¹è¿‡æ»¤ ============
def should_skip_paragraph(text: str) -> bool:
    """åˆ¤æ–­æ®µè½æ˜¯å¦åº”è¯¥è¢«å®Œå…¨åˆ é™¤"""
    skip_keywords = [
        "Copyright",
        "The American Institute of Architects",
        "AIA",
        "Exclusively published and distributed by Deltek",
        "TIPS:",
        "TIP:",
        "To view non-printing Editor's Notes",
        "MasterWorks/Single-File Formatting",
        "MasterWorks/Supporting Information",
        "Content Requests:",
        "<Double click here",
        "Double click here",
        "submit questions",
        "comments",
        "suggested edits",
    ]
    for keyword in skip_keywords:
        if keyword.lower() in text.lower():
            return True

    # ä¸å†åˆ é™¤SECTIONè¡Œï¼Œæ”¹ä¸ºåœ¨é¢„å¤„ç†æ—¶å»æ‰å‰ç¼€
    return False

def preprocess_text(text: str, style_name: str = None) -> tuple[str, bool]:
    """é¢„å¤„ç†æ–‡æœ¬ï¼ˆå»æ‰SECTIONå‰ç¼€ï¼Œå»æ‰åˆ—è¡¨ç¼–å·ï¼Œåˆ é™¤è‹±åˆ¶å•ä½ï¼Œç¿»è¯‘ç« èŠ‚æ ‡é¢˜ï¼‰

    è¿”å›: (å¤„ç†åçš„æ–‡æœ¬, æ˜¯å¦å·²ç¿»è¯‘ä¸ºä¸­æ–‡)
    """
    import re

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜ï¼Œç›´æ¥æ›¿æ¢ä¸ºä¸­æ–‡
    text_upper = text.strip().upper()
    if text_upper in SECTION_HEADINGS:
        return (SECTION_HEADINGS[text_upper], True)  # å·²ç¿»è¯‘

    # å¤„ç† "PART æ•°å­— - æ ‡é¢˜" æ¨¡å¼
    # "PART 1 - GENERAL" â†’ "ç¬¬1éƒ¨åˆ† - æ€»åˆ™"
    # "PART 2 - PRODUCTS" â†’ "ç¬¬2éƒ¨åˆ† - äº§å“"
    # "PART 3 - EXECUTION" â†’ "ç¬¬3éƒ¨åˆ† - æ–½å·¥"
    part_match = re.match(r'^PART\s+(\d+)\s*-?\s*(.*)$', text_upper)
    if part_match:
        part_num = part_match.group(1)
        part_title = part_match.group(2).strip()
        # é¢„å®šä¹‰çš„PARTæ ‡é¢˜
        part_titles = {
            "GENERAL": "æ€»åˆ™",
            "PRODUCTS": "äº§å“",
            "EXECUTION": "æ–½å·¥",
            "SUBMITTALS": "æäº¤ä»¶",
        }
        if part_title in part_titles:
            return (f"ç¬¬{part_num}éƒ¨åˆ† - {part_titles[part_title]}", True)
        elif part_title:
            # æœ‰æ ‡é¢˜ä½†ä¸åœ¨é¢„å®šä¹‰ä¸­ï¼Œç¿»è¯‘æ ‡é¢˜
            translated_title = translate_single(part_title)
            return (f"ç¬¬{part_num}éƒ¨åˆ† - {translated_title}", True)
        else:
            # åªæœ‰PARTæ•°å­—
            return (f"ç¬¬{part_num}éƒ¨åˆ†", True)

    # å¤„ç† "END OF SECTION æ•°å­—" æ¨¡å¼
    end_of_section_match = re.match(r'^END OF SECTION\s+([\d\.]+)\s*$', text_upper)
    if end_of_section_match:
        section_num = end_of_section_match.group(1)
        return (f"ç¬¬ {section_num} èŠ‚ç»“æŸ", True)  # å·²ç¿»è¯‘

    # å»æ‰ "SECTION " å‰ç¼€
    # "SECTION 070150.19 - PREPARATION FOR REROOFING" â†’ "070150.19 - PREPARATION FOR REROOFING"
    if text_upper.startswith("SECTION "):
        text = re.sub(r'^SECTION\s+', '', text, flags=re.IGNORECASE)

    # PARTè¦ç¿»è¯‘ï¼Œä¸è¦åˆ é™¤ï¼

    # å¦‚æœæ˜¯åˆ—è¡¨æ ·å¼ï¼ˆPR2, PR3ç­‰ï¼‰ï¼Œå»æ‰æ–‡æœ¬å¼€å¤´çš„ç¼–å·
    # "2. Temporary protection..." â†’ "Temporary protection..."
    if style_name and any(s in style_name.upper() for s in ['PR', 'LIST', 'CMT']):
        # åŒ¹é…å¼€å¤´çš„ "æ•°å­—. " æˆ– "æ•°å­—) "
        text = re.sub(r'^\d+[\.\)]\s+', '', text)

    # åˆ é™¤è‹±åˆ¶å•ä½è¡¨è¾¾å¼
    # ä¾‹å¦‚: "3 lb/100 sq. ft." "15 lb/100 sq. ft." ç­‰
    imperial_patterns = [
        r'\d+(?:\.\d+)?\s*lb/\d+(?:\.\d+)?\s*sq\.\s*ft\.?',  # å¦‚: 3 lb/100 sq. ft.
        r'\d+(?:\.\d+)?\s*lb/\d+(?:\.\d+)?\s*sq\s+ft\.?',    # å¦‚: 3 lb/100 sq ft
        r'\d+(?:\.\d+)?\s*oz/\d+(?:\.\d+)?\s*sq\.\s*ft\.?',  # ç›å¸
        r'\d+(?:\.\d+)?\s*psi',                                # ç£…åŠ›æ¯å¹³æ–¹è‹±å¯¸
        r'\d+(?:\.\d+)?\s*Â°F',                                 # åæ°åº¦
    ]

    for pattern in imperial_patterns:
        # åˆ é™¤è‹±åˆ¶å•ä½ï¼Œä½†ä¿ç•™å‰åçš„ç©ºæ ¼ç»“æ„
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)

    # æ¸…ç†å¤šä½™çš„é€—å·å’Œç©ºæ ¼
    text = re.sub(r',\s*,', ',', text)  # åŒé€—å· â†’ å•é€—å·
    text = re.sub(r'\s+,', ',', text)   # ç©ºæ ¼+é€—å· â†’ é€—å·
    text = re.sub(r',\s+\(', ' (', text) # é€—å·+ç©ºæ ¼+æ‹¬å· â†’ ç©ºæ ¼+æ‹¬å·
    text = re.sub(r'\s{2,}', ' ', text)  # å¤šä¸ªç©ºæ ¼ â†’ å•ç©ºæ ¼

    # æ”¹è¿›çš„å ä½ç¬¦å¤„ç†ï¼šç®€åŒ–ä¸ºä¸­æ–‡æ ‡è®°ï¼Œè®©æ•´å¥ä¸€èµ·ç¿»è¯‘
    # ä¾‹å¦‚ "A. Architect: <Insert name>." -> "A. Architect: ã€ˆå§“åã€‰." -> ç¿»è¯‘å "A. å»ºç­‘å¸ˆï¼šã€ˆå§“åã€‰ã€‚"
    def replace_placeholder(match):
        content = match.group(1).strip()
        # ç®€åŒ–å ä½ç¬¦ä¸ºç®€çŸ­ä¸­æ–‡
        simple_placeholders = {
            'name': 'å§“å',
            'Name': 'å§“å',
            'license #': 'è¯å·',
            'license': 'è¯ä¹¦',
            'load': 'è·è½½',
            'manufacturer': 'åˆ¶é€ å•†',
        }
        for key, value in simple_placeholders.items():
            if key.lower() in content.lower():
                return f'ã€ˆ{value}ã€‰'
        # é»˜è®¤ï¼šç®€åŒ–ä¸º"å¾…å¡«"
        return 'ã€ˆå¾…å¡«ã€‰'

    # æ›¿æ¢å ä½ç¬¦ä½†ä¿ç•™åœ¨å¥å­ä¸­
    text = re.sub(r'<Insert\s+([^>]+)>', replace_placeholder, text, flags=re.IGNORECASE)
    text = re.sub(r'<([^>]{1,50})>', replace_placeholder, text)

    return (text, False)  # æœªç¿»è¯‘ï¼Œéœ€è¦é€VLLM


def postprocess_translation(text: str, style_name: str = None) -> str:
    """åå¤„ç†ç¿»è¯‘ç»“æœï¼ˆç§»é™¤VLLMå¯èƒ½æ·»åŠ çš„ç¼–å·ï¼‰"""
    import re

    # å¦‚æœæ˜¯åˆ—è¡¨æ ·å¼ï¼ˆPR2, PR3, CMTç­‰ï¼‰ï¼Œå»æ‰æ–‡æœ¬å¼€å¤´çš„ç¼–å·
    # è¿™æ˜¯ä¸ºäº†é˜²æ­¢VLLMå¿½ç•¥æç¤ºè¯ï¼Œä»ç„¶æ·»åŠ ç¼–å·
    if style_name and any(s in style_name.upper() for s in ['PR', 'LIST', 'CMT']):
        # ç§»é™¤ä¸­æ–‡ç¼–å·æ ¼å¼ï¼š1. 2. 3. æˆ– 1ã€2ã€3ã€
        text = re.sub(r'^\d+[\.\)ã€]\s+', '', text)

    return text.strip()


def protect_units(text: str) -> tuple[str, dict]:
    """ä¿æŠ¤å•ä½å’Œåˆ—è¡¨ç¼–å·ä¸è¢«ç¿»è¯‘ï¼Œè¿”å›ï¼ˆæ›¿æ¢åçš„æ–‡æœ¬ï¼Œæ˜ å°„è¡¨ï¼‰"""
    import re

    units_map = {}
    counter = 0

    # âš ï¸ é¦–å…ˆä¿æŠ¤ASTMæ ‡å‡†ç¼–å·ï¼ˆå¿…é¡»åœ¨å•ä½æ¨¡å¼ä¹‹å‰ï¼ï¼‰
    # æ ¼å¼1: ASTM D4601/D4601M (å¸¦æ–œæ çš„å®Œæ•´æ ¼å¼)
    # æ ¼å¼2: ASTM D4601M æˆ– ASTM C1177M (å•ç‹¬çš„å…¬åˆ¶ç‰ˆæœ¬)
    # æ ¼å¼3: ASTM D4601 (æ ‡å‡†ç‰ˆæœ¬)
    # è¿™æ ·å¯ä»¥é¿å…Måç¼€è¢«è¯¯è®¤ä¸ºç±³(meter)å•ä½
    astm_pattern = r'ASTM\s+[A-Z]\d+(?:/[A-Z]\d+)?M?'
    for match in re.finditer(astm_pattern, text):
        placeholder = f'âŸ¨âŸ¨ASTM_{counter}âŸ©âŸ©'
        units_map[placeholder] = match.group(0)
        text = text.replace(match.group(0), placeholder, 1)
        counter += 1

    # å®šä¹‰éœ€è¦ä¿æŠ¤çš„å•ä½æ¨¡å¼ï¼ˆâš ï¸ åªä¿æŠ¤å…¬åˆ¶å•ä½ï¼ï¼‰
    # âš ï¸ é‡è¦ï¼šå¤åˆå•ä½å¿…é¡»åœ¨ç®€å•å•ä½ä¹‹å‰ï¼
    unit_patterns = [
        # å…¬åˆ¶å¤åˆå•ä½ï¼ˆå¿…é¡»åœ¨å‰é¢ï¼Œå¦åˆ™ä¼šè¢«éƒ¨åˆ†åŒ¹é…ï¼‰
        r'\d+(?:\.\d+)?\s*kg/sq\.\s*m',     # é¢å¯†åº¦ï¼ˆè‹±åˆ¶å†™æ³•ï¼Œå¦‚ 0.16 kg/sq. mï¼‰
        r'\d+(?:\.\d+)?\s*kg/cu\.\s*m',     # ä½“ç§¯å¯†åº¦ï¼ˆè‹±åˆ¶å†™æ³•ï¼‰
        r'\d+(?:\.\d+)?\s*kg/mÂ²',           # é¢å¯†åº¦ï¼ˆå…¬åˆ¶ç¬¦å·ï¼‰
        r'\d+(?:\.\d+)?\s*kg/mÂ³',           # ä½“ç§¯å¯†åº¦ï¼ˆå…¬åˆ¶ç¬¦å·ï¼‰
        r'\d+(?:\.\d+)?\s*N/mmÂ²',           # å‹å¼º
        r'\d+(?:\.\d+)?\s*W/mÂ²',            # åŠŸç‡å¯†åº¦
        r'\d+(?:\.\d+)?\s*mmÂ²',             # é¢ç§¯
        r'\d+(?:\.\d+)?\s*mÂ²',              # é¢ç§¯
        r'\d+(?:\.\d+)?\s*mÂ³',              # ä½“ç§¯

        # å…¬åˆ¶åŸºæœ¬å•ä½ï¼ˆåœ¨å¤åˆå•ä½ä¹‹åï¼ŒæŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­ï¼‰
        r'\d+(?:\.\d+)?\s*(?:kPa|MPa)',     # å‹å¼ºï¼ˆ3-4å­—æ¯ï¼‰
        r'\d+(?:\.\d+)?\s*(?:mm|cm|km|ml|Pa)(?![Â²Â³/a-z])',  # 2å­—æ¯å…¬åˆ¶å•ä½
        r'\d+(?:\.\d+)?\s*Â°C',              # æ¸©åº¦: Â°C
        r'\d+(?:\.\d+)?\s*(?:m|g|t|l|L)(?![Â²Â³/a-zA-Z])',  # 1å­—æ¯å…¬åˆ¶å•ä½ï¼ˆæœ€åï¼Œé˜²æ­¢éƒ¨åˆ†åŒ¹é…ï¼‰
    ]

    # ä¿æŠ¤åˆ—è¡¨ç¼–å·ï¼ˆå¿…é¡»åœ¨è¡Œé¦–æˆ–æ®µè½å¼€å¤´ï¼‰
    # æ ¼å¼: "a. " "1. " "A. " "I. " "(1) " ç­‰
    list_number_patterns = [
        r'^([a-z]\.\s+)',         # a. b. c. ç­‰
        r'^([A-Z]\.\s+)',         # A. B. C. ç­‰
        r'^(\d+\.\s+)',           # 1. 2. 3. ç­‰
        r'^([ivxlcdm]+\.\s+)',    # i. ii. iii. ç­‰ï¼ˆç½—é©¬æ•°å­—å°å†™ï¼‰
        r'^([IVXLCDM]+\.\s+)',    # I. II. III. ç­‰ï¼ˆç½—é©¬æ•°å­—å¤§å†™ï¼‰
        r'^(\(\d+\)\s+)',         # (1) (2) (3) ç­‰
        r'^(\([a-z]\)\s+)',       # (a) (b) (c) ç­‰
        r'^(\([A-Z]\)\s+)',       # (A) (B) (C) ç­‰
    ]

    def replace_marker(match):
        nonlocal counter
        marker_text = match.group(0)
        # ä½¿ç”¨æ›´ç‰¹æ®Šçš„æ ¼å¼ï¼Œé¿å…è¢«ç¿»è¯‘APIä¿®æ”¹
        placeholder = f"âŸ¨âŸ¨UNIT{counter:04d}âŸ©âŸ©"
        units_map[placeholder] = marker_text
        counter += 1
        return placeholder

    result = text

    # å…ˆä¿æŠ¤åˆ—è¡¨ç¼–å·ï¼ˆåœ¨è¡Œé¦–ï¼Œä½¿ç”¨MULTILINEæ¨¡å¼ï¼‰
    for pattern in list_number_patterns:
        result = re.sub(pattern, replace_marker, result, flags=re.MULTILINE)

    # å†ä¿æŠ¤å•ä½
    for pattern in unit_patterns:
        result = re.sub(pattern, replace_marker, result, flags=re.IGNORECASE)

    return result, units_map

def restore_units(text: str, units_map: dict) -> str:
    """æ¢å¤è¢«ä¿æŠ¤çš„å•ä½ï¼Œå¹¶è½¬æ¢ä¸ºç¬¦å·æ ¼å¼"""
    import re

    result = text
    for placeholder, unit in units_map.items():
        # è½¬æ¢è‹±æ–‡å•ä½ä¸ºç¬¦å·æ ¼å¼
        converted_unit = unit

        # kg/sq. m â†’ kg/mÂ² (å¤„ç†éæ–­ç©ºæ ¼ \xa0)
        converted_unit = re.sub(r'kg/sq\.\s*m', 'kg/mÂ²', converted_unit, flags=re.IGNORECASE)
        # kg/cu. m â†’ kg/mÂ³
        converted_unit = re.sub(r'kg/cu\.\s*m', 'kg/mÂ³', converted_unit, flags=re.IGNORECASE)
        # lb/sq. ft â†’ lb/ftÂ²
        converted_unit = re.sub(r'lb/sq\.\s*ft', 'lb/ftÂ²', converted_unit, flags=re.IGNORECASE)
        # sq. ft â†’ ftÂ²
        converted_unit = re.sub(r'sq\.\s*ft', 'ftÂ²', converted_unit, flags=re.IGNORECASE)
        # cu. m â†’ mÂ³
        converted_unit = re.sub(r'cu\.\s*m', 'mÂ³', converted_unit, flags=re.IGNORECASE)

        result = result.replace(placeholder, converted_unit)
    return result

def apply_translation_with_colors(para, translated_text, unit_colors):
    """åº”ç”¨ç¿»è¯‘åˆ°æ®µè½ï¼Œå¹¶æ¢å¤å•ä½çš„é¢œè‰²ï¼ˆå…¬åˆ¶å•ä½è‡ªåŠ¨è®¾ç½®ä¸ºè“ç»¿è‰²ï¼‰"""
    import re
    from docx.shared import RGBColor

    # å®šä¹‰è“ç»¿è‰²ï¼ˆTealï¼‰
    TEAL_COLOR = RGBColor(0, 176, 176)  # è“ç»¿è‰² #00B0B0

    # æ£€æŸ¥ç¿»è¯‘åçš„æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«å…¬åˆ¶å•ä½
    # æ³¨æ„ï¼šASTMæ ‡å‡†ç¼–å·å·²åœ¨protect_units()ä¸­ä¿æŠ¤ï¼Œä¸ä¼šè¢«åŒ¹é…
    unit_pattern = r'\d+(?:\.\d+)?\s*(?:kg/sq\.\s*m|kg/cu\.\s*m|kg/mÂ²|kg/mÂ³|N/mmÂ²|W/mÂ²|mmÂ²|mÂ²|mÂ³|kPa|MPa|mm|cm|km|ml|Pa|Â°C)(?![Â²Â³/a-z])|\d+(?:\.\d+)?\s*(?:m|g|t|l|L)(?![Â²Â³/a-zA-Z])'
    has_units = bool(re.search(unit_pattern, translated_text, re.IGNORECASE))

    # å¦‚æœæ²¡æœ‰å•ä½ï¼ŒæŒ‰åŸæ¥çš„æ–¹å¼å¤„ç†
    if not has_units:
        if len(para.runs) == 1:
            original_run = para.runs[0]
            original_bold = original_run.bold
            original_italic = original_run.italic
            original_underline = original_run.underline
            original_font_size = original_run.font.size
            original_font_color = original_run.font.color.rgb if original_run.font.color and original_run.font.color.rgb else None

            original_run.text = translated_text

            if original_bold is not None:
                original_run.bold = original_bold
            if original_italic is not None:
                original_run.italic = original_italic
            if original_underline is not None:
                original_run.underline = original_underline
            if original_font_size:
                original_run.font.size = original_font_size
            if original_font_color:
                original_run.font.color.rgb = original_font_color
            original_run.font.name = 'å®‹ä½“'
        else:
            # å¤šä¸ªrunï¼Œç®€åŒ–å¤„ç†
            first_run = para.runs[0]
            first_run.text = translated_text
            for run in para.runs[1:]:
                run.text = ''
        return

    # æœ‰å•ä½é¢œè‰²ï¼Œéœ€è¦æ‹†åˆ†å¹¶åº”ç”¨é¢œè‰²
    # âš ï¸ é‡è¦ï¼šåœ¨æ‹†åˆ†æ–‡æœ¬ä¹‹å‰ï¼Œå…ˆä¸´æ—¶ä¿æŠ¤ASTMæ ‡å‡†ç¼–å·ï¼
    # å› ä¸ºæ­¤æ—¶translated_textä¸­çš„ASTMå ä½ç¬¦å·²ç»è¢«restore_units()æ¢å¤äº†
    # å¦‚æœä¸ä¿æŠ¤ï¼Œä¼šåŒ¹é…åˆ°ASTMç¼–å·ä¸­çš„Måç¼€
    astm_pattern = r'ASTM\s+[A-Z]\d+(?:/[A-Z]\d+)?M?'
    astm_placeholders = {}
    astm_counter = 0
    temp_text = translated_text
    for match in re.finditer(astm_pattern, temp_text):
        placeholder = f'âŸ¨âŸ¨TEMP_ASTM_{astm_counter}âŸ©âŸ©'
        astm_placeholders[placeholder] = match.group(0)
        temp_text = temp_text.replace(match.group(0), placeholder, 1)
        astm_counter += 1

    # æ‰¾åˆ°æ‰€æœ‰å…¬åˆ¶å•ä½çš„ä½ç½®ï¼ˆå¿…é¡»ä¸protect_units()ä¸­çš„é¡ºåºä¿æŒä¸€è‡´ï¼‰
    unit_pattern = r'\d+(?:\.\d+)?\s*(?:kg/sq\.\s*m|kg/cu\.\s*m|kg/mÂ²|kg/mÂ³|N/mmÂ²|W/mÂ²|mmÂ²|mÂ²|mÂ³|kPa|MPa|mm|cm|km|ml|Pa|Â°C)(?![Â²Â³/a-z])|\d+(?:\.\d+)?\s*(?:m|g|t|l|L)(?![Â²Â³/a-zA-Z])'

    # åˆ†å‰²æ–‡æœ¬ï¼Œä¿ç•™å•ä½ï¼ˆä½¿ç”¨ä¸´æ—¶ä¿æŠ¤åçš„æ–‡æœ¬ï¼‰
    parts = re.split(f'({unit_pattern})', temp_text, flags=re.IGNORECASE)

    # ä¿å­˜ç¬¬ä¸€ä¸ªrunçš„æ ¼å¼
    if para.runs:
        first_run = para.runs[0]
        default_bold = first_run.bold
        default_italic = first_run.italic
        default_underline = first_run.underline
        default_font_size = first_run.font.size
        default_font_color = first_run.font.color.rgb if first_run.font.color and first_run.font.color.rgb else None
    else:
        default_bold = None
        default_italic = None
        default_underline = None
        default_font_size = None
        default_font_color = None

    # æ¸…ç©ºæ‰€æœ‰runs
    for run in para.runs[:]:
        run._element.getparent().remove(run._element)

    # é‡å»ºruns
    for part in parts:
        if not part:
            continue

        # âš ï¸ æ¢å¤ASTMå ä½ç¬¦
        final_part = part
        for placeholder, astm_text in astm_placeholders.items():
            final_part = final_part.replace(placeholder, astm_text)

        run = para.add_run(final_part)

        # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä½ï¼ˆåœ¨å ä½ç¬¦æ›¿æ¢å‰æ£€æŸ¥ï¼‰
        is_unit = bool(re.match(unit_pattern, part, re.IGNORECASE))

        if is_unit:
            # å…¬åˆ¶å•ä½å§‹ç»ˆä½¿ç”¨è“ç»¿è‰²
            run.font.color.rgb = TEAL_COLOR
        else:
            # éå•ä½éƒ¨åˆ†ï¼Œåº”ç”¨é»˜è®¤æ ¼å¼
            if default_font_color:
                run.font.color.rgb = default_font_color

        # åº”ç”¨å…¶ä»–æ ¼å¼
        if default_bold is not None:
            run.bold = default_bold
        if default_italic is not None:
            run.italic = default_italic
        if default_underline is not None:
            run.underline = default_underline
        if default_font_size:
            run.font.size = default_font_size
        run.font.name = 'å®‹ä½“'

def should_skip_by_style(style_name: str) -> bool:
    """æ ¹æ®æ ·å¼åˆ¤æ–­æ˜¯å¦åˆ é™¤ï¼ˆç©ºçš„CMT/TIPæ®µè½ï¼‰"""
    skip_styles = ["CMT", "TIP"]
    return style_name in skip_styles

# ============ LibreOffice è½¬æ¢ ============
def convert_doc_to_docx(input_file: Path, output_file: Path) -> bool:
    """ç”¨ LibreOffice è½¬æ¢ DOC â†’ DOCX (ä½¿ç”¨ä¸´æ—¶ç”¨æˆ·é…ç½®é¿å…Javaé—®é¢˜)"""
    import tempfile
    import shutil

    try:
        output_file.parent.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºä¸´æ—¶ç”¨æˆ·é…ç½®æ–‡ä»¶ç›®å½•
        user_profile = tempfile.mkdtemp(prefix='libreoffice_')

        try:
            result = subprocess.run([
                LIBREOFFICE,
                '--headless',
                '--invisible',
                '--nocrashreport',
                '--nodefault',
                '--nofirststartwizard',
                '--nolockcheck',
                '--nologo',
                '--norestore',
                f'-env:UserInstallation=file://{user_profile}',
                '--convert-to', 'docx:MS Word 2007 XML',
                '--outdir', str(output_file.parent),
                str(input_file)
            ], capture_output=True, text=True, timeout=60)

            # LibreOffice ä¼šç”ŸæˆåŒåçš„ .docx æ–‡ä»¶
            generated_file = output_file.parent / (input_file.stem + '.docx')

            if generated_file.exists() and generated_file != output_file:
                # é‡å‘½åä¸ºç›®æ ‡æ–‡ä»¶å
                generated_file.rename(output_file)
                return True
            elif output_file.exists():
                return True
            else:
                print(f"  âŒ è½¬æ¢å¤±è´¥: {result.stderr}")
                return False
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(user_profile)
            except:
                pass

    except Exception as e:
        print(f"  âŒ è½¬æ¢é”™è¯¯: {e}")
        return False

# ============ ç¿»è¯‘API ============
def translate_single(text: str) -> str:
    if not text.strip():
        return text

    prompt = f"""å°†ä»¥ä¸‹è‹±æ–‡å®Œæ•´ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¸è¦é—æ¼ä»»ä½•å•è¯ï¼š

{text}

ç¿»è¯‘ç»“æœï¼š"""

    try:
        response = requests.post(
            f"{VLLM_URL}/v1/chat/completions",
            json={
                "model": VLLM_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.1,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç¿»è¯‘
                "max_tokens": 2000
            },
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()['choices'][0]['message']['content'].strip()

            # ç§»é™¤thinkingæ ‡ç­¾
            if '<think>' in result:
                if '</think>' in result:
                    result = result.split('</think>')[-1].strip()
                else:
                    return text

            # ç§»é™¤å‰ç¼€
            prefixes = ["ä¸­æ–‡ï¼š", "ç¿»è¯‘ï¼š", "ç¿»è¯‘ç»“æœï¼š", "è¯‘æ–‡ï¼š"]
            for prefix in prefixes:
                if result.startswith(prefix):
                    result = result.split("ï¼š", 1)[1].strip()
                    break

            # åªå–ç¬¬ä¸€è¡Œï¼ˆé¿å…æ¨¡å‹è¾“å‡ºå¤šè¡Œè§£é‡Šï¼‰
            result = result.split('\n')[0].strip()

            return result if result else text
        return text
    except Exception as e:
        print(f"    âš ï¸ ç¿»è¯‘å¤±è´¥: {e}")
        return text

def remove_imperial_units(text: str) -> str:
    """åˆ é™¤è‹±åˆ¶å•ä½ï¼ˆä¿ç•™æ‹¬å·ä¸­çš„å…¬åˆ¶å•ä½ï¼‰

    å¤„ç†å„ç§æ ¼å¼ï¼š
    - æ•´æ•°: "9 inch (230 mm)"
    - åˆ†æ•°: "1/4 inch (6 mm)", "15/32 inch (12 mm)"
    - å¸¦è¿å­—ç¬¦: "1-inch- (25-mm-)", "15/32-inch (12-mm)"
    """
    import re

    # æ•°å­—æ¨¡å¼ï¼šæ”¯æŒæ•´æ•°ã€å°æ•°ã€åˆ†æ•°ï¼ˆå¦‚ 1/4, 15/32ï¼‰
    # ç¤ºä¾‹: "1", "1.5", "1/4", "15/32"
    num_pattern = r'\d+(?:/\d+)?(?:\.\d+)?'

    # ç­–ç•¥ï¼šåŒ¹é…"è‹±åˆ¶å•ä½ (å…¬åˆ¶å•ä½)"è¿™ç§æ¨¡å¼ï¼Œåªä¿ç•™æ‹¬å·éƒ¨åˆ†
    # æ¯”å¦‚ "9 inch (230 mm)" â†’ "(230 mm)"
    # æ¯”å¦‚ "1/4 inch (6 mm)" â†’ "(6 mm)"
    # æ¯”å¦‚ "1-inch- (25-mm-)" â†’ "(25-mm-)"

    # æ¨¡å¼1: æ•°å­— + è‹±åˆ¶å•ä½ + (å…¬åˆ¶å•ä½) â†’ åªä¿ç•™ (å…¬åˆ¶å•ä½)
    patterns_with_metric = [
        # "9 inch (230 mm)" ç±»å‹ï¼Œæ”¯æŒè¿å­—ç¬¦å’Œåˆ†æ•°
        rf'{num_pattern}\s*-?\s*(?:inch|inches|in\.?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:foot|feet|ft\.?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:yard|yards|yd\.?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:mile|miles|mi\.?)\s*-?\s*(\([^)]+\))',

        # "3 lb/100 sq. ft. (1.5 kg/mÂ²)" ç±»å‹
        rf'{num_pattern}\s*lbs?\.?/{num_pattern}\s*sq\.?\s*ft\.?\s*(\([^)]+\))',

        # "XX lb/cu. ft. (128 kg/cu. m)" ç±»å‹
        rf'{num_pattern}\s*lbs?\.?/cu\.?\s*ft\.?\s*(\([^)]+\))',

        # å…¶ä»–å¤åˆå•ä½
        rf'{num_pattern}\s*-?\s*(?:pound|pounds|lb\.?|lbs\.?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:sq\.?\s*ft\.?|square\s+feet?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:sq\.?\s*in\.?|square\s+inches?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:cu\.?\s*ft\.?|cubic\s+feet?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:ounce|ounces|oz\.?)\s*-?\s*(\([^)]+\))',
        rf'{num_pattern}\s*-?\s*(?:gallon|gallons|gal\.?)\s*-?\s*(\([^)]+\))',
    ]

    result = text

    # æ›¿æ¢ä¸ºåªä¿ç•™æ‹¬å·éƒ¨åˆ†
    for pattern in patterns_with_metric:
        result = re.sub(pattern, r'\1', result, flags=re.IGNORECASE)

    # æ¨¡å¼2: åˆ é™¤æ²¡æœ‰å…¬åˆ¶å•ä½çš„è‹±åˆ¶å•ä½
    # ï¼ˆå¦‚æœåé¢æ²¡æœ‰æ‹¬å·ï¼Œå°±ç›´æ¥åˆ é™¤ï¼‰
    # æ³¨æ„ï¼šé•¿å•è¯åœ¨å‰ï¼ˆinches before inchï¼‰ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
    standalone_imperial = [
        rf'{num_pattern}\s*-?\s*(?:inches|inch|in\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:feet|foot|ft\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:yards|yard|yd\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:miles|mile|mi\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:pounds|pound|lbs?\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:ounces|ounce|oz\.?)(?!\s*\()',
        rf'{num_pattern}\s*-?\s*(?:square\s+feet|square\s+foot|sq\.?\s*ft\.?)(?!\s*\()',
        rf'{num_pattern}\s*lbs?\.?/{num_pattern}\s*sq\.?\s*ft\.?(?!\s*\()',
    ]

    for pattern in standalone_imperial:
        result = re.sub(pattern, '', result, flags=re.IGNORECASE)

    # æ¨¡å¼3: æ¸…ç†æ®‹ç•™çš„å•ä½ï¼ˆæ¯”å¦‚å‰é¢æ•°å­—è¢«åˆ é™¤åå‰©ä¸‹çš„ "/cu. ft."ï¼‰
    leftover_units = [
        r'/\s*cu\.?\s*ft\.?',  # /cu. ft.
        r'/\s*sq\.?\s*ft\.?',  # /sq. ft.
        r'/\s*cu\.?\s*in\.?',  # /cu. in.
        r'/\s*sq\.?\s*in\.?',  # /sq. in.
    ]

    for pattern in leftover_units:
        result = re.sub(pattern, '', result, flags=re.IGNORECASE)

    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œæ ‡ç‚¹
    result = re.sub(r'\s+', ' ', result)  # å¤šä¸ªç©ºæ ¼å˜ä¸€ä¸ª
    result = re.sub(r'\s*,\s*,', ',', result)  # åˆ é™¤å¤šä½™çš„é€—å·
    result = re.sub(r'\s*:\s*\(', ' (', result)  # "Thickness: (xxx)" â†’ "Thickness (xxx)"
    result = re.sub(r'\[\s*/\s*\(', '[(', result)  # "[/ (" â†’ "[("
    result = result.strip()

    return result

def translate_placeholders(text: str) -> str:
    """åªç¿»è¯‘å ä½ç¬¦ï¼ˆä¸åˆ é™¤è‹±åˆ¶å•ä½ï¼‰"""
    replacements = {
        "<Insert name>": "<æ’å…¥å§“å>",
        "<Insert Name>": "<æ’å…¥å§“å>",
        "<insert name>": "<æ’å…¥å§“å>",
        "<Insert license #>": "<æ’å…¥è®¸å¯è¯ç¼–å·>",
        "<Insert License #>": "<æ’å…¥è®¸å¯è¯ç¼–å·>",
        "<Insert list of Sections>": "<æ’å…¥ç« èŠ‚åˆ—è¡¨>",
        "<Insert List of Sections>": "<æ’å…¥ç« èŠ‚åˆ—è¡¨>",
        "<Insert section list>": "<æ’å…¥ç« èŠ‚åˆ—è¡¨>",
        "<Insert address>": "<æ’å…¥åœ°å€>",
        "<Insert Address>": "<æ’å…¥åœ°å€>",
        "<Insert phone>": "<æ’å…¥ç”µè¯>",
        "<Insert Phone>": "<æ’å…¥ç”µè¯>",
        "<Insert email>": "<æ’å…¥é‚®ç®±>",
        "<Insert Email>": "<æ’å…¥é‚®ç®±>",
        "<Insert date>": "<æ’å…¥æ—¥æœŸ>",
        "<Insert Date>": "<æ’å…¥æ—¥æœŸ>",
        "<Insert project name>": "<æ’å…¥é¡¹ç›®åç§°>",
        "<Insert Project Name>": "<æ’å…¥é¡¹ç›®åç§°>",
        "<Insert description>": "<æ’å…¥æè¿°>",
        "<Insert Description>": "<æ’å…¥æè¿°>",
        "<Insert value>": "<æ’å…¥æ•°å€¼>",
        "<Insert Value>": "<æ’å…¥æ•°å€¼>",
        "<Insert location>": "<æ’å…¥ä½ç½®>",
        "<Insert Location>": "<æ’å…¥ä½ç½®>",
        "<Insert area>": "<æ’å…¥é¢ç§¯>",
        "<Insert Area>": "<æ’å…¥é¢ç§¯>",
        "<Insert dimension>": "<æ’å…¥å°ºå¯¸>",
        "<Insert Dimension>": "<æ’å…¥å°ºå¯¸>",
    }

    result = text
    for eng, chn in replacements.items():
        result = result.replace(eng, chn)

    return result

def translate_batch(texts: List[str]) -> List[str]:
    if not texts:
        return []

    non_empty_indices = [i for i, t in enumerate(texts) if t.strip()]
    non_empty_texts = [texts[i] for i in non_empty_indices]

    if not non_empty_texts:
        return texts

    combined = "\n---SPLIT---\n".join(non_empty_texts)
    prompt = f"""ä½ æ˜¯å»ºç­‘å·¥ç¨‹è§„èŒƒç¿»è¯‘ä¸“å®¶ã€‚å°†ä»¥ä¸‹è‹±æ–‡æ®µè½ç¿»è¯‘æˆä¸­æ–‡ï¼ˆæ®µè½ä¹‹é—´ç”¨---SPLIT---åˆ†éš”ï¼‰ï¼š

{combined}

ç¿»è¯‘è¦æ±‚ï¼š
1. **å¿…é¡»ç¿»è¯‘æ‰€æœ‰æ–‡æœ¬**ï¼ŒåŒ…æ‹¬å…¨å¤§å†™çš„ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ACTION SUBMITTALS"ç¿»è¯‘ä¸º"æ“ä½œæäº¤ä»¶"ï¼‰
2. ä¿ç•™ä¸“ä¸šç¼©å†™ï¼ˆå¦‚ASTMã€EPSã€OSBä¿æŒä¸å˜ï¼‰
3. **ä¸è¦æ·»åŠ ä»»ä½•æ•°å­—ç¼–å·**ï¼Œä¿æŒåŸæ–‡æ ¼å¼
4. ç”¨---SPLIT---åˆ†éš”æ¯ä¸ªç¿»è¯‘ç»“æœ
5. åªè¾“å‡ºç¿»è¯‘ï¼Œä¸è¦æ·»åŠ è§£é‡Š

ä¸­æ–‡ç¿»è¯‘ï¼š"""

    try:
        response = requests.post(
            f"{VLLM_URL}/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": VLLM_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": len(combined) * 3
            },
            timeout=600
        )

        if response.status_code == 200:
            result = response.json()
            translated = result['choices'][0]['message']['content'].strip()

            if '<think>' in translated:
                if '</think>' in translated:
                    translated = translated.split('</think>')[-1].strip()
                else:
                    return [translate_single(t) for t in texts]

            if translated.startswith("ç¿»è¯‘ï¼š") or translated.startswith("ä¸­æ–‡ç¿»è¯‘ï¼š"):
                translated = translated.split("ï¼š", 1)[1].strip()

            parts = translated.split("---SPLIT---")

            if len(parts) == len(non_empty_texts):
                results = texts.copy()
                for i, idx in enumerate(non_empty_indices):
                    results[idx] = parts[i].strip()
                return results
            else:
                return [translate_single(t) for t in texts]
        else:
            return texts
    except Exception as e:
        return [translate_single(t) for t in texts]

# ============ ç¿»è¯‘DOCXæ–‡æ¡£ ============
def translate_docx(docx_file: Path) -> bool:
    """ç¿»è¯‘DOCXæ–‡æ¡£ï¼ˆå®Œå…¨ä¿ç•™æ ·å¼ï¼‰"""
    try:
        from docx import Document

        doc = Document(str(docx_file))

        # ç§»é™¤é¡µçœ‰é¡µè„šï¼ˆå®Œå…¨åˆ é™¤æ‰€æœ‰XMLå†…å®¹åŒ…æ‹¬è¡¨æ ¼ï¼‰
        for section in doc.sections:
            section.header.is_linked_to_previous = False
            section.footer.is_linked_to_previous = False

            # å½»åº•æ¸…ç©ºé¡µçœ‰ï¼ˆåŒ…æ‹¬æ®µè½å’Œè¡¨æ ¼ï¼‰
            section.header._element.clear()
            section.first_page_header._element.clear()
            section.even_page_header._element.clear()

            # å½»åº•æ¸…ç©ºé¡µè„šï¼ˆåŒ…æ‹¬æ®µè½å’Œè¡¨æ ¼ï¼‰
            section.footer._element.clear()
            section.first_page_footer._element.clear()
            section.even_page_footer._element.clear()

        # ========== åˆ é™¤æ‰€æœ‰æ–‡æœ¬æ¡†ï¼ˆåŒ…æ‹¬TIPæ¡†ï¼‰==========
        print("  ğŸ—‘ï¸  åˆ é™¤æ–‡æœ¬æ¡†...")
        deleted_textbox_count = 0
        try:
            # æ–¹æ³•1: åˆ é™¤æ®µè½ä¸­çš„æ–‡æœ¬æ¡†
            paragraphs_with_textbox = []
            for para in doc.paragraphs:
                para_xml = para._element.xml
                if b'<w:txbxContent>' in para_xml or b'<v:textbox>' in para_xml:
                    paragraphs_with_textbox.append(para)

            for para in paragraphs_with_textbox:
                p_element = para._element
                p_element.getparent().remove(p_element)
                deleted_textbox_count += 1

            # æ–¹æ³•2: åˆ é™¤bodyä¸­çš„ç‹¬ç«‹shapeå¯¹è±¡
            body = doc._element.body

            # åˆ é™¤ç°ä»£æ ¼å¼çš„æ–‡æœ¬æ¡† (drawing with txbx)
            for drawing in body.findall('.//w:drawing', namespaces=body.nsmap):
                if drawing.find('.//wps:txbx', namespaces=body.nsmap) is not None:
                    parent = drawing.getparent()
                    if parent is not None:
                        parent.remove(drawing)
                        deleted_textbox_count += 1

            # åˆ é™¤VMLæ ¼å¼çš„æ–‡æœ¬æ¡†ï¼ˆæ—§ç‰ˆWordï¼‰
            for shape in body.findall('.//v:shape', namespaces={'v': 'urn:schemas-microsoft-com:vml'}):
                if shape.find('.//v:textbox', namespaces={'v': 'urn:schemas-microsoft-com:vml'}) is not None:
                    parent = shape.getparent()
                    if parent is not None:
                        parent.remove(shape)
                        deleted_textbox_count += 1

            print(f"  âœ… å·²åˆ é™¤ {deleted_textbox_count} ä¸ªæ–‡æœ¬æ¡†")
        except Exception as e:
            print(f"  âš ï¸  æ–‡æœ¬æ¡†åˆ é™¤è­¦å‘Š: {e}")

        # ç¬¬ä¸€æ­¥ï¼šæ ‡è®°å¹¶åˆ é™¤éœ€è¦è·³è¿‡çš„æ®µè½
        paragraphs_to_delete = []
        skipped_count = 0

        for para in doc.paragraphs:
            # åˆ é™¤æ¡ä»¶1ï¼šåŒ…å«è·³è¿‡å…³é”®è¯çš„æ®µè½
            if para.text.strip() and should_skip_paragraph(para.text):
                paragraphs_to_delete.append(para)
                skipped_count += 1
            # åˆ é™¤æ¡ä»¶2ï¼šç©ºçš„CMT/TIPæ®µè½
            elif not para.text.strip() and should_skip_by_style(para.style.name):
                paragraphs_to_delete.append(para)
                skipped_count += 1

        # åˆ é™¤æ ‡è®°çš„æ®µè½
        for para in paragraphs_to_delete:
            p_element = para._element
            p_element.getparent().remove(p_element)

        # ç¬¬äºŒæ­¥ï¼šæ”¶é›†éœ€è¦ç¿»è¯‘çš„æ®µè½ï¼ˆåŒæ—¶è®°å½•å•ä½çš„é¢œè‰²ï¼‰
        paragraphs_to_translate = []
        for para in doc.paragraphs:
            if para.text.strip():
                # æ‰«ærunï¼Œæ‰¾åˆ°åŒ…å«å•ä½çš„é¢œè‰²
                unit_colors = {}  # {å•ä½æ–‡æœ¬: RGBé¢œè‰²}
                for run in para.runs:
                    if run.text and run.font.color and run.font.color.rgb:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å•ä½æ¨¡å¼ï¼ˆä¸protect_unitsä¿æŒä¸€è‡´ï¼‰
                        import re
                        unit_pattern = r'\d+(?:\.\d+)?\s*(?:kg/sq\.\s*m|kg/cu\.\s*m|lb/sq\.\s*ft|kg/mÂ²|kg/mÂ³|N/mmÂ²|W/mÂ²|mmÂ²|mÂ²|mÂ³|sq\.\s*ft|cu\.\s*m|mm|cm|m|km|ft|in|kg|g|t|lb|ml|l|L|Â°C|Pa|kPa|MPa|kW)'
                        units = re.findall(unit_pattern, run.text, re.IGNORECASE)
                        for unit in units:
                            unit_colors[unit.strip()] = run.font.color.rgb

                # ä¿å­˜æ®µè½æ ¼å¼ï¼ˆç”¨äºåç»­æ¢å¤ï¼‰
                para_format = {
                    'space_before': para.paragraph_format.space_before,
                    'space_after': para.paragraph_format.space_after,
                    'line_spacing': para.paragraph_format.line_spacing,
                    'line_spacing_rule': para.paragraph_format.line_spacing_rule
                }

                paragraphs_to_translate.append({
                    'paragraph': para,
                    'unit_colors': unit_colors,
                    'format': para_format
                })

        total = len(paragraphs_to_translate)
        print(f"  ğŸ“Š å…±éœ€ç¿»è¯‘ {total} ä¸ªæ®µè½")

        # æ‰¹é‡ç¿»è¯‘
        for i in range(0, total, BATCH_SIZE):
            current_batch = min(i + BATCH_SIZE, total)
            progress = f"[{current_batch}/{total}]"
            print(f"  ğŸ”„ {progress} æ­£åœ¨ç¿»è¯‘...")

            batch_data = paragraphs_to_translate[i:i+BATCH_SIZE]
            batch_paras = [item['paragraph'] for item in batch_data]
            batch_texts = [p.text for p in batch_paras]

            # ç¬¬1æ­¥ï¼šé¢„å¤„ç†ï¼ˆå»æ‰SECTIONå‰ç¼€ï¼Œå»æ‰åˆ—è¡¨ç¼–å·ç­‰ï¼‰
            # è¿”å› (æ–‡æœ¬, æ˜¯å¦å·²ç¿»è¯‘)
            preprocess_results = [preprocess_text(text, para.style.name if para.style else None)
                                 for text, para in zip(batch_texts, batch_paras)]
            batch_texts = [result[0] for result in preprocess_results]
            already_translated = [result[1] for result in preprocess_results]

            # ç¬¬2æ­¥ï¼šåˆ é™¤è‹±åˆ¶å•ä½ï¼ˆåœ¨ç¿»è¯‘ä¹‹å‰ï¼‰
            batch_texts = [remove_imperial_units(t) for t in batch_texts]

            # ç¬¬3æ­¥ï¼šä¿æŠ¤å•ä½ä¸è¢«ç¿»è¯‘
            protected_texts = []
            units_maps = []
            for text in batch_texts:
                protected_text, units_map = protect_units(text)
                protected_texts.append(protected_text)
                units_maps.append(units_map)

            # ç¬¬4æ­¥ï¼šç¿»è¯‘ï¼ˆè·³è¿‡å·²ç¿»è¯‘çš„ï¼‰
            translated_texts = []
            texts_to_translate = []
            indices_to_translate = []

            for idx, (text, is_translated) in enumerate(zip(protected_texts, already_translated)):
                if is_translated:
                    # å·²ç»æ˜¯ä¸­æ–‡ï¼Œä¸éœ€è¦ç¿»è¯‘
                    translated_texts.append(text)
                else:
                    # éœ€è¦ç¿»è¯‘
                    texts_to_translate.append(text)
                    indices_to_translate.append(idx)
                    translated_texts.append(None)  # å ä½

            # åªç¿»è¯‘éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬
            if texts_to_translate:
                vllm_translations = translate_batch(texts_to_translate)
                # å¡«å›ç¿»è¯‘ç»“æœ
                for idx, trans in zip(indices_to_translate, vllm_translations):
                    translated_texts[idx] = trans

            # ç¬¬5æ­¥ï¼šæ¢å¤å•ä½
            translated_texts = [restore_units(trans, units_map)
                              for trans, units_map in zip(translated_texts, units_maps)]

            # åº”ç”¨ç¿»è¯‘ï¼ˆä¿ç•™æ‰€æœ‰æ ¼å¼åŒ…æ‹¬é¢œè‰²ï¼‰
            for data_item, para, trans_text in zip(batch_data, batch_paras, translated_texts):
                # ç¬¬6æ­¥ï¼šåå¤„ç†ï¼šç¿»è¯‘å ä½ç¬¦
                trans_text = translate_placeholders(trans_text)

                # ç¬¬7æ­¥ï¼šåå¤„ç†ï¼šç§»é™¤VLLMå¯èƒ½æ·»åŠ çš„ç¼–å·
                trans_text = postprocess_translation(trans_text, para.style.name if para.style else None)

                # ä½¿ç”¨æ–°å‡½æ•°åº”ç”¨ç¿»è¯‘å¹¶æ¢å¤å•ä½é¢œè‰²
                apply_translation_with_colors(para, trans_text, data_item['unit_colors'])

                # æ¢å¤æ®µè½æ ¼å¼ï¼ˆå¦‚æœLibreOfficeè½¬æ¢æ—¶ä¸¢å¤±äº†æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
                from docx.shared import Pt
                from docx.enum.text import WD_LINE_SPACING

                saved_format = data_item['format']
                # å¦‚æœåŸå§‹æ ¼å¼ä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆ12ptæ®µå‰ï¼Œ1.0è¡Œè·ï¼‰
                if saved_format['space_before'] is not None:
                    para.paragraph_format.space_before = saved_format['space_before']
                else:
                    para.paragraph_format.space_before = Pt(12)

                if saved_format['space_after'] is not None:
                    para.paragraph_format.space_after = saved_format['space_after']

                if saved_format['line_spacing'] is not None and saved_format['line_spacing_rule'] is not None:
                    para.paragraph_format.line_spacing = saved_format['line_spacing']
                    para.paragraph_format.line_spacing_rule = saved_format['line_spacing_rule']
                else:
                    # è®¾ç½®å•å€è¡Œè·ï¼ˆ1.0ï¼‰
                    para.paragraph_format.line_spacing = 1.0
                    para.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE

        # ç¿»è¯‘è¡¨æ ¼
        if doc.tables:
            for table in doc.tables:
                cells_data = []
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs:
                            if para.text.strip():
                                cells_data.append((para, para.text))

                if cells_data:
                    cell_texts = [text for _, text in cells_data]

                    # ä¿æŠ¤å•ä½
                    protected_texts = []
                    units_maps = []
                    for text in cell_texts:
                        protected_text, units_map = protect_units(text)
                        protected_texts.append(protected_text)
                        units_maps.append(units_map)

                    # ç¿»è¯‘
                    translated = translate_batch(protected_texts)

                    # æ¢å¤å•ä½
                    translated = [restore_units(trans, units_map)
                                for trans, units_map in zip(translated, units_maps)]

                    for (para, _), trans in zip(cells_data, translated):
                        # åå¤„ç†ï¼šç¿»è¯‘å ä½ç¬¦
                        trans = translate_placeholders(trans)

                        if len(para.runs) == 1:
                            # ä¿å­˜åŸæœ‰æ ¼å¼
                            original_run = para.runs[0]
                            original_bold = original_run.bold
                            original_italic = original_run.italic
                            original_underline = original_run.underline
                            original_font_size = original_run.font.size
                            original_font_color = original_run.font.color.rgb if original_run.font.color and original_run.font.color.rgb else None

                            # ä¿®æ”¹æ–‡æœ¬
                            original_run.text = trans

                            # æ¢å¤æ ¼å¼ï¼ˆåŒ…æ‹¬é¢œè‰²ï¼‰
                            if original_bold is not None:
                                original_run.bold = original_bold
                            if original_italic is not None:
                                original_run.italic = original_italic
                            if original_underline is not None:
                                original_run.underline = original_underline
                            if original_font_size:
                                original_run.font.size = original_font_size
                            if original_font_color:
                                original_run.font.color.rgb = original_font_color
                            original_run.font.name = 'å®‹ä½“'

                        elif len(para.runs) > 1:
                            # ä¿å­˜ç¬¬ä¸€ä¸ªrunçš„æ ¼å¼
                            first_run = para.runs[0]
                            original_bold = first_run.bold
                            original_italic = first_run.italic
                            original_underline = first_run.underline
                            original_font_size = first_run.font.size
                            original_font_color = first_run.font.color.rgb if first_run.font.color and first_run.font.color.rgb else None

                            # ä¿®æ”¹æ–‡æœ¬
                            first_run.text = trans

                            # æ¢å¤æ ¼å¼
                            if original_bold is not None:
                                first_run.bold = original_bold
                            if original_italic is not None:
                                first_run.italic = original_italic
                            if original_underline is not None:
                                first_run.underline = original_underline
                            if original_font_size:
                                first_run.font.size = original_font_size
                            if original_font_color:
                                first_run.font.color.rgb = original_font_color
                            first_run.font.name = 'å®‹ä½“'

                            # åˆ é™¤å…¶ä»–runs
                            for run in para.runs[1:]:
                                run.text = ''
                        else:
                            new_run = para.add_run(trans)
                            new_run.font.name = 'å®‹ä½“'

        # ä¿å­˜
        doc.save(str(docx_file))
        return True

    except Exception as e:
        print(f"  âŒ ç¿»è¯‘é”™è¯¯: {e}")
        return False

# ============ æ‰¹é‡å¤„ç† ============
def batch_process(max_files=None):
    source_path = Path(SOURCE_DIR)

    if not source_path.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {SOURCE_DIR}")
        return

    folders = sorted([d for d in source_path.iterdir() if d.is_dir() and not d.name.startswith('.')])

    print(f"\n{'='*70}")
    print(f"  ğŸš€ æ‰¹é‡è½¬æ¢+ç¿»è¯‘ï¼ˆLibreOffice + å®Œæ•´æ ·å¼ä¿ç•™ï¼‰")
    print(f"{'='*70}")
    print(f"æ­¥éª¤1: LibreOffice è½¬æ¢ DOC â†’ DOCX")
    print(f"æ­¥éª¤2: ç¿»è¯‘ DOCXï¼ˆä¿ç•™æ‰€æœ‰æ ·å¼ï¼‰")
    print(f"æ–‡ä»¶å¤¹: {len(folders)} ä¸ª")
    print(f"{'='*70}\n")

    total_success = 0
    total_fail = 0
    total_skip = 0

    for folder_idx, folder in enumerate(folders, 1):
        folder_name = folder.name
        translated_folder_name = translate_folder_name(folder_name)

        print(f"\n{'#'*70}")
        print(f"# [{folder_idx}/{len(folders)}] {folder_name}")
        print(f"# â†’ {translated_folder_name}")
        print(f"{'#'*70}")

        files = sorted(list(folder.glob("*.DOC")) + list(folder.glob("*.docx")))
        files = [f for f in files if not f.name.startswith('~$') and not f.name.startswith('.~')]

        if max_files:
            files = files[:max_files]

        for file_idx, input_file in enumerate(files, 1):
            file_name = input_file.name
            translated_file_name = translate_file_name(file_name)

            output_folder = Path(OUTPUT_DIR).parent / translated_folder_name
            output_file = output_folder / translated_file_name

            print(f"\n  [{file_idx}/{len(files)}] {file_name}")
            print(f"       â†’ {translated_file_name}")

            if output_file.exists():
                print(f"  â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡")
                total_skip += 1
                continue

            try:
                # æ­¥éª¤1ï¼šè½¬æ¢
                print(f"  ğŸ”„ è½¬æ¢ä¸­...", end='', flush=True)
                if convert_doc_to_docx(input_file, output_file):
                    print(f" âœ…")

                    # æ­¥éª¤2ï¼šç¿»è¯‘
                    print(f"  ğŸ“ ç¿»è¯‘ä¸­...", end='', flush=True)
                    if translate_docx(output_file):
                        print(f" âœ…")
                        total_success += 1
                    else:
                        print(f" âŒ")
                        total_fail += 1
                else:
                    print(f" âŒ")
                    total_fail += 1

            except KeyboardInterrupt:
                print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"\n  âŒ å¤±è´¥: {e}")
                total_fail += 1

        if max_files:
            break

    print(f"\n\n{'='*70}")
    print(f"  ğŸ“Š å¤„ç†å®Œæˆ")
    print(f"{'='*70}")
    print(f"âœ… æˆåŠŸ: {total_success}")
    print(f"â­ï¸  è·³è¿‡: {total_skip}")
    print(f"âŒ å¤±è´¥: {total_fail}")
    print(f"{'='*70}\n")

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ‰¹é‡è½¬æ¢+ç¿»è¯‘")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•ï¼ˆ1ä¸ªæ–‡ä»¶ï¼‰")
    parser.add_argument("--small", action="store_true", help="å°æ‰¹é‡ï¼ˆ10ä¸ªæ–‡ä»¶ï¼‰")

    args = parser.parse_args()

    print("ğŸ”Œ æµ‹è¯•VLLMè¿æ¥...")
    try:
        response = requests.get(f"{VLLM_URL}/v1/models", timeout=5)
        if response.status_code == 200:
            print(f"âœ… VLLMè¿æ¥æˆåŠŸ\n")
        else:
            print(f"âš ï¸  VLLMå“åº”å¼‚å¸¸")
    except Exception as e:
        print(f"âŒ VLLMè¿æ¥å¤±è´¥: {e}")
        sys.exit(1)

    max_files = None
    if args.test:
        max_files = 1
    elif args.small:
        max_files = 10

    batch_process(max_files)
