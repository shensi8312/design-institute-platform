#!/usr/bin/env python3
"""
å®‰å…¨ç¿»è¯‘è„šæœ¬ - å®Œå…¨ä¿æŠ¤æ ·å¼å’Œç¼–å·
âœ… åªä¿®æ”¹æ–‡æœ¬èŠ‚ç‚¹ï¼Œä¸åŠ¨XMLç»“æ„
âœ… ä¿ç•™æ‰€æœ‰æ ·å¼ï¼ˆART, PR1, PR2ç­‰ï¼‰
âœ… ä¿ç•™è‡ªåŠ¨ç¼–å·ï¼ˆA. B. C.ï¼‰
âœ… ä¿ç•™å¤šçº§åˆ—è¡¨
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from typing import List, Dict
import requests

sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

# ============ é…ç½® ============
SOURCE_DIR = "docs/specs/Full Length"
OUTPUT_DIR = "docs/specs_zh/Full Length"
TRANSLATION_MAP = "docs/specs/æ–‡ä»¶åç¿»è¯‘å¯¹ç…§è¡¨_å®Œæ•´ç‰ˆ.json"
VLLM_URL = os.getenv("VLLM_URL", "http://10.10.18.3:8000")
VLLM_MODEL = os.getenv("VLLM_MODEL", "/mnt/data/models/Qwen3-32B")
BATCH_SIZE = 10

# ============ åŠ è½½ç¿»è¯‘å¯¹ç…§è¡¨ ============
def load_translation_map() -> Dict:
    try:
        with open(TRANSLATION_MAP, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {"folders": {}, "files": {}}

TRANS_MAP = load_translation_map()

def translate_folder_name(folder_name: str) -> str:
    return TRANS_MAP.get("folders", {}).get(folder_name, folder_name)

def translate_file_name(file_name: str) -> str:
    name_without_ext = file_name.replace('.DOC', '').replace('.docx', '')
    translated = TRANS_MAP.get("files", {}).get(file_name, name_without_ext)
    return f"{translated}.docx"

# ============ å†…å®¹è¿‡æ»¤ ============
def should_skip_paragraph(text: str) -> bool:
    skip_keywords = [
        "Copyright",
        "The American Institute of Architects",
        "AIA",
        "Exclusively published and distributed by Deltek",
        "TIPS:",
        "To view non-printing Editor's Notes",
        "MasterWorks/Single-File Formatting",
        "MasterWorks/Supporting Information",
        "Content Requests:",
        "<Double click here to submit",
        "Double click here",
    ]
    for keyword in skip_keywords:
        if keyword in text:
            return True
    return False

# ============ ç¿»è¯‘API ============
def translate_single(text: str) -> str:
    if not text.strip():
        return text

    prompt = f"""ç¿»è¯‘æˆä¸­æ–‡ï¼ˆä¿ç•™ä¸“ä¸šæœ¯è¯­å’Œæ ¼å¼ï¼‰ï¼š

{text}

ä¸­æ–‡ï¼š"""

    try:
        response = requests.post(
            f"{VLLM_URL}/v1/chat/completions",
            json={
                "model": VLLM_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1000
            },
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()['choices'][0]['message']['content'].strip()
            if '<think>' in result:
                if '</think>' in result:
                    result = result.split('</think>')[-1].strip()
                else:
                    return text
            if result.startswith("ä¸­æ–‡ï¼š") or result.startswith("ç¿»è¯‘ï¼š"):
                result = result.split("ï¼š", 1)[1].strip()
            result = result.split('\n')[0].strip()
            return result if result else text
        return text
    except:
        return text

def translate_batch(texts: List[str]) -> List[str]:
    if not texts:
        return []

    non_empty_indices = [i for i, t in enumerate(texts) if t.strip()]
    non_empty_texts = [texts[i] for i in non_empty_indices]

    if not non_empty_texts:
        return texts

    combined = "\n---SPLIT---\n".join(non_empty_texts)
    prompt = f"""ä½ æ˜¯å»ºç­‘å·¥ç¨‹è§„èŒƒç¿»è¯‘ä¸“å®¶ã€‚ç¿»è¯‘ä»¥ä¸‹{len(non_empty_texts)}ä¸ªæ®µè½ï¼ˆç”¨---SPLIT---åˆ†éš”ï¼‰ï¼š

{combined}

è¦æ±‚ï¼š
1. ä¿ç•™æ‰€æœ‰ä¸“ä¸šæœ¯è¯­ã€ç¼–å·ã€æ ¼å¼æ ‡è®°
2. ä¿æŒåŸæœ‰çš„æ¢è¡Œå’Œç¼©è¿›
3. ç”¨---SPLIT---åˆ†éš”ç¿»è¯‘ç»“æœ
4. ç›´æ¥è¾“å‡ºç¿»è¯‘ï¼Œä¸è¦åŠ "ç¿»è¯‘ï¼š"ç­‰å‰ç¼€

ä¸­æ–‡ç¿»è¯‘ï¼š"""

    try:
        response = requests.post(
            f"{VLLM_URL}/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": VLLM_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": len(combined) * 3
            },
            timeout=180
        )

        if response.status_code == 200:
            result = response.json()
            translated = result['choices'][0]['message']['content'].strip()

            if '<think>' in translated:
                if '</think>' in translated:
                    translated = translated.split('</think>')[-1].strip()
                else:
                    return [translate_single(t) for t in texts]

            if translated.startswith("ç¿»è¯‘ï¼š") or translated.startswith("ä¸­æ–‡ç¿»è¯‘ï¼š"):
                translated = translated.split("ï¼š", 1)[1].strip()

            parts = translated.split("---SPLIT---")

            if len(parts) == len(non_empty_texts):
                results = texts.copy()
                for i, idx in enumerate(non_empty_indices):
                    results[idx] = parts[i].strip()
                return results
            else:
                print(f"  âš ï¸  æ‰¹é‡åˆ†å‰²å¤±è´¥({len(parts)}!={len(non_empty_texts)})ï¼Œé€ä¸ªç¿»è¯‘...")
                return [translate_single(t) for t in texts]
        else:
            return texts
    except Exception as e:
        print(f"  âš ï¸  ç¿»è¯‘å¤±è´¥: {e}")
        return [translate_single(t) for t in texts]

# ============ å®‰å…¨æ–‡æ¡£å¤„ç† - åªä¿®æ”¹æ–‡æœ¬ä¸åŠ¨ç»“æ„ ============
def process_word_document_safe(input_file: Path, output_file: Path):
    """
    æœ€å®‰å…¨çš„å¤„ç†æ–¹å¼ï¼š
    1. åªä¿®æ”¹æ¯ä¸ªrunçš„textå±æ€§
    2. å®Œå…¨ä¸åˆ é™¤ã€ä¸æ·»åŠ ã€ä¸é‡å»ºä»»ä½•å…ƒç´ 
    3. ä¿ç•™æ®µè½æ ·å¼ã€ç¼–å·ã€åˆ—è¡¨ç­‰æ‰€æœ‰å±æ€§
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“„ å¤„ç†: {input_file.name}")
    print(f"{'='*70}")

    # 1. DOCè½¬DOCX
    if input_file.suffix.upper() == '.DOC':
        temp_docx = Path(f"/tmp/{input_file.stem}_temp.docx")
        if sys.platform == 'darwin':
            print("ğŸ”„ DOCè½¬DOCX (ä½¿ç”¨textutil)...")
            result = subprocess.run([
                'textutil', '-convert', 'docx',
                str(input_file), '-output', str(temp_docx)
            ], capture_output=True, text=True)

            if result.returncode != 0 or not temp_docx.exists():
                print(f"âŒ è½¬æ¢å¤±è´¥")
                return False
            working_file = temp_docx
        else:
            print("âŒ émacOSç³»ç»Ÿ")
            return False
    else:
        working_file = input_file

    output_file.parent.mkdir(parents=True, exist_ok=True)

    try:
        from docx import Document

        doc = Document(str(working_file))

        # 2. ç§»é™¤é¡µçœ‰é¡µè„š
        print("ğŸ—‘ï¸  ç§»é™¤é¡µçœ‰é¡µè„š...")
        for section in doc.sections:
            section.header.is_linked_to_previous = False
            section.footer.is_linked_to_previous = False
            for p in section.header.paragraphs:
                for run in p.runs:
                    run.text = ''
            for p in section.footer.paragraphs:
                for run in p.runs:
                    run.text = ''

        # 3. æ”¶é›†éœ€è¦ç¿»è¯‘çš„æ®µè½
        paragraphs_to_translate = []
        skipped_count = 0

        for para in doc.paragraphs:
            if para.text.strip():
                if should_skip_paragraph(para.text):
                    # åˆ é™¤ç‰ˆæƒæ®µè½çš„æ‰€æœ‰run
                    for run in para.runs:
                        run.text = ''
                    skipped_count += 1
                else:
                    paragraphs_to_translate.append(para)

        if skipped_count > 0:
            print(f"ğŸ—‘ï¸  å·²åˆ é™¤ {skipped_count} ä¸ªç‰ˆæƒ/æç¤ºæ®µè½")

        total = len(paragraphs_to_translate)
        print(f"ğŸ“ ç¿»è¯‘ {total} ä¸ªæ®µè½ï¼ˆ{BATCH_SIZE}ä¸ª/æ‰¹ï¼‰...")

        # 4. æ‰¹é‡ç¿»è¯‘ - æœ€å®‰å…¨çš„æ–¹å¼
        for i in range(0, total, BATCH_SIZE):
            batch_paras = paragraphs_to_translate[i:i+BATCH_SIZE]
            batch_texts = [p.text for p in batch_paras]

            progress = f"[{i+1}-{min(i+BATCH_SIZE, total)}/{total}]"
            print(f"{progress} ç¿»è¯‘ä¸­...", end='', flush=True)

            translated_texts = translate_batch(batch_texts)

            # åº”ç”¨ç¿»è¯‘ - å…³é”®ï¼šåªä¿®æ”¹run.textï¼Œä»€ä¹ˆéƒ½ä¸åˆ é™¤ä¸æ·»åŠ 
            for para, trans_text in zip(batch_paras, translated_texts):
                # æ–¹æ¡ˆAï¼šå¦‚æœåªæœ‰ä¸€ä¸ªrunï¼Œç›´æ¥ä¿®æ”¹
                if len(para.runs) == 1:
                    para.runs[0].text = trans_text

                # æ–¹æ¡ˆBï¼šå¦‚æœæœ‰å¤šä¸ªrunsï¼ŒæŠŠæ–‡æœ¬åˆå¹¶åˆ°ç¬¬ä¸€ä¸ªrun
                elif len(para.runs) > 1:
                    para.runs[0].text = trans_text
                    # æ¸…ç©ºå…¶ä»–runsï¼ˆä½†ä¸åˆ é™¤ï¼Œé¿å…ç ´åç»“æ„ï¼‰
                    for run in para.runs[1:]:
                        run.text = ''

                # æ–¹æ¡ˆCï¼šå¦‚æœæ²¡æœ‰runï¼Œæ·»åŠ ä¸€ä¸ªï¼ˆä¿æŒæ ·å¼ï¼‰
                else:
                    para.add_run(trans_text)

            print(f" âœ…")

        # 5. ç¿»è¯‘è¡¨æ ¼
        if doc.tables:
            print(f"\nğŸ“Š ç¿»è¯‘ {len(doc.tables)} ä¸ªè¡¨æ ¼...")
            for table_idx, table in enumerate(doc.tables, 1):
                cells_data = []
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs:
                            if para.text.strip():
                                cells_data.append((para, para.text))

                if cells_data:
                    cell_texts = [text for _, text in cells_data]
                    print(f"  è¡¨æ ¼{table_idx}: {len(cell_texts)}ä¸ªå•å…ƒæ ¼...", end='', flush=True)
                    translated = translate_batch(cell_texts)

                    for (para, _), trans in zip(cells_data, translated):
                        if len(para.runs) == 1:
                            para.runs[0].text = trans
                        elif len(para.runs) > 1:
                            para.runs[0].text = trans
                            for run in para.runs[1:]:
                                run.text = ''
                        else:
                            para.add_run(trans)

                    print(" âœ…")

        # 6. ä¿å­˜
        doc.save(str(output_file))
        print(f"\nâœ… å®Œæˆï¼ä¿å­˜åˆ°: {output_file}")

        # 7. æ¸…ç†
        if input_file.suffix.upper() == '.DOC' and temp_docx.exists():
            temp_docx.unlink()

        return True

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

# ============ æ‰¹é‡ç¿»è¯‘ ============
def batch_translate_all(max_files=None):
    source_path = Path(SOURCE_DIR)

    if not source_path.exists():
        print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {SOURCE_DIR}")
        return

    folders = sorted([d for d in source_path.iterdir() if d.is_dir() and not d.name.startswith('.')])

    print(f"\n{'='*70}")
    print(f"  ğŸš€ å®‰å…¨ç¿»è¯‘ï¼ˆå®Œå…¨ä¿æŠ¤æ ·å¼å’Œç¼–å·ï¼‰")
    print(f"{'='*70}")
    print(f"æºç›®å½•: {SOURCE_DIR}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"æ–‡ä»¶å¤¹: {len(folders)} ä¸ª")
    print(f"{'='*70}\n")

    total_success = 0
    total_fail = 0
    total_skip = 0

    for folder_idx, folder in enumerate(folders, 1):
        folder_name = folder.name
        translated_folder_name = translate_folder_name(folder_name)

        print(f"\n{'#'*70}")
        print(f"# æ–‡ä»¶å¤¹ [{folder_idx}/{len(folders)}]: {folder_name}")
        print(f"# ç¿»è¯‘ä¸º: {translated_folder_name}")
        print(f"{'#'*70}")

        files = sorted(list(folder.glob("*.DOC")) + list(folder.glob("*.docx")))
        files = [f for f in files if not f.name.startswith('~$') and not f.name.startswith('.~')]

        if max_files:
            files = files[:max_files]

        for file_idx, input_file in enumerate(files, 1):
            file_name = input_file.name
            translated_file_name = translate_file_name(file_name)

            output_folder = Path(OUTPUT_DIR).parent / translated_folder_name
            output_file = output_folder / translated_file_name

            print(f"\n  [{file_idx}/{len(files)}] {file_name}")
            print(f"       â†’ {translated_file_name}")

            if output_file.exists():
                print(f"  â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡")
                total_skip += 1
                continue

            try:
                success = process_word_document_safe(input_file, output_file)
                if success:
                    total_success += 1
                else:
                    total_fail += 1
            except KeyboardInterrupt:
                print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"\n  âŒ å¤±è´¥: {e}")
                total_fail += 1

        if max_files:
            break

    print(f"\n\n{'='*70}")
    print(f"  ğŸ“Š ç¿»è¯‘å®Œæˆ")
    print(f"{'='*70}")
    print(f"âœ… æˆåŠŸ: {total_success}")
    print(f"â­ï¸  è·³è¿‡: {total_skip}")
    print(f"âŒ å¤±è´¥: {total_fail}")
    print(f"{'='*70}\n")

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="å®‰å…¨ç¿»è¯‘ï¼ˆä¿æŠ¤æ ·å¼ï¼‰")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•ï¼ˆ1ä¸ªæ–‡ä»¶ï¼‰")
    parser.add_argument("--small", action="store_true", help="å°æ‰¹é‡ï¼ˆ10ä¸ªæ–‡ä»¶ï¼‰")

    args = parser.parse_args()

    print("ğŸ”Œ æµ‹è¯•VLLMè¿æ¥...")
    try:
        response = requests.get(f"{VLLM_URL}/v1/models", timeout=5)
        if response.status_code == 200:
            print(f"âœ… VLLMæœåŠ¡è¿æ¥æˆåŠŸ\n")
        else:
            print(f"âš ï¸  VLLMå“åº”å¼‚å¸¸")
    except Exception as e:
        print(f"âŒ VLLMè¿æ¥å¤±è´¥: {e}")
        sys.exit(1)

    max_files = None
    if args.test:
        max_files = 1
    elif args.small:
        max_files = 10

    batch_translate_all(max_files)
